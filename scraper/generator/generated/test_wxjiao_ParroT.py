import sys
_module = sys.modules[__name__]
del sys
convert_alpaca_to_hf = _module
convert_pair_to_alpaca = _module
inference = _module
inference_lora = _module
create_circleci_config = _module
conftest = _module
_config = _module
create_model_from_encoder_decoder_models = _module
run_image_captioning_flax = _module
run_bart_dlm_flax = _module
run_clm_flax = _module
run_mlm_flax = _module
run_t5_mlm_flax = _module
t5_tokenizer_model = _module
run_qa = _module
utils_qa = _module
run_summarization_flax = _module
test_flax_examples = _module
run_flax_glue = _module
run_flax_ner = _module
run_image_classification = _module
run_multiple_choice = _module
utils_multiple_choice = _module
lightning_base = _module
run_glue = _module
run_ner = _module
run_squad = _module
run_squad_trainer = _module
run_camembert = _module
run_chinese_ref = _module
run_language_modeling = _module
run_openai_gpt = _module
run_swag = _module
run_transfo_xl = _module
seq2seq = _module
convert_model_to_fp16 = _module
download_wmt = _module
finetune_trainer = _module
minify_dataset = _module
old_test_calculate_rouge = _module
old_test_datasets = _module
old_test_fsmt_bleu_score = _module
old_test_seq2seq_examples = _module
old_test_seq2seq_examples_multi_gpu = _module
old_test_tatoeba_conversion = _module
pack_dataset = _module
rouge_cli = _module
run_distributed_eval = _module
run_eval = _module
run_eval_search = _module
save_len_file = _module
save_randomly_initialized_model = _module
sentence_splitter = _module
seq2seq_trainer = _module
seq2seq_training_args = _module
utils = _module
xla_spawn = _module
run_tf_text_classification = _module
run_tf_ner = _module
preprocess = _module
tasks = _module
utils_ner = _module
run_audio_classification = _module
plot_csv_file = _module
run_benchmark = _module
run_clip = _module
run_image_classification_no_trainer = _module
run_mae = _module
run_mim = _module
flash_attention = _module
bloom_flash_attention = _module
llama_flash_attention = _module
triton_flash_attention = _module
run_clm = _module
run_clm_llms = _module
run_clm_llms_flash = _module
run_clm_lora = _module
run_clm_no_trainer = _module
run_mlm = _module
run_mlm_no_trainer = _module
run_plm = _module
run_swag_no_trainer = _module
run_qa_beam_search = _module
run_qa_beam_search_no_trainer = _module
run_qa_no_trainer = _module
run_seq2seq_qa = _module
trainer_qa = _module
trainer_seq2seq_qa = _module
run_semantic_segmentation = _module
run_semantic_segmentation_no_trainer = _module
run_wav2vec2_pretraining_no_trainer = _module
run_speech_recognition_ctc = _module
run_speech_recognition_seq2seq = _module
run_summarization = _module
run_summarization_no_trainer = _module
test_accelerate_examples = _module
test_pytorch_examples = _module
test_xla_examples = _module
run_glue_no_trainer = _module
run_xnli = _module
run_generation = _module
run_generation_contrastive_search = _module
run_ner_no_trainer = _module
run_translation = _module
run_translation_no_trainer = _module
run_hans = _module
utils_hans = _module
pabee = _module
modeling_pabee_albert = _module
modeling_pabee_bert = _module
run_glue_with_pabee = _module
test_run_glue_with_pabee = _module
bertabs = _module
configuration_bertabs = _module
convert_bertabs_original_pytorch_checkpoint = _module
modeling_bertabs = _module
test_utils_summarization = _module
utils_summarization = _module
run_bertology = _module
run_prune_gpt = _module
train_complexity_predictor = _module
arguments = _module
bpe_training = _module
codeparrot_training = _module
human_eval = _module
initialize_model = _module
minhash_deduplication = _module
preprocessing = _module
pretokenizing = _module
tests = _module
test_deduplicate = _module
validation_loss = _module
run_decision_transformer = _module
run_glue_deebert = _module
src = _module
modeling_highway_bert = _module
modeling_highway_roberta = _module
test_glue_deebert = _module
distiller = _module
grouped_batch_sampler = _module
lm_seqs_dataset = _module
run_squad_w_distillation = _module
binarized_data = _module
extract = _module
extract_distilbert = _module
token_counts = _module
train = _module
setup = _module
fsner = _module
model = _module
tokenizer_utils = _module
igf = _module
run_clm_igf = _module
bigbird_flax = _module
evaluate = _module
prepare_natural_questions = _module
run_mlm_flax_stream = _module
configuration_hybrid_clip = _module
modeling_hybrid_clip = _module
run_hybrid_clip = _module
partitions = _module
run_clm_mp = _module
run_wav2vec2_pretrain_flax = _module
run_funsd_cord = _module
eli5_app = _module
eli5_utils = _module
luke_utils = _module
run_luke_ner_no_trainer = _module
extracting_data = _module
modeling_frcnn = _module
processing_image = _module
visualizing_image = _module
run_mlm_wwm = _module
run_mmimdb = _module
utils_mmimdb = _module
bertarize = _module
counts_parameters = _module
emmental = _module
configuration_bert_masked = _module
modeling_bert_masked = _module
modules = _module
binarizer = _module
masked_nn = _module
masked_run_glue = _module
masked_run_squad = _module
generation_onnx = _module
reduce_onnx_size = _module
run_onnx_exporter = _module
modeling_flax_performer = _module
modeling_flax_performer_utils = _module
run_mlm_performer = _module
pplm_classification_head = _module
run_pplm = _module
run_pplm_discrim_train = _module
quant_trainer = _module
run_quant_qa = _module
trainer_quant_qa = _module
callbacks_rag = _module
distributed_ray_retriever = _module
eval_rag = _module
finetune_rag = _module
kb_encode_utils = _module
use_own_knowledge_dataset = _module
utils_rag = _module
rag = _module
_test_finetune_rag = _module
consolidate_rag_checkpoint = _module
distributed_pytorch_retriever = _module
parse_dpr_relevance_data = _module
test_distributed_retriever = _module
eval = _module
run_speech_recognition_ctc_bnb = _module
run_speech_recognition_ctc_streaming = _module
finetuning = _module
selftraining = _module
_test_bash_script = _module
_test_make_student = _module
_test_seq2seq_examples = _module
_test_seq2seq_examples_multi_gpu = _module
callbacks = _module
convert_pl_checkpoint_to_hf = _module
distillation = _module
finetune = _module
make_student = _module
run_tabfact_with_tapex = _module
run_wikisql_with_tapex = _module
run_wikitablequestions_with_tapex = _module
wikisql_utils = _module
VQGAN_CLIP = _module
img_processing = _module
loaders = _module
alignment = _module
run_asr = _module
run_common_voice = _module
run_pretrain = _module
test_wav2vec2_deepspeed = _module
run_xtreme_s = _module
distill_classifier = _module
run_benchmark_tf = _module
test_tensorflow_examples = _module
run_text_classification = _module
hubconf = _module
check_tokenizers = _module
build_test_sample_spm_no_bos = _module
stale = _module
transformers = _module
activations = _module
activations_tf = _module
audio_utils = _module
benchmark = _module
benchmark_args = _module
benchmark_args_tf = _module
benchmark_args_utils = _module
benchmark_tf = _module
benchmark_utils = _module
commands = _module
add_new_model = _module
add_new_model_like = _module
convert = _module
download = _module
env = _module
lfs = _module
pt_to_tf = _module
run = _module
serving = _module
transformers_cli = _module
user = _module
configuration_utils = _module
convert_graph_to_onnx = _module
convert_pytorch_checkpoint_to_tf2 = _module
convert_slow_tokenizer = _module
convert_slow_tokenizers_checkpoints_to_fast = _module
convert_tf_hub_seq_to_seq_bert_to_pytorch = _module
data = _module
data_collator = _module
datasets = _module
glue = _module
language_modeling = _module
squad = _module
metrics = _module
squad_metrics = _module
processors = _module
xnli = _module
test_generation_utils = _module
debug_utils = _module
deepspeed = _module
dependency_versions_check = _module
dependency_versions_table = _module
dynamic_module_utils = _module
feature_extraction_sequence_utils = _module
feature_extraction_utils = _module
file_utils = _module
generation = _module
beam_constraints = _module
beam_search = _module
flax_logits_process = _module
flax_utils = _module
logits_process = _module
stopping_criteria = _module
tf_logits_process = _module
tf_utils = _module
generation_flax_utils = _module
generation_tf_utils = _module
generation_utils = _module
hf_argparser = _module
image_processing_utils = _module
image_transforms = _module
image_utils = _module
integrations = _module
keras_callbacks = _module
modelcard = _module
modeling_flax_outputs = _module
modeling_flax_pytorch_utils = _module
modeling_flax_utils = _module
modeling_outputs = _module
modeling_tf_outputs = _module
modeling_tf_pytorch_utils = _module
modeling_tf_utils = _module
modeling_utils = _module
models = _module
albert = _module
configuration_albert = _module
convert_albert_original_tf_checkpoint_to_pytorch = _module
modeling_albert = _module
modeling_flax_albert = _module
modeling_tf_albert = _module
tokenization_albert = _module
tokenization_albert_fast = _module
align = _module
configuration_align = _module
convert_align_tf_to_hf = _module
modeling_align = _module
processing_align = _module
altclip = _module
configuration_altclip = _module
modeling_altclip = _module
processing_altclip = _module
audio_spectrogram_transformer = _module
configuration_audio_spectrogram_transformer = _module
convert_audio_spectrogram_transformer_original_to_pytorch = _module
feature_extraction_audio_spectrogram_transformer = _module
modeling_audio_spectrogram_transformer = _module
auto = _module
auto_factory = _module
configuration_auto = _module
feature_extraction_auto = _module
image_processing_auto = _module
modeling_auto = _module
modeling_flax_auto = _module
modeling_tf_auto = _module
processing_auto = _module
tokenization_auto = _module
bart = _module
configuration_bart = _module
convert_bart_original_pytorch_checkpoint_to_pytorch = _module
modeling_bart = _module
modeling_flax_bart = _module
modeling_tf_bart = _module
tokenization_bart = _module
tokenization_bart_fast = _module
barthez = _module
tokenization_barthez = _module
tokenization_barthez_fast = _module
bartpho = _module
tokenization_bartpho = _module
beit = _module
configuration_beit = _module
convert_beit_unilm_to_pytorch = _module
feature_extraction_beit = _module
image_processing_beit = _module
modeling_beit = _module
modeling_flax_beit = _module
bert = _module
configuration_bert = _module
convert_bert_original_tf2_checkpoint_to_pytorch = _module
convert_bert_original_tf_checkpoint_to_pytorch = _module
convert_bert_pytorch_checkpoint_to_original_tf = _module
convert_bert_token_dropping_original_tf2_checkpoint_to_pytorch = _module
modeling_bert = _module
modeling_flax_bert = _module
modeling_tf_bert = _module
tokenization_bert = _module
tokenization_bert_fast = _module
tokenization_bert_tf = _module
bert_generation = _module
configuration_bert_generation = _module
modeling_bert_generation = _module
tokenization_bert_generation = _module
bert_japanese = _module
tokenization_bert_japanese = _module
bertweet = _module
tokenization_bertweet = _module
big_bird = _module
configuration_big_bird = _module
convert_bigbird_original_tf_checkpoint_to_pytorch = _module
modeling_big_bird = _module
modeling_flax_big_bird = _module
tokenization_big_bird = _module
tokenization_big_bird_fast = _module
bigbird_pegasus = _module
configuration_bigbird_pegasus = _module
convert_bigbird_pegasus_tf_to_pytorch = _module
modeling_bigbird_pegasus = _module
biogpt = _module
configuration_biogpt = _module
convert_biogpt_original_pytorch_checkpoint_to_pytorch = _module
modeling_biogpt = _module
tokenization_biogpt = _module
bit = _module
configuration_bit = _module
convert_bit_to_pytorch = _module
image_processing_bit = _module
modeling_bit = _module
blenderbot = _module
configuration_blenderbot = _module
convert_blenderbot_original_pytorch_checkpoint_to_pytorch = _module
modeling_blenderbot = _module
modeling_flax_blenderbot = _module
modeling_tf_blenderbot = _module
tokenization_blenderbot = _module
tokenization_blenderbot_fast = _module
blenderbot_small = _module
configuration_blenderbot_small = _module
modeling_blenderbot_small = _module
modeling_flax_blenderbot_small = _module
modeling_tf_blenderbot_small = _module
tokenization_blenderbot_small = _module
tokenization_blenderbot_small_fast = _module
blip = _module
configuration_blip = _module
convert_blip_original_pytorch_to_hf = _module
image_processing_blip = _module
modeling_blip = _module
modeling_blip_text = _module
processing_blip = _module
blip_2 = _module
configuration_blip_2 = _module
convert_blip_2_original_to_pytorch = _module
modeling_blip_2 = _module
processing_blip_2 = _module
bloom = _module
configuration_bloom = _module
convert_bloom_original_checkpoint_to_pytorch = _module
modeling_bloom = _module
tokenization_bloom_fast = _module
bort = _module
convert_bort_original_gluonnlp_checkpoint_to_pytorch = _module
bridgetower = _module
configuration_bridgetower = _module
image_processing_bridgetower = _module
modeling_bridgetower = _module
processing_bridgetower = _module
byt5 = _module
convert_byt5_original_tf_checkpoint_to_pytorch = _module
tokenization_byt5 = _module
camembert = _module
configuration_camembert = _module
modeling_camembert = _module
modeling_tf_camembert = _module
tokenization_camembert = _module
tokenization_camembert_fast = _module
canine = _module
configuration_canine = _module
convert_canine_original_tf_checkpoint_to_pytorch = _module
modeling_canine = _module
tokenization_canine = _module
chinese_clip = _module
configuration_chinese_clip = _module
convert_chinese_clip_original_pytorch_to_hf = _module
feature_extraction_chinese_clip = _module
image_processing_chinese_clip = _module
modeling_chinese_clip = _module
processing_chinese_clip = _module
clap = _module
configuration_clap = _module
convert_clap_original_pytorch_to_hf = _module
feature_extraction_clap = _module
modeling_clap = _module
processing_clap = _module
clip = _module
configuration_clip = _module
convert_clip_original_pytorch_to_hf = _module
feature_extraction_clip = _module
image_processing_clip = _module
modeling_clip = _module
modeling_flax_clip = _module
modeling_tf_clip = _module
processing_clip = _module
tokenization_clip = _module
tokenization_clip_fast = _module
clipseg = _module
configuration_clipseg = _module
convert_clipseg_original_pytorch_to_hf = _module
modeling_clipseg = _module
processing_clipseg = _module
codegen = _module
configuration_codegen = _module
modeling_codegen = _module
tokenization_codegen = _module
tokenization_codegen_fast = _module
conditional_detr = _module
configuration_conditional_detr = _module
convert_conditional_detr_original_pytorch_checkpoint_to_pytorch = _module
feature_extraction_conditional_detr = _module
image_processing_conditional_detr = _module
modeling_conditional_detr = _module
convbert = _module
configuration_convbert = _module
convert_convbert_original_tf1_checkpoint_to_pytorch_and_tf2 = _module
modeling_convbert = _module
modeling_tf_convbert = _module
tokenization_convbert = _module
tokenization_convbert_fast = _module
convnext = _module
configuration_convnext = _module
convert_convnext_to_pytorch = _module
feature_extraction_convnext = _module
image_processing_convnext = _module
modeling_convnext = _module
modeling_tf_convnext = _module
convnextv2 = _module
configuration_convnextv2 = _module
convert_convnextv2_to_pytorch = _module
modeling_convnextv2 = _module
cpm = _module
tokenization_cpm = _module
tokenization_cpm_fast = _module
ctrl = _module
configuration_ctrl = _module
modeling_ctrl = _module
modeling_tf_ctrl = _module
tokenization_ctrl = _module
cvt = _module
configuration_cvt = _module
convert_cvt_original_pytorch_checkpoint_to_pytorch = _module
modeling_cvt = _module
modeling_tf_cvt = _module
data2vec = _module
configuration_data2vec_audio = _module
configuration_data2vec_text = _module
configuration_data2vec_vision = _module
convert_data2vec_audio_original_pytorch_checkpoint_to_pytorch = _module
convert_data2vec_text_original_pytorch_checkpoint_to_pytorch = _module
convert_data2vec_vision_original_pytorch_checkpoint_to_pytorch = _module
modeling_data2vec_audio = _module
modeling_data2vec_text = _module
modeling_data2vec_vision = _module
modeling_tf_data2vec_vision = _module
deberta = _module
configuration_deberta = _module
modeling_deberta = _module
modeling_tf_deberta = _module
tokenization_deberta = _module
tokenization_deberta_fast = _module
deberta_v2 = _module
configuration_deberta_v2 = _module
modeling_deberta_v2 = _module
modeling_tf_deberta_v2 = _module
tokenization_deberta_v2 = _module
tokenization_deberta_v2_fast = _module
decision_transformer = _module
configuration_decision_transformer = _module
modeling_decision_transformer = _module
deformable_detr = _module
configuration_deformable_detr = _module
convert_deformable_detr_to_pytorch = _module
feature_extraction_deformable_detr = _module
image_processing_deformable_detr = _module
load_custom = _module
modeling_deformable_detr = _module
deit = _module
configuration_deit = _module
convert_deit_timm_to_pytorch = _module
feature_extraction_deit = _module
image_processing_deit = _module
modeling_deit = _module
modeling_tf_deit = _module
deta = _module
configuration_deta = _module
convert_deta_resnet_to_pytorch = _module
convert_deta_swin_to_pytorch = _module
image_processing_deta = _module
modeling_deta = _module
detr = _module
configuration_detr = _module
convert_detr_original_pytorch_checkpoint_to_pytorch = _module
convert_detr_to_pytorch = _module
feature_extraction_detr = _module
image_processing_detr = _module
modeling_detr = _module
dialogpt = _module
convert_dialogpt_original_pytorch_checkpoint_to_pytorch = _module
dinat = _module
configuration_dinat = _module
modeling_dinat = _module
distilbert = _module
configuration_distilbert = _module
modeling_distilbert = _module
modeling_flax_distilbert = _module
modeling_tf_distilbert = _module
tokenization_distilbert = _module
tokenization_distilbert_fast = _module
dit = _module
convert_dit_unilm_to_pytorch = _module
donut = _module
configuration_donut_swin = _module
convert_donut_to_pytorch = _module
feature_extraction_donut = _module
image_processing_donut = _module
modeling_donut_swin = _module
processing_donut = _module
dpr = _module
configuration_dpr = _module
convert_dpr_original_checkpoint_to_pytorch = _module
modeling_dpr = _module
modeling_tf_dpr = _module
tokenization_dpr = _module
tokenization_dpr_fast = _module
dpt = _module
configuration_dpt = _module
convert_dpt_hybrid_to_pytorch = _module
convert_dpt_to_pytorch = _module
feature_extraction_dpt = _module
image_processing_dpt = _module
modeling_dpt = _module
efficientformer = _module
configuration_efficientformer = _module
convert_efficientformer_original_pytorch_checkpoint_to_pytorch = _module
image_processing_efficientformer = _module
modeling_efficientformer = _module
efficientnet = _module
configuration_efficientnet = _module
convert_efficientnet_to_pytorch = _module
image_processing_efficientnet = _module
modeling_efficientnet = _module
electra = _module
configuration_electra = _module
convert_electra_original_tf_checkpoint_to_pytorch = _module
modeling_electra = _module
modeling_flax_electra = _module
modeling_tf_electra = _module
tokenization_electra = _module
tokenization_electra_fast = _module
encoder_decoder = _module
configuration_encoder_decoder = _module
modeling_encoder_decoder = _module
modeling_flax_encoder_decoder = _module
modeling_tf_encoder_decoder = _module
ernie = _module
configuration_ernie = _module
modeling_ernie = _module
ernie_m = _module
configuration_ernie_m = _module
modeling_ernie_m = _module
tokenization_ernie_m = _module
esm = _module
configuration_esm = _module
convert_esm = _module
modeling_esm = _module
modeling_esmfold = _module
modeling_tf_esm = _module
openfold_utils = _module
chunk_utils = _module
data_transforms = _module
feats = _module
loss = _module
protein = _module
residue_constants = _module
rigid_utils = _module
tensor_utils = _module
tokenization_esm = _module
flaubert = _module
configuration_flaubert = _module
modeling_flaubert = _module
modeling_tf_flaubert = _module
tokenization_flaubert = _module
flava = _module
configuration_flava = _module
convert_dalle_to_flava_codebook = _module
convert_flava_original_pytorch_to_hf = _module
feature_extraction_flava = _module
image_processing_flava = _module
modeling_flava = _module
processing_flava = _module
fnet = _module
configuration_fnet = _module
convert_fnet_original_flax_checkpoint_to_pytorch = _module
modeling_fnet = _module
tokenization_fnet = _module
tokenization_fnet_fast = _module
fsmt = _module
configuration_fsmt = _module
convert_fsmt_original_pytorch_checkpoint_to_pytorch = _module
modeling_fsmt = _module
tokenization_fsmt = _module
funnel = _module
configuration_funnel = _module
convert_funnel_original_tf_checkpoint_to_pytorch = _module
modeling_funnel = _module
modeling_tf_funnel = _module
tokenization_funnel = _module
tokenization_funnel_fast = _module
git = _module
configuration_git = _module
convert_git_to_pytorch = _module
modeling_git = _module
processing_git = _module
glpn = _module
configuration_glpn = _module
convert_glpn_to_pytorch = _module
feature_extraction_glpn = _module
image_processing_glpn = _module
modeling_glpn = _module
gpt2 = _module
configuration_gpt2 = _module
convert_gpt2_original_tf_checkpoint_to_pytorch = _module
modeling_flax_gpt2 = _module
modeling_gpt2 = _module
modeling_tf_gpt2 = _module
tokenization_gpt2 = _module
tokenization_gpt2_fast = _module
tokenization_gpt2_tf = _module
gpt_neo = _module
configuration_gpt_neo = _module
convert_gpt_neo_mesh_tf_to_pytorch = _module
modeling_flax_gpt_neo = _module
modeling_gpt_neo = _module
gpt_neox = _module
configuration_gpt_neox = _module
modeling_gpt_neox = _module
tokenization_gpt_neox_fast = _module
gpt_neox_japanese = _module
configuration_gpt_neox_japanese = _module
modeling_gpt_neox_japanese = _module
tokenization_gpt_neox_japanese = _module
gpt_sw3 = _module
convert_megatron_to_pytorch = _module
tokenization_gpt_sw3 = _module
gptj = _module
configuration_gptj = _module
modeling_flax_gptj = _module
modeling_gptj = _module
modeling_tf_gptj = _module
gptsan_japanese = _module
configuration_gptsan_japanese = _module
convert_gptsan_tf_checkpoint_to_pytorch = _module
modeling_gptsan_japanese = _module
tokenization_gptsan_japanese = _module
graphormer = _module
collating_graphormer = _module
configuration_graphormer = _module
modeling_graphormer = _module
groupvit = _module
configuration_groupvit = _module
convert_groupvit_nvlab_to_hf = _module
modeling_groupvit = _module
modeling_tf_groupvit = _module
herbert = _module
tokenization_herbert = _module
tokenization_herbert_fast = _module
hubert = _module
configuration_hubert = _module
convert_distilhubert_original_s3prl_checkpoint_to_pytorch = _module
convert_hubert_original_pytorch_checkpoint_to_pytorch = _module
convert_hubert_original_s3prl_checkpoint_to_pytorch = _module
modeling_hubert = _module
modeling_tf_hubert = _module
ibert = _module
configuration_ibert = _module
modeling_ibert = _module
quant_modules = _module
imagegpt = _module
configuration_imagegpt = _module
convert_imagegpt_original_tf2_to_pytorch = _module
feature_extraction_imagegpt = _module
image_processing_imagegpt = _module
modeling_imagegpt = _module
informer = _module
configuration_informer = _module
modeling_informer = _module
jukebox = _module
configuration_jukebox = _module
convert_jukebox = _module
modeling_jukebox = _module
tokenization_jukebox = _module
layoutlm = _module
configuration_layoutlm = _module
modeling_layoutlm = _module
modeling_tf_layoutlm = _module
tokenization_layoutlm = _module
tokenization_layoutlm_fast = _module
layoutlmv2 = _module
configuration_layoutlmv2 = _module
feature_extraction_layoutlmv2 = _module
image_processing_layoutlmv2 = _module
modeling_layoutlmv2 = _module
processing_layoutlmv2 = _module
tokenization_layoutlmv2 = _module
tokenization_layoutlmv2_fast = _module
layoutlmv3 = _module
configuration_layoutlmv3 = _module
feature_extraction_layoutlmv3 = _module
image_processing_layoutlmv3 = _module
modeling_layoutlmv3 = _module
modeling_tf_layoutlmv3 = _module
processing_layoutlmv3 = _module
tokenization_layoutlmv3 = _module
tokenization_layoutlmv3_fast = _module
layoutxlm = _module
processing_layoutxlm = _module
tokenization_layoutxlm = _module
tokenization_layoutxlm_fast = _module
led = _module
configuration_led = _module
modeling_led = _module
modeling_tf_led = _module
tokenization_led = _module
tokenization_led_fast = _module
levit = _module
configuration_levit = _module
convert_levit_timm_to_pytorch = _module
feature_extraction_levit = _module
image_processing_levit = _module
modeling_levit = _module
lilt = _module
configuration_lilt = _module
modeling_lilt = _module
llama = _module
configuration_llama = _module
convert_llama_weights_to_hf = _module
modeling_llama = _module
tokenization_llama = _module
longformer = _module
configuration_longformer = _module
convert_longformer_original_pytorch_lightning_to_pytorch = _module
modeling_longformer = _module
modeling_tf_longformer = _module
tokenization_longformer = _module
tokenization_longformer_fast = _module
longt5 = _module
configuration_longt5 = _module
convert_longt5x_checkpoint_to_flax = _module
modeling_flax_longt5 = _module
modeling_longt5 = _module
luke = _module
configuration_luke = _module
convert_luke_original_pytorch_checkpoint_to_pytorch = _module
modeling_luke = _module
tokenization_luke = _module
lxmert = _module
configuration_lxmert = _module
convert_lxmert_original_tf_checkpoint_to_pytorch = _module
modeling_lxmert = _module
modeling_tf_lxmert = _module
tokenization_lxmert = _module
tokenization_lxmert_fast = _module
m2m_100 = _module
configuration_m2m_100 = _module
convert_m2m100_original_checkpoint_to_pytorch = _module
modeling_m2m_100 = _module
tokenization_m2m_100 = _module
marian = _module
configuration_marian = _module
convert_marian_tatoeba_to_pytorch = _module
convert_marian_to_pytorch = _module
modeling_flax_marian = _module
modeling_marian = _module
modeling_tf_marian = _module
tokenization_marian = _module
markuplm = _module
configuration_markuplm = _module
feature_extraction_markuplm = _module
modeling_markuplm = _module
processing_markuplm = _module
tokenization_markuplm = _module
tokenization_markuplm_fast = _module
mask2former = _module
configuration_mask2former = _module
convert_mask2former_original_pytorch_checkpoint_to_pytorch = _module
image_processing_mask2former = _module
modeling_mask2former = _module
maskformer = _module
configuration_maskformer = _module
configuration_maskformer_swin = _module
convert_maskformer_original_pytorch_checkpoint_to_pytorch = _module
convert_maskformer_resnet_to_pytorch = _module
convert_maskformer_swin_to_pytorch = _module
feature_extraction_maskformer = _module
image_processing_maskformer = _module
modeling_maskformer = _module
modeling_maskformer_swin = _module
mbart = _module
configuration_mbart = _module
convert_mbart_original_checkpoint_to_pytorch = _module
modeling_flax_mbart = _module
modeling_mbart = _module
modeling_tf_mbart = _module
tokenization_mbart = _module
tokenization_mbart_fast = _module
mbart50 = _module
tokenization_mbart50 = _module
tokenization_mbart50_fast = _module
mctct = _module
configuration_mctct = _module
feature_extraction_mctct = _module
modeling_mctct = _module
processing_mctct = _module
mega = _module
configuration_mega = _module
convert_mega_original_pytorch_checkpoint_to_pytorch = _module
modeling_mega = _module
megatron_bert = _module
configuration_megatron_bert = _module
convert_megatron_bert_checkpoint = _module
modeling_megatron_bert = _module
megatron_gpt2 = _module
checkpoint_reshaping_and_interoperability = _module
convert_megatron_gpt2_checkpoint = _module
mgp_str = _module
configuration_mgp_str = _module
modeling_mgp_str = _module
processing_mgp_str = _module
tokenization_mgp_str = _module
mluke = _module
convert_mluke_original_pytorch_checkpoint_to_pytorch = _module
tokenization_mluke = _module
mmbt = _module
configuration_mmbt = _module
modeling_mmbt = _module
mobilebert = _module
configuration_mobilebert = _module
convert_mobilebert_original_tf_checkpoint_to_pytorch = _module
modeling_mobilebert = _module
modeling_tf_mobilebert = _module
tokenization_mobilebert = _module
tokenization_mobilebert_fast = _module
mobilenet_v1 = _module
configuration_mobilenet_v1 = _module
convert_original_tf_checkpoint_to_pytorch = _module
feature_extraction_mobilenet_v1 = _module
image_processing_mobilenet_v1 = _module
modeling_mobilenet_v1 = _module
mobilenet_v2 = _module
configuration_mobilenet_v2 = _module
feature_extraction_mobilenet_v2 = _module
image_processing_mobilenet_v2 = _module
modeling_mobilenet_v2 = _module
mobilevit = _module
configuration_mobilevit = _module
convert_mlcvnets_to_pytorch = _module
feature_extraction_mobilevit = _module
image_processing_mobilevit = _module
modeling_mobilevit = _module
modeling_tf_mobilevit = _module
mpnet = _module
configuration_mpnet = _module
modeling_mpnet = _module
modeling_tf_mpnet = _module
tokenization_mpnet = _module
tokenization_mpnet_fast = _module
mt5 = _module
configuration_mt5 = _module
modeling_flax_mt5 = _module
modeling_mt5 = _module
modeling_tf_mt5 = _module
mvp = _module
configuration_mvp = _module
modeling_mvp = _module
tokenization_mvp = _module
tokenization_mvp_fast = _module
nat = _module
configuration_nat = _module
modeling_nat = _module
nezha = _module
configuration_nezha = _module
modeling_nezha = _module
nllb = _module
tokenization_nllb = _module
tokenization_nllb_fast = _module
nystromformer = _module
configuration_nystromformer = _module
convert_nystromformer_original_pytorch_checkpoint_to_pytorch = _module
modeling_nystromformer = _module
oneformer = _module
configuration_oneformer = _module
convert_to_hf_oneformer = _module
image_processing_oneformer = _module
modeling_oneformer = _module
processing_oneformer = _module
openai = _module
configuration_openai = _module
convert_openai_original_tf_checkpoint_to_pytorch = _module
modeling_openai = _module
modeling_tf_openai = _module
tokenization_openai = _module
tokenization_openai_fast = _module
opt = _module
configuration_opt = _module
convert_opt_original_pytorch_checkpoint_to_pytorch = _module
modeling_flax_opt = _module
modeling_opt = _module
modeling_tf_opt = _module
owlvit = _module
configuration_owlvit = _module
convert_owlvit_original_flax_to_hf = _module
feature_extraction_owlvit = _module
image_processing_owlvit = _module
modeling_owlvit = _module
processing_owlvit = _module
pegasus = _module
configuration_pegasus = _module
convert_pegasus_tf_to_pytorch = _module
modeling_flax_pegasus = _module
modeling_pegasus = _module
modeling_tf_pegasus = _module
tokenization_pegasus = _module
tokenization_pegasus_fast = _module
pegasus_x = _module
configuration_pegasus_x = _module
modeling_pegasus_x = _module
perceiver = _module
configuration_perceiver = _module
convert_perceiver_haiku_to_pytorch = _module
feature_extraction_perceiver = _module
image_processing_perceiver = _module
modeling_perceiver = _module
tokenization_perceiver = _module
phobert = _module
tokenization_phobert = _module
pix2struct = _module
configuration_pix2struct = _module
convert_pix2struct_original_pytorch_to_hf = _module
image_processing_pix2struct = _module
modeling_pix2struct = _module
processing_pix2struct = _module
plbart = _module
configuration_plbart = _module
convert_plbart_original_checkpoint_to_torch = _module
modeling_plbart = _module
tokenization_plbart = _module
poolformer = _module
configuration_poolformer = _module
convert_poolformer_original_to_pytorch = _module
feature_extraction_poolformer = _module
image_processing_poolformer = _module
modeling_poolformer = _module
prophetnet = _module
configuration_prophetnet = _module
convert_prophetnet_original_pytorch_checkpoint_to_pytorch = _module
modeling_prophetnet = _module
tokenization_prophetnet = _module
qdqbert = _module
configuration_qdqbert = _module
modeling_qdqbert = _module
configuration_rag = _module
modeling_rag = _module
modeling_tf_rag = _module
retrieval_rag = _module
tokenization_rag = _module
realm = _module
configuration_realm = _module
modeling_realm = _module
retrieval_realm = _module
tokenization_realm = _module
tokenization_realm_fast = _module
reformer = _module
configuration_reformer = _module
convert_reformer_trax_checkpoint_to_pytorch = _module
modeling_reformer = _module
tokenization_reformer = _module
tokenization_reformer_fast = _module
regnet = _module
configuration_regnet = _module
convert_regnet_seer_10b_to_pytorch = _module
convert_regnet_to_pytorch = _module
modeling_regnet = _module
modeling_tf_regnet = _module
rembert = _module
configuration_rembert = _module
convert_rembert_tf_checkpoint_to_pytorch = _module
modeling_rembert = _module
modeling_tf_rembert = _module
tokenization_rembert = _module
tokenization_rembert_fast = _module
resnet = _module
configuration_resnet = _module
convert_resnet_to_pytorch = _module
modeling_flax_resnet = _module
modeling_resnet = _module
modeling_tf_resnet = _module
retribert = _module
configuration_retribert = _module
modeling_retribert = _module
tokenization_retribert = _module
tokenization_retribert_fast = _module
roberta = _module
configuration_roberta = _module
convert_roberta_original_pytorch_checkpoint_to_pytorch = _module
modeling_flax_roberta = _module
modeling_roberta = _module
modeling_tf_roberta = _module
tokenization_roberta = _module
tokenization_roberta_fast = _module
roberta_prelayernorm = _module
configuration_roberta_prelayernorm = _module
convert_roberta_prelayernorm_original_pytorch_checkpoint_to_pytorch = _module
modeling_flax_roberta_prelayernorm = _module
modeling_roberta_prelayernorm = _module
modeling_tf_roberta_prelayernorm = _module
roc_bert = _module
configuration_roc_bert = _module
modeling_roc_bert = _module
tokenization_roc_bert = _module
roformer = _module
configuration_roformer = _module
convert_roformer_original_tf_checkpoint_to_pytorch = _module
modeling_flax_roformer = _module
modeling_roformer = _module
modeling_tf_roformer = _module
tokenization_roformer = _module
tokenization_roformer_fast = _module
tokenization_utils = _module
segformer = _module
configuration_segformer = _module
convert_segformer_original_to_pytorch = _module
feature_extraction_segformer = _module
image_processing_segformer = _module
modeling_segformer = _module
modeling_tf_segformer = _module
sew = _module
configuration_sew = _module
convert_sew_original_pytorch_checkpoint_to_pytorch = _module
modeling_sew = _module
sew_d = _module
configuration_sew_d = _module
convert_sew_d_original_pytorch_checkpoint_to_pytorch = _module
modeling_sew_d = _module
speech_encoder_decoder = _module
configuration_speech_encoder_decoder = _module
convert_mbart_wav2vec2_seq2seq_original_to_pytorch = _module
convert_speech_to_text_wav2vec2_seq2seq_original_to_pytorch = _module
modeling_flax_speech_encoder_decoder = _module
modeling_speech_encoder_decoder = _module
speech_to_text = _module
configuration_speech_to_text = _module
convert_s2t_fairseq_to_tfms = _module
feature_extraction_speech_to_text = _module
modeling_speech_to_text = _module
modeling_tf_speech_to_text = _module
processing_speech_to_text = _module
tokenization_speech_to_text = _module
speech_to_text_2 = _module
configuration_speech_to_text_2 = _module
modeling_speech_to_text_2 = _module
processing_speech_to_text_2 = _module
tokenization_speech_to_text_2 = _module
speecht5 = _module
configuration_speecht5 = _module
convert_hifigan = _module
convert_speecht5_original_pytorch_checkpoint_to_pytorch = _module
feature_extraction_speecht5 = _module
modeling_speecht5 = _module
processing_speecht5 = _module
tokenization_speecht5 = _module
splinter = _module
configuration_splinter = _module
modeling_splinter = _module
tokenization_splinter = _module
tokenization_splinter_fast = _module
squeezebert = _module
configuration_squeezebert = _module
modeling_squeezebert = _module
tokenization_squeezebert = _module
tokenization_squeezebert_fast = _module
swin = _module
configuration_swin = _module
convert_swin_simmim_to_pytorch = _module
convert_swin_timm_to_pytorch = _module
modeling_swin = _module
modeling_tf_swin = _module
swin2sr = _module
configuration_swin2sr = _module
convert_swin2sr_original_to_pytorch = _module
image_processing_swin2sr = _module
modeling_swin2sr = _module
swinv2 = _module
configuration_swinv2 = _module
convert_swinv2_timm_to_pytorch = _module
modeling_swinv2 = _module
switch_transformers = _module
configuration_switch_transformers = _module
convert_big_switch = _module
convert_switch_transformers_original_flax_checkpoint_to_pytorch = _module
modeling_switch_transformers = _module
t5 = _module
configuration_t5 = _module
convert_t5_original_tf_checkpoint_to_pytorch = _module
convert_t5x_checkpoint_to_flax = _module
convert_t5x_checkpoint_to_pytorch = _module
modeling_flax_t5 = _module
modeling_t5 = _module
modeling_tf_t5 = _module
tokenization_t5 = _module
tokenization_t5_fast = _module
table_transformer = _module
configuration_table_transformer = _module
convert_table_transformer_original_pytorch_checkpoint_to_pytorch = _module
modeling_table_transformer = _module
tapas = _module
configuration_tapas = _module
convert_tapas_original_tf_checkpoint_to_pytorch = _module
modeling_tapas = _module
modeling_tf_tapas = _module
tokenization_tapas = _module
tapex = _module
tokenization_tapex = _module
time_series_transformer = _module
configuration_time_series_transformer = _module
modeling_time_series_transformer = _module
timesformer = _module
configuration_timesformer = _module
convert_timesformer_to_pytorch = _module
modeling_timesformer = _module
trajectory_transformer = _module
configuration_trajectory_transformer = _module
convert_trajectory_transformer_original_pytorch_checkpoint_to_pytorch = _module
modeling_trajectory_transformer = _module
transfo_xl = _module
configuration_transfo_xl = _module
convert_transfo_xl_original_tf_checkpoint_to_pytorch = _module
modeling_tf_transfo_xl = _module
modeling_tf_transfo_xl_utilities = _module
modeling_transfo_xl = _module
modeling_transfo_xl_utilities = _module
tokenization_transfo_xl = _module
trocr = _module
configuration_trocr = _module
convert_trocr_unilm_to_pytorch = _module
modeling_trocr = _module
processing_trocr = _module
tvlt = _module
configuration_tvlt = _module
feature_extraction_tvlt = _module
image_processing_tvlt = _module
modeling_tvlt = _module
processing_tvlt = _module
unispeech = _module
configuration_unispeech = _module
convert_unispeech_original_pytorch_checkpoint_to_pytorch = _module
modeling_unispeech = _module
unispeech_sat = _module
configuration_unispeech_sat = _module
convert_unispeech_original_s3prl_checkpoint_to_pytorch = _module
convert_unispeech_sat_original_pytorch_checkpoint_to_pytorch = _module
modeling_unispeech_sat = _module
upernet = _module
configuration_upernet = _module
convert_convnext_upernet_to_pytorch = _module
convert_swin_upernet_to_pytorch = _module
modeling_upernet = _module
van = _module
configuration_van = _module
convert_van_to_pytorch = _module
modeling_van = _module
videomae = _module
configuration_videomae = _module
convert_videomae_to_pytorch = _module
feature_extraction_videomae = _module
image_processing_videomae = _module
modeling_videomae = _module
vilt = _module
configuration_vilt = _module
convert_vilt_original_to_pytorch = _module
feature_extraction_vilt = _module
image_processing_vilt = _module
modeling_vilt = _module
processing_vilt = _module
vision_encoder_decoder = _module
configuration_vision_encoder_decoder = _module
modeling_flax_vision_encoder_decoder = _module
modeling_tf_vision_encoder_decoder = _module
modeling_vision_encoder_decoder = _module
vision_text_dual_encoder = _module
configuration_vision_text_dual_encoder = _module
modeling_flax_vision_text_dual_encoder = _module
modeling_tf_vision_text_dual_encoder = _module
modeling_vision_text_dual_encoder = _module
processing_vision_text_dual_encoder = _module
visual_bert = _module
configuration_visual_bert = _module
convert_visual_bert_original_pytorch_checkpoint_to_pytorch = _module
modeling_visual_bert = _module
vit = _module
configuration_vit = _module
convert_dino_to_pytorch = _module
convert_vit_timm_to_pytorch = _module
feature_extraction_vit = _module
image_processing_vit = _module
modeling_flax_vit = _module
modeling_tf_vit = _module
modeling_vit = _module
vit_hybrid = _module
configuration_vit_hybrid = _module
convert_vit_hybrid_timm_to_pytorch = _module
image_processing_vit_hybrid = _module
modeling_vit_hybrid = _module
vit_mae = _module
configuration_vit_mae = _module
convert_vit_mae_to_pytorch = _module
modeling_tf_vit_mae = _module
modeling_vit_mae = _module
vit_msn = _module
configuration_vit_msn = _module
convert_msn_to_pytorch = _module
modeling_vit_msn = _module
wav2vec2 = _module
configuration_wav2vec2 = _module
convert_wav2vec2_original_pytorch_checkpoint_to_pytorch = _module
convert_wav2vec2_original_s3prl_checkpoint_to_pytorch = _module
feature_extraction_wav2vec2 = _module
modeling_flax_wav2vec2 = _module
modeling_tf_wav2vec2 = _module
modeling_wav2vec2 = _module
processing_wav2vec2 = _module
tokenization_wav2vec2 = _module
wav2vec2_conformer = _module
configuration_wav2vec2_conformer = _module
convert_wav2vec2_conformer_original_pytorch_checkpoint_to_pytorch = _module
modeling_wav2vec2_conformer = _module
wav2vec2_phoneme = _module
tokenization_wav2vec2_phoneme = _module
wav2vec2_with_lm = _module
processing_wav2vec2_with_lm = _module
wavlm = _module
configuration_wavlm = _module
convert_wavlm_original_pytorch_checkpoint_to_pytorch = _module
convert_wavlm_original_s3prl_checkpoint_to_pytorch = _module
modeling_wavlm = _module
whisper = _module
configuration_whisper = _module
convert_openai_to_hf = _module
english_normalizer = _module
feature_extraction_whisper = _module
modeling_flax_whisper = _module
modeling_tf_whisper = _module
modeling_whisper = _module
processing_whisper = _module
tokenization_whisper = _module
tokenization_whisper_fast = _module
x_clip = _module
configuration_x_clip = _module
convert_x_clip_original_pytorch_to_hf = _module
modeling_x_clip = _module
processing_x_clip = _module
xglm = _module
configuration_xglm = _module
convert_xglm_original_ckpt_to_trfms = _module
modeling_flax_xglm = _module
modeling_tf_xglm = _module
modeling_xglm = _module
tokenization_xglm = _module
tokenization_xglm_fast = _module
xlm = _module
configuration_xlm = _module
convert_xlm_original_pytorch_checkpoint_to_pytorch = _module
modeling_tf_xlm = _module
modeling_xlm = _module
tokenization_xlm = _module
xlm_prophetnet = _module
configuration_xlm_prophetnet = _module
modeling_xlm_prophetnet = _module
tokenization_xlm_prophetnet = _module
xlm_roberta = _module
configuration_xlm_roberta = _module
modeling_flax_xlm_roberta = _module
modeling_tf_xlm_roberta = _module
modeling_xlm_roberta = _module
tokenization_xlm_roberta = _module
tokenization_xlm_roberta_fast = _module
xlm_roberta_xl = _module
configuration_xlm_roberta_xl = _module
convert_xlm_roberta_xl_original_pytorch_checkpoint_to_pytorch = _module
modeling_xlm_roberta_xl = _module
xlnet = _module
configuration_xlnet = _module
convert_xlnet_original_tf_checkpoint_to_pytorch = _module
modeling_tf_xlnet = _module
modeling_xlnet = _module
tokenization_xlnet = _module
tokenization_xlnet_fast = _module
xmod = _module
configuration_xmod = _module
convert_xmod_original_pytorch_checkpoint_to_pytorch = _module
modeling_xmod = _module
yolos = _module
configuration_yolos = _module
convert_yolos_to_pytorch = _module
feature_extraction_yolos = _module
image_processing_yolos = _module
modeling_yolos = _module
yoso = _module
configuration_yoso = _module
convert_yoso_pytorch_to_pytorch = _module
modeling_yoso = _module
onnx = _module
config = _module
features = _module
optimization = _module
optimization_tf = _module
pipelines = _module
audio_classification = _module
automatic_speech_recognition = _module
base = _module
conversational = _module
depth_estimation = _module
document_question_answering = _module
feature_extraction = _module
fill_mask = _module
image_classification = _module
image_segmentation = _module
image_to_text = _module
object_detection = _module
pt_utils = _module
question_answering = _module
table_question_answering = _module
text2text_generation = _module
text_classification = _module
text_generation = _module
token_classification = _module
video_classification = _module
visual_question_answering = _module
zero_shot_audio_classification = _module
zero_shot_classification = _module
zero_shot_image_classification = _module
zero_shot_object_detection = _module
processing_utils = _module
pytorch_utils = _module
sagemaker = _module
trainer_sm = _module
training_args_sm = _module
testing_utils = _module
time_series_utils = _module
tokenization_utils_base = _module
tokenization_utils_fast = _module
trainer = _module
trainer_callback = _module
trainer_pt_utils = _module
trainer_seq2seq = _module
trainer_tf = _module
trainer_utils = _module
training_args = _module
training_args_seq2seq = _module
training_args_tf = _module
bitsandbytes = _module
constants = _module
doc = _module
dummy_detectron2_objects = _module
dummy_flax_objects = _module
dummy_keras_nlp_objects = _module
dummy_pt_objects = _module
dummy_sentencepiece_and_tokenizers_objects = _module
dummy_sentencepiece_objects = _module
dummy_speech_objects = _module
dummy_tensorflow_text_objects = _module
dummy_tf_objects = _module
dummy_tokenizers_objects = _module
dummy_vision_objects = _module
fx = _module
generic = _module
hp_naming = _module
hub = _module
import_utils = _module
logging = _module
model_parallel_utils = _module
notebook = _module
quantization_config = _module
sentencepiece_model_pb2 = _module
versions = _module
test_benchmark = _module
test_benchmark_tf = _module
test_deepspeed = _module
test_model_zoo = _module
test_trainer_ext = _module
test_beam_constraints = _module
test_beam_search = _module
test_configuration_utils = _module
test_flax_logits_process = _module
test_flax_utils = _module
test_framework_agnostic = _module
test_logits_process = _module
test_stopping_criteria = _module
test_tf_logits_process = _module
test_tf_utils = _module
test_utils = _module
mixed_int8 = _module
test_mixed_int8 = _module
test_modeling_albert = _module
test_modeling_flax_albert = _module
test_modeling_tf_albert = _module
test_tokenization_albert = _module
test_modeling_align = _module
test_processor_align = _module
test_modeling_altclip = _module
test_feature_extraction_audio_spectrogram_transformer = _module
test_modeling_audio_spectrogram_transformer = _module
test_configuration_auto = _module
test_feature_extraction_auto = _module
test_image_processing_auto = _module
test_modeling_auto = _module
test_modeling_flax_auto = _module
test_modeling_tf_auto = _module
test_modeling_tf_pytorch = _module
test_processor_auto = _module
test_tokenization_auto = _module
test_modeling_bart = _module
test_modeling_flax_bart = _module
test_modeling_tf_bart = _module
test_tokenization_bart = _module
test_tokenization_barthez = _module
test_tokenization_bartpho = _module
test_image_processing_beit = _module
test_modeling_beit = _module
test_modeling_flax_beit = _module
test_modeling_bert = _module
test_modeling_flax_bert = _module
test_modeling_tf_bert = _module
test_tokenization_bert = _module
test_tokenization_bert_tf = _module
test_modeling_bert_generation = _module
test_tokenization_bert_generation = _module
test_tokenization_bert_japanese = _module
test_tokenization_bertweet = _module
test_modeling_big_bird = _module
test_modeling_flax_big_bird = _module
test_tokenization_big_bird = _module
test_modeling_bigbird_pegasus = _module
test_modeling_biogpt = _module
test_tokenization_biogpt = _module
test_modeling_bit = _module
test_modeling_blenderbot = _module
test_modeling_flax_blenderbot = _module
test_modeling_tf_blenderbot = _module
test_tokenization_blenderbot = _module
test_modeling_blenderbot_small = _module
test_modeling_flax_blenderbot_small = _module
test_modeling_tf_blenderbot_small = _module
test_tokenization_blenderbot_small = _module
test_image_processing_blip = _module
test_modeling_blip = _module
test_modeling_blip_text = _module
test_processor_blip = _module
test_modeling_blip_2 = _module
test_processor_blip_2 = _module
test_modeling_bloom = _module
test_tokenization_bloom = _module
test_modeling_bort = _module
test_modeling_tf_bort = _module
test_image_processing_bridgetower = _module
test_modeling_bridgetower = _module
test_tokenization_byt5 = _module
test_modeling_camembert = _module
test_modeling_tf_camembert = _module
test_tokenization_camembert = _module
test_modeling_canine = _module
test_tokenization_canine = _module
test_image_processing_chinese_clip = _module
test_modeling_chinese_clip = _module
test_processor_chinese_clip = _module
test_feature_extraction_clap = _module
test_modeling_clap = _module
test_processor_clap = _module
test_image_processing_clip = _module
test_modeling_clip = _module
test_modeling_flax_clip = _module
test_modeling_tf_clip = _module
test_processor_clip = _module
test_tokenization_clip = _module
test_modeling_clipseg = _module
test_processor_clipseg = _module
test_modeling_codegen = _module
test_tokenization_codegen = _module
test_image_processing_conditional_detr = _module
test_modeling_conditional_detr = _module
test_modeling_convbert = _module
test_modeling_tf_convbert = _module
test_image_processing_convnext = _module
test_modeling_convnext = _module
test_modeling_tf_convnext = _module
test_modeling_convnextv2 = _module
test_tokenization_cpm = _module
test_modeling_ctrl = _module
test_modeling_tf_ctrl = _module
test_tokenization_ctrl = _module
test_modeling_cvt = _module
test_modeling_tf_cvt = _module
test_modeling_data2vec_audio = _module
test_modeling_data2vec_text = _module
test_modeling_data2vec_vision = _module
test_modeling_tf_data2vec_vision = _module
test_modeling_deberta = _module
test_modeling_tf_deberta = _module
test_tokenization_deberta = _module
test_modeling_deberta_v2 = _module
test_modeling_tf_deberta_v2 = _module
test_tokenization_deberta_v2 = _module
test_modeling_decision_transformer = _module
test_image_processing_deformable_detr = _module
test_modeling_deformable_detr = _module
test_image_processing_deit = _module
test_modeling_deit = _module
test_modeling_tf_deit = _module
test_image_processing_deta = _module
test_modeling_deta = _module
test_image_processing_detr = _module
test_modeling_detr = _module
test_modeling_dinat = _module
test_modeling_distilbert = _module
test_modeling_flax_distilbert = _module
test_modeling_tf_distilbert = _module
test_tokenization_distilbert = _module
test_modeling_dit = _module
test_image_processing_donut = _module
test_modeling_donut_swin = _module
test_processing_donut = _module
test_modeling_dpr = _module
test_modeling_tf_dpr = _module
test_tokenization_dpr = _module
test_image_processing_dpt = _module
test_modeling_dpt = _module
test_modeling_dpt_hybrid = _module
test_image_processing_efficientformer = _module
test_modeling_efficientformer = _module
test_image_processing_efficientnet = _module
test_modeling_efficientnet = _module
test_modeling_electra = _module
test_modeling_flax_electra = _module
test_modeling_tf_electra = _module
test_modeling_encoder_decoder = _module
test_modeling_flax_encoder_decoder = _module
test_modeling_tf_encoder_decoder = _module
test_modeling_ernie = _module
test_modeling_ernie_m = _module
test_tokenization_ernie_m = _module
test_modeling_esm = _module
test_modeling_esmfold = _module
test_modeling_tf_esm = _module
test_tokenization_esm = _module
test_modeling_flaubert = _module
test_modeling_tf_flaubert = _module
test_image_processing_flava = _module
test_modeling_flava = _module
test_processor_flava = _module
test_modeling_fnet = _module
test_tokenization_fnet = _module
test_modeling_fsmt = _module
test_tokenization_fsmt = _module
test_modeling_funnel = _module
test_modeling_tf_funnel = _module
test_tokenization_funnel = _module
test_modeling_git = _module
test_processor_git = _module
test_image_processing_glpn = _module
test_modeling_glpn = _module
test_modeling_flax_gpt2 = _module
test_modeling_gpt2 = _module
test_modeling_tf_gpt2 = _module
test_tokenization_gpt2 = _module
test_tokenization_gpt2_tf = _module
test_modeling_flax_gpt_neo = _module
test_modeling_gpt_neo = _module
test_modeling_gpt_neox = _module
test_modeling_gpt_neox_japanese = _module
test_tokenization_gpt_neox_japanese = _module
test_tokenization_gpt_sw3 = _module
test_modeling_flax_gptj = _module
test_modeling_gptj = _module
test_modeling_tf_gptj = _module
test_modeling_gptsan_japanese = _module
test_tokenization_gptsan_japanese = _module
test_modeling_graphormer = _module
test_modeling_groupvit = _module
test_modeling_tf_groupvit = _module
test_tokenization_herbert = _module
test_modeling_hubert = _module
test_modeling_tf_hubert = _module
test_modeling_ibert = _module
test_image_processing_imagegpt = _module
test_modeling_imagegpt = _module
test_modeling_informer = _module
test_modeling_jukebox = _module
test_tokenization_jukebox = _module
test_modeling_layoutlm = _module
test_modeling_tf_layoutlm = _module
test_tokenization_layoutlm = _module
test_image_processing_layoutlmv2 = _module
test_modeling_layoutlmv2 = _module
test_processor_layoutlmv2 = _module
test_tokenization_layoutlmv2 = _module
test_image_processing_layoutlmv3 = _module
test_modeling_layoutlmv3 = _module
test_modeling_tf_layoutlmv3 = _module
test_processor_layoutlmv3 = _module
test_tokenization_layoutlmv3 = _module
test_processor_layoutxlm = _module
test_tokenization_layoutxlm = _module
test_modeling_led = _module
test_modeling_tf_led = _module
test_tokenization_led = _module
test_image_processing_levit = _module
test_modeling_levit = _module
test_modeling_lilt = _module
test_modeling_llama = _module
test_modeling_longformer = _module
test_modeling_tf_longformer = _module
test_tokenization_longformer = _module
test_modeling_flax_longt5 = _module
test_modeling_longt5 = _module
test_modeling_luke = _module
test_tokenization_luke = _module
test_modeling_lxmert = _module
test_modeling_tf_lxmert = _module
test_tokenization_lxmert = _module
test_modeling_m2m_100 = _module
test_tokenization_m2m_100 = _module
test_modeling_flax_marian = _module
test_modeling_marian = _module
test_modeling_tf_marian = _module
test_tokenization_marian = _module
test_feature_extraction_markuplm = _module
test_modeling_markuplm = _module
test_processor_markuplm = _module
test_tokenization_markuplm = _module
test_image_processing_mask2former = _module
test_modeling_mask2former = _module
test_image_processing_maskformer = _module
test_modeling_maskformer = _module
test_modeling_maskformer_swin = _module
test_modeling_flax_mbart = _module
test_modeling_mbart = _module
test_modeling_tf_mbart = _module
test_tokenization_mbart = _module
test_tokenization_mbart50 = _module
test_feature_extraction_mctct = _module
test_modeling_mctct = _module
test_processor_mctct = _module
test_modeling_mega = _module
test_modeling_megatron_bert = _module
test_modeling_megatron_gpt2 = _module
test_modeling_mgp_str = _module
test_processor_mgp_str = _module
test_tokenization_mgp_str = _module
test_tokenization_mluke = _module
test_modeling_mobilebert = _module
test_modeling_tf_mobilebert = _module
test_tokenization_mobilebert = _module
test_image_processing_mobilenet_v1 = _module
test_modeling_mobilenet_v1 = _module
test_image_processing_mobilenet_v2 = _module
test_modeling_mobilenet_v2 = _module
test_image_processing_mobilevit = _module
test_modeling_mobilevit = _module
test_modeling_tf_mobilevit = _module
test_modeling_mpnet = _module
test_modeling_tf_mpnet = _module
test_tokenization_mpnet = _module
test_modeling_flax_mt5 = _module
test_modeling_mt5 = _module
test_modeling_tf_mt5 = _module
test_modeling_mvp = _module
test_tokenization_mvp = _module
test_modeling_nat = _module
test_modeling_nezha = _module
test_tokenization_nllb = _module
test_modeling_nystromformer = _module
test_image_processing_oneformer = _module
test_modeling_oneformer = _module
test_processor_oneformer = _module
test_modeling_openai = _module
test_modeling_tf_openai = _module
test_tokenization_openai = _module
test_modeling_flax_opt = _module
test_modeling_opt = _module
test_modeling_tf_opt = _module
test_image_processing_owlvit = _module
test_modeling_owlvit = _module
test_processor_owlvit = _module
test_modeling_flax_pegasus = _module
test_modeling_pegasus = _module
test_modeling_tf_pegasus = _module
test_tokenization_pegasus = _module
test_modeling_pegasus_x = _module
test_modeling_perceiver = _module
test_tokenization_perceiver = _module
test_tokenization_phobert = _module
test_image_processing_pix2struct = _module
test_modeling_pix2struct = _module
test_processor_pix2struct = _module
test_modeling_plbart = _module
test_tokenization_plbart = _module
test_image_processing_poolformer = _module
test_modeling_poolformer = _module
test_modeling_prophetnet = _module
test_tokenization_prophetnet = _module
test_modeling_qdqbert = _module
test_modeling_rag = _module
test_modeling_tf_rag = _module
test_retrieval_rag = _module
test_tokenization_rag = _module
test_modeling_realm = _module
test_retrieval_realm = _module
test_tokenization_realm = _module
test_modeling_reformer = _module
test_tokenization_reformer = _module
test_modeling_regnet = _module
test_modeling_tf_regnet = _module
test_modeling_rembert = _module
test_modeling_tf_rembert = _module
test_modeling_flax_resnet = _module
test_modeling_resnet = _module
test_modeling_tf_resnet = _module
test_tokenization_retribert = _module
test_modeling_flax_roberta = _module
test_modeling_roberta = _module
test_modeling_tf_roberta = _module
test_tokenization_roberta = _module
test_modeling_flax_roberta_prelayernorm = _module
test_modeling_roberta_prelayernorm = _module
test_modeling_tf_roberta_prelayernorm = _module
test_modeling_roc_bert = _module
test_tokenization_roc_bert = _module
test_modeling_flax_roformer = _module
test_modeling_roformer = _module
test_modeling_tf_roformer = _module
test_tokenization_roformer = _module
test_image_processing_segformer = _module
test_modeling_segformer = _module
test_modeling_tf_segformer = _module
test_modeling_sew = _module
test_modeling_sew_d = _module
test_modeling_flax_speech_encoder_decoder = _module
test_modeling_speech_encoder_decoder = _module
test_feature_extraction_speech_to_text = _module
test_modeling_speech_to_text = _module
test_modeling_tf_speech_to_text = _module
test_processor_speech_to_text = _module
test_tokenization_speech_to_text = _module
test_modeling_speech_to_text_2 = _module
test_tokenization_speech_to_text_2 = _module
test_feature_extraction_speecht5 = _module
test_modeling_speecht5 = _module
test_processor_speecht5 = _module
test_tokenization_speecht5 = _module
test_modeling_splinter = _module
test_modeling_squeezebert = _module
test_tokenization_squeezebert = _module
test_modeling_swin = _module
test_modeling_tf_swin = _module
test_image_processing_swin2sr = _module
test_modeling_swin2sr = _module
test_modeling_swinv2 = _module
test_modeling_switch_transformers = _module
test_modeling_flax_t5 = _module
test_modeling_t5 = _module
test_modeling_tf_t5 = _module
test_tokenization_t5 = _module
test_modeling_table_transformer = _module
test_modeling_tapas = _module
test_modeling_tf_tapas = _module
test_tokenization_tapas = _module
test_tokenization_tapex = _module
test_modeling_time_series_transformer = _module
test_modeling_timesformer = _module
test_modeling_trajectory_transformer = _module
test_modeling_tf_transfo_xl = _module
test_modeling_transfo_xl = _module
test_tokenization_transfo_xl = _module
test_modeling_trocr = _module
test_feature_extraction_tvlt = _module
test_image_processor_tvlt = _module
test_modeling_tvlt = _module
test_processor_tvlt = _module
test_modeling_unispeech = _module
test_modeling_unispeech_sat = _module
test_modeling_upernet = _module
test_modeling_van = _module
test_image_processing_videomae = _module
test_modeling_videomae = _module
test_image_processing_vilt = _module
test_modeling_vilt = _module
test_modeling_flax_vision_encoder_decoder = _module
test_modeling_tf_vision_encoder_decoder = _module
test_modeling_vision_encoder_decoder = _module
test_modeling_flax_vision_text_dual_encoder = _module
test_modeling_tf_vision_text_dual_encoder = _module
test_modeling_vision_text_dual_encoder = _module
test_processor_vision_text_dual_encoder = _module
test_modeling_visual_bert = _module
test_image_processing_vit = _module
test_modeling_flax_vit = _module
test_modeling_tf_vit = _module
test_modeling_vit = _module
test_modeling_vit_hybrid = _module
test_modeling_tf_vit_mae = _module
test_modeling_vit_mae = _module
test_modeling_vit_msn = _module
test_feature_extraction_wav2vec2 = _module
test_modeling_flax_wav2vec2 = _module
test_modeling_tf_wav2vec2 = _module
test_modeling_wav2vec2 = _module
test_processor_wav2vec2 = _module
test_tokenization_wav2vec2 = _module
test_modeling_wav2vec2_conformer = _module
test_tokenization_wav2vec2_phoneme = _module
test_processor_wav2vec2_with_lm = _module
test_modeling_wavlm = _module
test_feature_extraction_whisper = _module
test_modeling_flax_whisper = _module
test_modeling_tf_whisper = _module
test_modeling_whisper = _module
test_processor_whisper = _module
test_tokenization_whisper = _module
test_modeling_x_clip = _module
test_modeling_flax_xglm = _module
test_modeling_tf_xglm = _module
test_modeling_xglm = _module
test_tokenization_xglm = _module
test_modeling_tf_xlm = _module
test_modeling_xlm = _module
test_tokenization_xlm = _module
test_modeling_xlm_prophetnet = _module
test_tokenization_xlm_prophetnet = _module
test_modeling_flax_xlm_roberta = _module
test_modeling_tf_xlm_roberta = _module
test_modeling_xlm_roberta = _module
test_tokenization_xlm_roberta = _module
test_modeling_xlm_roberta_xl = _module
test_modeling_tf_xlnet = _module
test_modeling_xlnet = _module
test_tokenization_xlnet = _module
test_modeling_xmod = _module
test_image_processing_yolos = _module
test_modeling_yolos = _module
test_modeling_yoso = _module
test_features = _module
test_onnx = _module
test_onnx_v2 = _module
test_optimization = _module
test_optimization_tf = _module
test_pipelines_audio_classification = _module
test_pipelines_automatic_speech_recognition = _module
test_pipelines_common = _module
test_pipelines_conversational = _module
test_pipelines_depth_estimation = _module
test_pipelines_document_question_answering = _module
test_pipelines_feature_extraction = _module
test_pipelines_fill_mask = _module
test_pipelines_image_classification = _module
test_pipelines_image_segmentation = _module
test_pipelines_image_to_text = _module
test_pipelines_object_detection = _module
test_pipelines_question_answering = _module
test_pipelines_summarization = _module
test_pipelines_table_question_answering = _module
test_pipelines_text2text_generation = _module
test_pipelines_text_classification = _module
test_pipelines_text_generation = _module
test_pipelines_token_classification = _module
test_pipelines_translation = _module
test_pipelines_video_classification = _module
test_pipelines_visual_question_answering = _module
test_pipelines_zero_shot = _module
test_pipelines_zero_shot_audio_classification = _module
test_pipelines_zero_shot_image_classification = _module
test_pipelines_zero_shot_object_detection = _module
test_check_copies = _module
test_check_dummies = _module
test_get_test_info = _module
test_tests_fetcher = _module
run_ddp = _module
run_glue_model_parallelism = _module
run_tf = _module
run_tf_dist = _module
test_multi_node_data_parallel = _module
test_multi_node_model_parallel = _module
test_single_node_gpu = _module
test_configuration_common = _module
test_feature_extraction_common = _module
test_image_processing_common = _module
test_image_transforms = _module
test_modeling_common = _module
test_modeling_flax_common = _module
test_modeling_tf_common = _module
test_pipeline_mixin = _module
test_sequence_feature_extraction_common = _module
test_tokenization_common = _module
tokenization = _module
test_tokenization_fast = _module
test_tokenization_utils = _module
test_data_collator = _module
test_trainer = _module
test_trainer_callback = _module
test_trainer_distributed = _module
test_trainer_seq2seq = _module
test_trainer_tpu = _module
test_trainer_utils = _module
test_activations = _module
test_activations_tf = _module
test_add_new_model_like = _module
test_cli = _module
test_convert_slow_tokenizer = _module
test_doc_samples = _module
test_file_utils = _module
test_generic = _module
test_hf_argparser = _module
test_hub_utils = _module
test_image_processing_utils = _module
test_image_utils = _module
test_logging = _module
test_model_card = _module
test_model_output = _module
test_modeling_tf_core = _module
test_offline = _module
test_skip_decorators = _module
test_versions_utils = _module
check_config_attributes = _module
check_config_docstrings = _module
check_copies = _module
check_doc_toc = _module
check_doctest_list = _module
check_dummies = _module
check_inits = _module
check_model_tester = _module
check_repo = _module
check_self_hosted_runner = _module
check_table = _module
check_task_guides = _module
check_tf_ops = _module
create_dummy_models = _module
custom_init_isort = _module
download_glue_data = _module
extract_warnings = _module
get_ci_error_statistics = _module
get_github_job_time = _module
get_modified_files = _module
get_test_info = _module
notification_service = _module
notification_service_doc_tests = _module
past_ci_versions = _module
prepare_for_doc_test = _module
print_env = _module
release = _module
sort_auto_mappings = _module
test_module = _module
custom_configuration = _module
custom_feature_extraction = _module
custom_image_processing = _module
custom_modeling = _module
custom_pipeline = _module
custom_processing = _module
custom_tokenization = _module
custom_tokenization_fast = _module
tests_fetcher = _module
update_metadata = _module
update_tiny_models = _module

from _paritybench_helpers import _mock_config, patch_functional
from unittest.mock import mock_open, MagicMock
from torch.autograd import Function
from torch.nn import Module
import abc, collections, copy, enum, functools, inspect, itertools, logging, math, matplotlib, numbers, numpy, pandas, queue, random, re, scipy, sklearn, string, time, torch, torchaudio, torchvision, triton, types, typing, uuid, warnings
import operator as op
from dataclasses import dataclass
import numpy as np
from torch import Tensor
patch_functional()
open = mock_open()
yaml = logging = sys = argparse = MagicMock()
ArgumentParser = argparse.ArgumentParser
_global_config = args = argv = cfg = config = params = _mock_config()
argparse.ArgumentParser.return_value.parse_args.return_value = _global_config
yaml.load.return_value = _global_config
sys.argv = _global_config
__version__ = '1.0.0'
xrange = range
wraps = functools.wraps


import math


import torch


import triton


import triton.language as tl


@triton.heuristics({'EVEN_M': lambda args: args['seqlen_q'] % args['BLOCK_M'] == 0, 'EVEN_N': lambda args: args['seqlen_k'] % args['BLOCK_N'] == 0, 'EVEN_HEADDIM': lambda args: args['headdim'] == args['BLOCK_HEADDIM']})
@triton.jit
def _fwd_kernel(Q, K, V, Bias, Out, Lse, TMP, softmax_scale, stride_qb, stride_qh, stride_qm, stride_kb, stride_kh, stride_kn, stride_vb, stride_vh, stride_vn, stride_bb, stride_bh, stride_bm, stride_ob, stride_oh, stride_om, nheads, seqlen_q, seqlen_k, seqlen_q_rounded, headdim, CACHE_KEY_SEQLEN_Q, CACHE_KEY_SEQLEN_K, BIAS_TYPE: 'tl.constexpr', IS_CAUSAL: 'tl.constexpr', BLOCK_HEADDIM: 'tl.constexpr', EVEN_M: 'tl.constexpr', EVEN_N: 'tl.constexpr', EVEN_HEADDIM: 'tl.constexpr', BLOCK_M: 'tl.constexpr', BLOCK_N: 'tl.constexpr'):
    start_m = tl.program_id(0)
    off_hb = tl.program_id(1)
    off_b = off_hb // nheads
    off_h = off_hb % nheads
    offs_m = start_m * BLOCK_M + tl.arange(0, BLOCK_M)
    offs_n = tl.arange(0, BLOCK_N)
    offs_d = tl.arange(0, BLOCK_HEADDIM)
    q_ptrs = Q + off_b * stride_qb + off_h * stride_qh + (offs_m[:, None] * stride_qm + offs_d[None, :])
    k_ptrs = K + off_b * stride_kb + off_h * stride_kh + (offs_n[:, None] * stride_kn + offs_d[None, :])
    v_ptrs = V + off_b * stride_vb + off_h * stride_vh + (offs_n[:, None] * stride_vn + offs_d[None, :])
    if BIAS_TYPE == 'vector':
        b_ptrs = Bias + off_b * stride_bb + off_h * stride_bh + offs_n
    elif BIAS_TYPE == 'matrix':
        b_ptrs = Bias + off_b * stride_bb + off_h * stride_bh + (offs_m[:, None] * stride_bm + offs_n[None, :])
    t_ptrs = TMP + off_hb * seqlen_q_rounded + offs_m
    lse_i = tl.zeros([BLOCK_M], dtype=tl.float32) - float('inf')
    m_i = tl.zeros([BLOCK_M], dtype=tl.float32) - float('inf')
    acc_o = tl.zeros([BLOCK_M, BLOCK_HEADDIM], dtype=tl.float32)
    if EVEN_M & EVEN_N:
        if EVEN_HEADDIM:
            q = tl.load(q_ptrs)
        else:
            q = tl.load(q_ptrs, mask=offs_d[None, :] < headdim, other=0.0)
    elif EVEN_HEADDIM:
        q = tl.load(q_ptrs, mask=offs_m[:, None] < seqlen_q, other=0.0)
    else:
        q = tl.load(q_ptrs, mask=(offs_m[:, None] < seqlen_q) & (offs_d[None, :] < headdim), other=0.0)
    end_n = seqlen_k if not IS_CAUSAL else tl.minimum((start_m + 1) * BLOCK_M, seqlen_k)
    for start_n in range(0, end_n, BLOCK_N):
        start_n = tl.multiple_of(start_n, BLOCK_N)
        if EVEN_N & EVEN_M:
            if EVEN_HEADDIM:
                k = tl.load(k_ptrs + start_n * stride_kn)
            else:
                k = tl.load(k_ptrs + start_n * stride_kn, mask=offs_d[None, :] < headdim, other=0.0)
        elif EVEN_HEADDIM:
            k = tl.load(k_ptrs + start_n * stride_kn, mask=(start_n + offs_n)[:, None] < seqlen_k, other=0.0)
        else:
            k = tl.load(k_ptrs + start_n * stride_kn, mask=((start_n + offs_n)[:, None] < seqlen_k) & (offs_d[None, :] < headdim), other=0.0)
        qk = tl.zeros([BLOCK_M, BLOCK_N], dtype=tl.float32)
        qk += tl.dot(q, k, trans_b=True)
        if not EVEN_N:
            qk += tl.where((start_n + offs_n)[None, :] < seqlen_k, 0, float('-inf'))
        if IS_CAUSAL:
            qk += tl.where(offs_m[:, None] >= (start_n + offs_n)[None, :], 0, float('-inf'))
        if BIAS_TYPE != 'none':
            if BIAS_TYPE == 'vector':
                if EVEN_N:
                    bias = tl.load(b_ptrs + start_n)
                else:
                    bias = tl.load(b_ptrs + start_n, mask=start_n + offs_n < seqlen_k, other=0.0)
                bias = bias[None, :]
            elif BIAS_TYPE == 'matrix':
                if EVEN_M & EVEN_N:
                    bias = tl.load(b_ptrs + start_n)
                else:
                    bias = tl.load(b_ptrs + start_n, mask=(offs_m[:, None] < seqlen_q) & ((start_n + offs_n)[None, :] < seqlen_k), other=0.0)
            qk = qk * softmax_scale + bias
            m_ij = tl.maximum(tl.max(qk, 1), lse_i)
            p = tl.exp(qk - m_ij[:, None])
        else:
            m_ij = tl.maximum(tl.max(qk, 1) * softmax_scale, lse_i)
            p = tl.exp(qk * softmax_scale - m_ij[:, None])
        l_ij = tl.sum(p, 1)
        acc_o_scale = tl.exp(m_i - m_ij)
        tl.store(t_ptrs, acc_o_scale)
        acc_o_scale = tl.load(t_ptrs)
        acc_o = acc_o * acc_o_scale[:, None]
        if EVEN_N & EVEN_M:
            if EVEN_HEADDIM:
                v = tl.load(v_ptrs + start_n * stride_vn)
            else:
                v = tl.load(v_ptrs + start_n * stride_vn, mask=offs_d[None, :] < headdim, other=0.0)
        elif EVEN_HEADDIM:
            v = tl.load(v_ptrs + start_n * stride_vn, mask=(start_n + offs_n)[:, None] < seqlen_k, other=0.0)
        else:
            v = tl.load(v_ptrs + start_n * stride_vn, mask=((start_n + offs_n)[:, None] < seqlen_k) & (offs_d[None, :] < headdim), other=0.0)
        p = p
        acc_o += tl.dot(p, v)
        m_i = m_ij
        l_i_new = tl.exp(lse_i - m_ij) + l_ij
        lse_i = m_ij + tl.log(l_i_new)
    o_scale = tl.exp(m_i - lse_i)
    tl.store(t_ptrs, o_scale)
    o_scale = tl.load(t_ptrs)
    acc_o = acc_o * o_scale[:, None]
    start_m = tl.program_id(0)
    offs_m = start_m * BLOCK_M + tl.arange(0, BLOCK_M)
    lse_ptrs = Lse + off_hb * seqlen_q_rounded + offs_m
    tl.store(lse_ptrs, lse_i)
    offs_d = tl.arange(0, BLOCK_HEADDIM)
    out_ptrs = Out + off_b * stride_ob + off_h * stride_oh + (offs_m[:, None] * stride_om + offs_d[None, :])
    if EVEN_M:
        if EVEN_HEADDIM:
            tl.store(out_ptrs, acc_o)
        else:
            tl.store(out_ptrs, acc_o, mask=offs_d[None, :] < headdim)
    elif EVEN_HEADDIM:
        tl.store(out_ptrs, acc_o, mask=offs_m[:, None] < seqlen_q)
    else:
        tl.store(out_ptrs, acc_o, mask=(offs_m[:, None] < seqlen_q) & (offs_d[None, :] < headdim))


@triton.jit
def _bwd_preprocess_do_o_dot(Out, DO, Delta, stride_ob, stride_oh, stride_om, stride_dob, stride_doh, stride_dom, nheads, seqlen_q, seqlen_q_rounded, headdim, BLOCK_M: 'tl.constexpr', BLOCK_HEADDIM: 'tl.constexpr'):
    start_m = tl.program_id(0)
    off_hb = tl.program_id(1)
    off_b = off_hb // nheads
    off_h = off_hb % nheads
    offs_m = start_m * BLOCK_M + tl.arange(0, BLOCK_M)
    offs_d = tl.arange(0, BLOCK_HEADDIM)
    o = tl.load(Out + off_b * stride_ob + off_h * stride_oh + offs_m[:, None] * stride_om + offs_d[None, :], mask=(offs_m[:, None] < seqlen_q) & (offs_d[None, :] < headdim), other=0.0)
    do = tl.load(DO + off_b * stride_dob + off_h * stride_doh + offs_m[:, None] * stride_dom + offs_d[None, :], mask=(offs_m[:, None] < seqlen_q) & (offs_d[None, :] < headdim), other=0.0)
    delta = tl.sum(o * do, axis=1)
    tl.store(Delta + off_hb * seqlen_q_rounded + offs_m, delta)


@triton.jit
def _bwd_store_dk_dv(dk_ptrs, dv_ptrs, dk, dv, offs_n, offs_d, seqlen_k, headdim, EVEN_M: 'tl.constexpr', EVEN_N: 'tl.constexpr', EVEN_HEADDIM: 'tl.constexpr'):
    if EVEN_N & EVEN_M:
        if EVEN_HEADDIM:
            tl.store(dv_ptrs, dv)
            tl.store(dk_ptrs, dk)
        else:
            tl.store(dv_ptrs, dv, mask=offs_d[None, :] < headdim)
            tl.store(dk_ptrs, dk, mask=offs_d[None, :] < headdim)
    elif EVEN_HEADDIM:
        tl.store(dv_ptrs, dv, mask=offs_n[:, None] < seqlen_k)
        tl.store(dk_ptrs, dk, mask=offs_n[:, None] < seqlen_k)
    else:
        tl.store(dv_ptrs, dv, mask=(offs_n[:, None] < seqlen_k) & (offs_d[None, :] < headdim))
        tl.store(dk_ptrs, dk, mask=(offs_n[:, None] < seqlen_k) & (offs_d[None, :] < headdim))


@triton.jit
def _bwd_kernel_one_col_block(start_n, Q, K, V, Bias, DO, DQ, DK, DV, LSE, D, softmax_scale, stride_qm, stride_kn, stride_vn, stride_bm, stride_dom, stride_dqm, stride_dkn, stride_dvn, seqlen_q, seqlen_k, headdim, ATOMIC_ADD: 'tl.constexpr', BIAS_TYPE: 'tl.constexpr', IS_CAUSAL: 'tl.constexpr', BLOCK_HEADDIM: 'tl.constexpr', EVEN_M: 'tl.constexpr', EVEN_N: 'tl.constexpr', EVEN_HEADDIM: 'tl.constexpr', BLOCK_M: 'tl.constexpr', BLOCK_N: 'tl.constexpr'):
    begin_m = 0 if not IS_CAUSAL else start_n * BLOCK_N // BLOCK_M * BLOCK_M
    offs_qm = begin_m + tl.arange(0, BLOCK_M)
    offs_n = start_n * BLOCK_N + tl.arange(0, BLOCK_N)
    offs_m = tl.arange(0, BLOCK_M)
    offs_d = tl.arange(0, BLOCK_HEADDIM)
    q_ptrs = Q + (offs_qm[:, None] * stride_qm + offs_d[None, :])
    k_ptrs = K + (offs_n[:, None] * stride_kn + offs_d[None, :])
    v_ptrs = V + (offs_n[:, None] * stride_vn + offs_d[None, :])
    do_ptrs = DO + (offs_qm[:, None] * stride_dom + offs_d[None, :])
    dq_ptrs = DQ + (offs_qm[:, None] * stride_dqm + offs_d[None, :])
    if BIAS_TYPE == 'vector':
        b_ptrs = Bias + offs_n
    elif BIAS_TYPE == 'matrix':
        b_ptrs = Bias + (offs_qm[:, None] * stride_bm + offs_n[None, :])
    dv = tl.zeros([BLOCK_N, BLOCK_HEADDIM], dtype=tl.float32)
    dk = tl.zeros([BLOCK_N, BLOCK_HEADDIM], dtype=tl.float32)
    if begin_m >= seqlen_q:
        dv_ptrs = DV + (offs_n[:, None] * stride_dvn + offs_d[None, :])
        dk_ptrs = DK + (offs_n[:, None] * stride_dkn + offs_d[None, :])
        _bwd_store_dk_dv(dk_ptrs, dv_ptrs, dk, dv, offs_n, offs_d, seqlen_k, headdim, EVEN_M=EVEN_M, EVEN_N=EVEN_N, EVEN_HEADDIM=EVEN_HEADDIM)
        return
    if EVEN_N & EVEN_M:
        if EVEN_HEADDIM:
            k = tl.load(k_ptrs)
            v = tl.load(v_ptrs)
        else:
            k = tl.load(k_ptrs, mask=offs_d[None, :] < headdim, other=0.0)
            v = tl.load(v_ptrs, mask=offs_d[None, :] < headdim, other=0.0)
    elif EVEN_HEADDIM:
        k = tl.load(k_ptrs, mask=offs_n[:, None] < seqlen_k, other=0.0)
        v = tl.load(v_ptrs, mask=offs_n[:, None] < seqlen_k, other=0.0)
    else:
        k = tl.load(k_ptrs, mask=(offs_n[:, None] < seqlen_k) & (offs_d[None, :] < headdim), other=0.0)
        v = tl.load(v_ptrs, mask=(offs_n[:, None] < seqlen_k) & (offs_d[None, :] < headdim), other=0.0)
    num_block_m = tl.cdiv(seqlen_q, BLOCK_M)
    for start_m in range(begin_m, num_block_m * BLOCK_M, BLOCK_M):
        start_m = tl.multiple_of(start_m, BLOCK_M)
        offs_m_curr = start_m + offs_m
        if EVEN_M & EVEN_HEADDIM:
            q = tl.load(q_ptrs)
        elif EVEN_HEADDIM:
            q = tl.load(q_ptrs, mask=offs_m_curr[:, None] < seqlen_q, other=0.0)
        else:
            q = tl.load(q_ptrs, mask=(offs_m_curr[:, None] < seqlen_q) & (offs_d[None, :] < headdim), other=0.0)
        qk = tl.dot(q, k, trans_b=True)
        if not EVEN_N:
            qk = tl.where(offs_n[None, :] < seqlen_k, qk, float('-inf'))
        if IS_CAUSAL:
            qk = tl.where(offs_m_curr[:, None] >= offs_n[None, :], qk, float('-inf'))
        if BIAS_TYPE != 'none':
            tl.debug_barrier()
            if BIAS_TYPE == 'vector':
                if EVEN_N:
                    bias = tl.load(b_ptrs)
                else:
                    bias = tl.load(b_ptrs, mask=offs_n < seqlen_k, other=0.0)
                bias = bias[None, :]
            elif BIAS_TYPE == 'matrix':
                if EVEN_M & EVEN_N:
                    bias = tl.load(b_ptrs)
                else:
                    bias = tl.load(b_ptrs, mask=(offs_m_curr[:, None] < seqlen_q) & (offs_n[None, :] < seqlen_k), other=0.0)
            qk = qk * softmax_scale + bias
        if not EVEN_M & EVEN_HEADDIM:
            tl.debug_barrier()
        lse_i = tl.load(LSE + offs_m_curr)
        if BIAS_TYPE == 'none':
            p = tl.exp(qk * softmax_scale - lse_i[:, None])
        else:
            p = tl.exp(qk - lse_i[:, None])
        if EVEN_M & EVEN_HEADDIM:
            do = tl.load(do_ptrs)
        else:
            do = tl.load(do_ptrs, mask=(offs_m_curr[:, None] < seqlen_q) & (offs_d[None, :] < headdim), other=0.0)
        dv += tl.dot(p, do, trans_a=True)
        if not EVEN_M & EVEN_HEADDIM:
            tl.debug_barrier()
        dp = tl.dot(do, v, trans_b=True)
        if not EVEN_HEADDIM:
            tl.debug_barrier()
        Di = tl.load(D + offs_m_curr)
        ds = p * (dp - Di[:, None]) * softmax_scale
        dk += tl.dot(ds, q, trans_a=True)
        if not EVEN_M & EVEN_HEADDIM:
            tl.debug_barrier()
        if not ATOMIC_ADD:
            if EVEN_M & EVEN_HEADDIM:
                dq = tl.load(dq_ptrs, eviction_policy='evict_last')
                dq += tl.dot(ds, k)
                tl.store(dq_ptrs, dq, eviction_policy='evict_last')
            elif EVEN_HEADDIM:
                dq = tl.load(dq_ptrs, mask=offs_m_curr[:, None] < seqlen_q, other=0.0, eviction_policy='evict_last')
                dq += tl.dot(ds, k)
                tl.store(dq_ptrs, dq, mask=offs_m_curr[:, None] < seqlen_q, eviction_policy='evict_last')
            else:
                dq = tl.load(dq_ptrs, mask=(offs_m_curr[:, None] < seqlen_q) & (offs_d[None, :] < headdim), other=0.0, eviction_policy='evict_last')
                dq += tl.dot(ds, k)
                tl.store(dq_ptrs, dq, mask=(offs_m_curr[:, None] < seqlen_q) & (offs_d[None, :] < headdim), eviction_policy='evict_last')
        else:
            dq = tl.dot(ds, k)
            if EVEN_M & EVEN_HEADDIM:
                tl.atomic_add(dq_ptrs, dq)
            elif EVEN_HEADDIM:
                tl.atomic_add(dq_ptrs, dq, mask=offs_m_curr[:, None] < seqlen_q)
            else:
                tl.atomic_add(dq_ptrs, dq, mask=(offs_m_curr[:, None] < seqlen_q) & (offs_d[None, :] < headdim))
        dq_ptrs += BLOCK_M * stride_dqm
        q_ptrs += BLOCK_M * stride_qm
        do_ptrs += BLOCK_M * stride_dom
        if BIAS_TYPE == 'matrix':
            b_ptrs += BLOCK_M * stride_bm
    dv_ptrs = DV + (offs_n[:, None] * stride_dvn + offs_d[None, :])
    dk_ptrs = DK + (offs_n[:, None] * stride_dkn + offs_d[None, :])
    _bwd_store_dk_dv(dk_ptrs, dv_ptrs, dk, dv, offs_n, offs_d, seqlen_k, headdim, EVEN_M=EVEN_M, EVEN_N=EVEN_N, EVEN_HEADDIM=EVEN_HEADDIM)


def init_to_zero(name):
    return lambda nargs: nargs[name].zero_()


@triton.autotune(configs=[triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'SEQUENCE_PARALLEL': False}, num_warps=8, num_stages=1, pre_hook=init_to_zero('DQ')), triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'SEQUENCE_PARALLEL': True}, num_warps=8, num_stages=1, pre_hook=init_to_zero('DQ'))], key=['CACHE_KEY_SEQLEN_Q', 'CACHE_KEY_SEQLEN_K', 'BIAS_TYPE', 'IS_CAUSAL', 'BLOCK_HEADDIM'])
@triton.heuristics({'EVEN_M': lambda args: args['seqlen_q'] % args['BLOCK_M'] == 0, 'EVEN_N': lambda args: args['seqlen_k'] % args['BLOCK_N'] == 0, 'EVEN_HEADDIM': lambda args: args['headdim'] == args['BLOCK_HEADDIM']})
@triton.jit
def _bwd_kernel(Q, K, V, Bias, DO, DQ, DK, DV, LSE, D, softmax_scale, stride_qb, stride_qh, stride_qm, stride_kb, stride_kh, stride_kn, stride_vb, stride_vh, stride_vn, stride_bb, stride_bh, stride_bm, stride_dob, stride_doh, stride_dom, stride_dqb, stride_dqh, stride_dqm, stride_dkb, stride_dkh, stride_dkn, stride_dvb, stride_dvh, stride_dvn, nheads, seqlen_q, seqlen_k, seqlen_q_rounded, headdim, CACHE_KEY_SEQLEN_Q, CACHE_KEY_SEQLEN_K, BIAS_TYPE: 'tl.constexpr', IS_CAUSAL: 'tl.constexpr', BLOCK_HEADDIM: 'tl.constexpr', SEQUENCE_PARALLEL: 'tl.constexpr', EVEN_M: 'tl.constexpr', EVEN_N: 'tl.constexpr', EVEN_HEADDIM: 'tl.constexpr', BLOCK_M: 'tl.constexpr', BLOCK_N: 'tl.constexpr'):
    off_hb = tl.program_id(1)
    off_b = off_hb // nheads
    off_h = off_hb % nheads
    Q += off_b * stride_qb + off_h * stride_qh
    K += off_b * stride_kb + off_h * stride_kh
    V += off_b * stride_vb + off_h * stride_vh
    DO += off_b * stride_dob + off_h * stride_doh
    DQ += off_b * stride_dqb + off_h * stride_dqh
    DK += off_b * stride_dkb + off_h * stride_dkh
    DV += off_b * stride_dvb + off_h * stride_dvh
    if BIAS_TYPE != 'none':
        Bias += off_b * stride_bb + off_h * stride_bh
    D += off_hb * seqlen_q_rounded
    LSE += off_hb * seqlen_q_rounded
    if not SEQUENCE_PARALLEL:
        num_block_n = tl.cdiv(seqlen_k, BLOCK_N)
        for start_n in range(0, num_block_n):
            _bwd_kernel_one_col_block(start_n, Q, K, V, Bias, DO, DQ, DK, DV, LSE, D, softmax_scale, stride_qm, stride_kn, stride_vn, stride_bm, stride_dom, stride_dqm, stride_dkn, stride_dvn, seqlen_q, seqlen_k, headdim, ATOMIC_ADD=False, BIAS_TYPE=BIAS_TYPE, IS_CAUSAL=IS_CAUSAL, BLOCK_HEADDIM=BLOCK_HEADDIM, EVEN_M=EVEN_M, EVEN_N=EVEN_N, EVEN_HEADDIM=EVEN_HEADDIM, BLOCK_M=BLOCK_M, BLOCK_N=BLOCK_N)
    else:
        start_n = tl.program_id(0)
        _bwd_kernel_one_col_block(start_n, Q, K, V, Bias, DO, DQ, DK, DV, LSE, D, softmax_scale, stride_qm, stride_kn, stride_vn, stride_bm, stride_dom, stride_dqm, stride_dkn, stride_dvn, seqlen_q, seqlen_k, headdim, ATOMIC_ADD=True, BIAS_TYPE=BIAS_TYPE, IS_CAUSAL=IS_CAUSAL, BLOCK_HEADDIM=BLOCK_HEADDIM, EVEN_M=EVEN_M, EVEN_N=EVEN_N, EVEN_HEADDIM=EVEN_HEADDIM, BLOCK_M=BLOCK_M, BLOCK_N=BLOCK_N)

