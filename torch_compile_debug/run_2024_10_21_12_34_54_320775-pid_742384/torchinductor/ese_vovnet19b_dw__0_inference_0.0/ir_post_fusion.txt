op0: SchedulerNode(ComputedBuffer)
op0.writes = [MemoryDep('buf0', 248832*c0 + c1 + 3*c2, {c0: 8, c1: 3, c2: 82944}, None)]
op0.unmet_dependencies = []
op0.met_dependencies = [MemoryDep('arg1_1', c0, {c0: 1990656}, None)]
op0.outputs = [
    buf0: ComputedBuffer
    buf0.layout = FixedLayout('cuda', torch.float32, size=[8, 3, 288, 288], stride=[248832, 1, 864, 3])
    buf0.users = [NodeUser(node=ExternKernelSchedulerNode(name='op2'), can_inplace=False, is_weak=False)]
]
op0.group.device = cuda:0
op0.group.iteration = (1990656, 1)
op0.sizes = ([8, 3, 82944], [])
arg1_1_layout = FixedLayout('cuda', torch.float32, size=[8, 3, 288, 288], stride=[248832, 82944, 288, 1])
buf0_layout = FixedLayout('cuda', torch.float32, size=[8, 3, 288, 288], stride=[248832, 1, 864, 3])
class op0_loop_body:
    var_ranges = {z0: 8, z1: 3, z2: 82944}
    index0 = 248832*z0 + 82944*z1 + z2
    index1 = 248832*z0 + z1 + 3*z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('arg1_1', get_index)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf0', get_index_1, load, None)
        return store


op1: SchedulerNode(ComputedBuffer)
op1.writes = [MemoryDep('buf1', 27*c0 + c1 + 3*c2, {c0: 64, c1: 3, c2: 9}, None)]
op1.unmet_dependencies = []
op1.met_dependencies = [MemoryDep('arg0_1', c0, {c0: 1728}, None)]
op1.outputs = [
    buf1: ComputedBuffer
    buf1.layout = FixedLayout('cuda', torch.float32, size=[64, 3, 3, 3], stride=[27, 1, 9, 3])
    buf1.users = [NodeUser(node=ExternKernelSchedulerNode(name='op2'), can_inplace=False, is_weak=False)]
]
op1.group.device = cuda:0
op1.group.iteration = (1728, 1)
op1.sizes = ([64, 3, 9], [])
arg0_1_layout = FixedLayout('cuda', torch.float32, size=[64, 3, 3, 3], stride=[27, 9, 3, 1])
buf1_layout = FixedLayout('cuda', torch.float32, size=[64, 3, 3, 3], stride=[27, 1, 9, 3])
class op1_loop_body:
    var_ranges = {z0: 64, z1: 3, z2: 9}
    index0 = 27*z0 + 9*z1 + z2
    index1 = 27*z0 + z1 + 3*z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('arg0_1', get_index)
        get_index_1 = self.get_index('index1')
        store = ops.store('buf1', get_index_1, load, None)
        return store


op2: ExternKernelSchedulerNode(ExternKernelAlloc)
op2.writes = [StarDep(name='buf2', mode=None)]
op2.unmet_dependencies = [StarDep(name='buf0', mode=None), StarDep(name='buf1', mode=None)]
op2.met_dependencies = []
op2.outputs = [
    buf2: ExternKernelAlloc
    buf2.layout = FixedLayout('cuda', torch.float32, size=[8, 64, 144, 144], stride=[1327104, 1, 9216, 64])
    buf2.users = [NodeUser(node=SchedulerNode(name='op3'), can_inplace=True, is_weak=False)]
]
op2.node.kernel = extern_kernels.convolution


op3: SchedulerNode(ComputedBuffer)
op3.writes = [MemoryDep('buf3', c0, {c0: 10616832}, None)]
op3.unmet_dependencies = [MemoryDep('buf2', c0, {c0: 10616832}, None)]
op3.met_dependencies = 
    [   MemoryDep('arg2_1', c1, {c0: 165888, c1: 64}, None),
        MemoryDep('arg3_1', c1, {c0: 165888, c1: 64}, None),
        MemoryDep('arg4_1', c1, {c0: 165888, c1: 64}, None),
        MemoryDep('arg5_1', c1, {c0: 165888, c1: 64}, None)]
op3.outputs = [
    buf3: ComputedBuffer
    buf3.layout = FixedLayout('cuda', torch.float32, size=[8, 64, 144, 144], stride=[1327104, 1, 9216, 64])
    buf3.users = [NodeUser(node=ExternKernelSchedulerNode(name='op4'), can_inplace=False, is_weak=False)]
]
op3.group.device = cuda:0
op3.group.iteration = (10616832, 1)
op3.sizes = ([165888, 64], [])
buf2_layout = FixedLayout('cuda', torch.float32, size=[8, 64, 144, 144], stride=[1327104, 1, 9216, 64])
arg2_1_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
arg3_1_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
arg4_1_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
arg5_1_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf3_layout = FixedLayout('cuda', torch.float32, size=[8, 64, 144, 144], stride=[1327104, 1, 9216, 64])
class op3_loop_body:
    var_ranges = {z0: 165888, z1: 64}
    index0 = 64*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf2', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg2_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('arg3_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg4_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('arg5_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf3', get_index_5, relu, None)
        return store


op4: ExternKernelSchedulerNode(ExternKernelAlloc)
op4.writes = [StarDep(name='buf4', mode=None)]
op4.unmet_dependencies = [StarDep(name='buf3', mode=None)]
op4.met_dependencies = [StarDep(name='arg6_1', mode=None)]
op4.outputs = [
    buf4: ExternKernelAlloc
    buf4.layout = FixedLayout('cuda', torch.float32, size=[8, 64, 144, 144], stride=[1327104, 1, 9216, 64])
    buf4.users = [NodeUser(node=ExternKernelSchedulerNode(name='op5'), can_inplace=False, is_weak=False)]
]
op4.node.kernel = extern_kernels.convolution


op5: ExternKernelSchedulerNode(ExternKernelAlloc)
op5.writes = [StarDep(name='buf5', mode=None)]
op5.unmet_dependencies = [StarDep(name='buf4', mode=None)]
op5.met_dependencies = [StarDep(name='arg7_1', mode=None)]
op5.outputs = [
    buf5: ExternKernelAlloc
    buf5.layout = FixedLayout('cuda', torch.float32, size=[8, 64, 144, 144], stride=[1327104, 1, 9216, 64])
    buf5.users = [NodeUser(node=SchedulerNode(name='op6'), can_inplace=True, is_weak=False)]
]
op5.node.kernel = extern_kernels.convolution


op6: SchedulerNode(ComputedBuffer)
op6.writes = [MemoryDep('buf6', c0, {c0: 10616832}, None)]
op6.unmet_dependencies = [MemoryDep('buf5', c0, {c0: 10616832}, None)]
op6.met_dependencies = 
    [   MemoryDep('arg10_1', c1, {c0: 165888, c1: 64}, None),
        MemoryDep('arg11_1', c1, {c0: 165888, c1: 64}, None),
        MemoryDep('arg8_1', c1, {c0: 165888, c1: 64}, None),
        MemoryDep('arg9_1', c1, {c0: 165888, c1: 64}, None)]
op6.outputs = [
    buf6: ComputedBuffer
    buf6.layout = FixedLayout('cuda', torch.float32, size=[8, 64, 144, 144], stride=[1327104, 1, 9216, 64])
    buf6.users = [NodeUser(node=ExternKernelSchedulerNode(name='op7'), can_inplace=False, is_weak=False)]
]
op6.group.device = cuda:0
op6.group.iteration = (10616832, 1)
op6.sizes = ([165888, 64], [])
buf5_layout = FixedLayout('cuda', torch.float32, size=[8, 64, 144, 144], stride=[1327104, 1, 9216, 64])
arg8_1_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
arg9_1_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
arg10_1_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
arg11_1_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf6_layout = FixedLayout('cuda', torch.float32, size=[8, 64, 144, 144], stride=[1327104, 1, 9216, 64])
class op6_loop_body:
    var_ranges = {z0: 165888, z1: 64}
    index0 = 64*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf5', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg8_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('arg9_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg10_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('arg11_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf6', get_index_5, relu, None)
        return store


op7: ExternKernelSchedulerNode(ExternKernelAlloc)
op7.writes = [StarDep(name='buf7', mode=None)]
op7.unmet_dependencies = [StarDep(name='buf6', mode=None)]
op7.met_dependencies = [StarDep(name='arg12_1', mode=None)]
op7.outputs = [
    buf7: ExternKernelAlloc
    buf7.layout = FixedLayout('cuda', torch.float32, size=[8, 64, 72, 72], stride=[331776, 1, 4608, 64])
    buf7.users = [NodeUser(node=ExternKernelSchedulerNode(name='op8'), can_inplace=False, is_weak=False)]
]
op7.node.kernel = extern_kernels.convolution


op8: ExternKernelSchedulerNode(ExternKernelAlloc)
op8.writes = [StarDep(name='buf8', mode=None)]
op8.unmet_dependencies = [StarDep(name='buf7', mode=None)]
op8.met_dependencies = [StarDep(name='arg13_1', mode=None)]
op8.outputs = [
    buf8: ExternKernelAlloc
    buf8.layout = FixedLayout('cuda', torch.float32, size=[8, 64, 72, 72], stride=[331776, 1, 4608, 64])
    buf8.users = [NodeUser(node=SchedulerNode(name='op9'), can_inplace=True, is_weak=False)]
]
op8.node.kernel = extern_kernels.convolution


op9: SchedulerNode(ComputedBuffer)
op9.writes = [MemoryDep('buf9', c0, {c0: 2654208}, None)]
op9.unmet_dependencies = [MemoryDep('buf8', c0, {c0: 2654208}, None)]
op9.met_dependencies = 
    [   MemoryDep('arg14_1', c1, {c0: 41472, c1: 64}, None),
        MemoryDep('arg15_1', c1, {c0: 41472, c1: 64}, None),
        MemoryDep('arg16_1', c1, {c0: 41472, c1: 64}, None),
        MemoryDep('arg17_1', c1, {c0: 41472, c1: 64}, None)]
op9.outputs = [
    buf9: ComputedBuffer
    buf9.layout = FixedLayout('cuda', torch.float32, size=[8, 64, 72, 72], stride=[331776, 1, 4608, 64])
    buf9.users = [
        NodeUser(node=ExternKernelSchedulerNode(name='op10'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op20'), can_inplace=False, is_weak=False),
    ]
]
op9.group.device = cuda:0
op9.group.iteration = (2654208, 1)
op9.sizes = ([41472, 64], [])
buf8_layout = FixedLayout('cuda', torch.float32, size=[8, 64, 72, 72], stride=[331776, 1, 4608, 64])
arg14_1_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
arg15_1_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
arg16_1_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
arg17_1_layout = FixedLayout('cuda', torch.float32, size=[64], stride=[1])
buf9_layout = FixedLayout('cuda', torch.float32, size=[8, 64, 72, 72], stride=[331776, 1, 4608, 64])
class op9_loop_body:
    var_ranges = {z0: 41472, z1: 64}
    index0 = 64*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf8', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg14_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('arg15_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg16_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('arg17_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf9', get_index_5, relu, None)
        return store


op10: ExternKernelSchedulerNode(ExternKernelAlloc)
op10.writes = [StarDep(name='buf10', mode=None)]
op10.unmet_dependencies = [StarDep(name='buf9', mode=None)]
op10.met_dependencies = [StarDep(name='arg18_1', mode=None)]
op10.outputs = [
    buf10: ExternKernelAlloc
    buf10.layout = FixedLayout('cuda', torch.float32, size=[8, 128, 72, 72], stride=[663552, 1, 9216, 128])
    buf10.users = [NodeUser(node=SchedulerNode(name='op11'), can_inplace=True, is_weak=False)]
]
op10.node.kernel = extern_kernels.convolution


op11: SchedulerNode(ComputedBuffer)
op11.writes = [MemoryDep('buf11', c0, {c0: 5308416}, None)]
op11.unmet_dependencies = [MemoryDep('buf10', c0, {c0: 5308416}, None)]
op11.met_dependencies = 
    [   MemoryDep('arg19_1', c1, {c0: 41472, c1: 128}, None),
        MemoryDep('arg20_1', c1, {c0: 41472, c1: 128}, None),
        MemoryDep('arg21_1', c1, {c0: 41472, c1: 128}, None),
        MemoryDep('arg22_1', c1, {c0: 41472, c1: 128}, None)]
op11.outputs = [
    buf11: ComputedBuffer
    buf11.layout = FixedLayout('cuda', torch.float32, size=[8, 128, 72, 72], stride=[663552, 1, 9216, 128])
    buf11.users = [NodeUser(node=ExternKernelSchedulerNode(name='op12'), can_inplace=False, is_weak=False)]
]
op11.group.device = cuda:0
op11.group.iteration = (5308416, 1)
op11.sizes = ([41472, 128], [])
buf10_layout = FixedLayout('cuda', torch.float32, size=[8, 128, 72, 72], stride=[663552, 1, 9216, 128])
arg19_1_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
arg20_1_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
arg21_1_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
arg22_1_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf11_layout = FixedLayout('cuda', torch.float32, size=[8, 128, 72, 72], stride=[663552, 1, 9216, 128])
class op11_loop_body:
    var_ranges = {z0: 41472, z1: 128}
    index0 = 128*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf10', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg19_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('arg20_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg21_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('arg22_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf11', get_index_5, relu, None)
        return store


op12: ExternKernelSchedulerNode(ExternKernelAlloc)
op12.writes = [StarDep(name='buf12', mode=None)]
op12.unmet_dependencies = [StarDep(name='buf11', mode=None)]
op12.met_dependencies = [StarDep(name='arg23_1', mode=None)]
op12.outputs = [
    buf12: ExternKernelAlloc
    buf12.layout = FixedLayout('cuda', torch.float32, size=[8, 128, 72, 72], stride=[663552, 1, 9216, 128])
    buf12.users = [NodeUser(node=ExternKernelSchedulerNode(name='op13'), can_inplace=False, is_weak=False)]
]
op12.node.kernel = extern_kernels.convolution


op13: ExternKernelSchedulerNode(ExternKernelAlloc)
op13.writes = [StarDep(name='buf13', mode=None)]
op13.unmet_dependencies = [StarDep(name='buf12', mode=None)]
op13.met_dependencies = [StarDep(name='arg24_1', mode=None)]
op13.outputs = [
    buf13: ExternKernelAlloc
    buf13.layout = FixedLayout('cuda', torch.float32, size=[8, 128, 72, 72], stride=[663552, 1, 9216, 128])
    buf13.users = [NodeUser(node=SchedulerNode(name='op14'), can_inplace=True, is_weak=False)]
]
op13.node.kernel = extern_kernels.convolution


op14: SchedulerNode(ComputedBuffer)
op14.writes = [MemoryDep('buf14', c0, {c0: 5308416}, None)]
op14.unmet_dependencies = [MemoryDep('buf13', c0, {c0: 5308416}, None)]
op14.met_dependencies = 
    [   MemoryDep('arg25_1', c1, {c0: 41472, c1: 128}, None),
        MemoryDep('arg26_1', c1, {c0: 41472, c1: 128}, None),
        MemoryDep('arg27_1', c1, {c0: 41472, c1: 128}, None),
        MemoryDep('arg28_1', c1, {c0: 41472, c1: 128}, None)]
op14.outputs = [
    buf14: ComputedBuffer
    buf14.layout = FixedLayout('cuda', torch.float32, size=[8, 128, 72, 72], stride=[663552, 1, 9216, 128])
    buf14.users = [
        NodeUser(node=ExternKernelSchedulerNode(name='op15'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op20'), can_inplace=False, is_weak=False),
    ]
]
op14.group.device = cuda:0
op14.group.iteration = (5308416, 1)
op14.sizes = ([41472, 128], [])
buf13_layout = FixedLayout('cuda', torch.float32, size=[8, 128, 72, 72], stride=[663552, 1, 9216, 128])
arg25_1_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
arg26_1_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
arg27_1_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
arg28_1_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf14_layout = FixedLayout('cuda', torch.float32, size=[8, 128, 72, 72], stride=[663552, 1, 9216, 128])
class op14_loop_body:
    var_ranges = {z0: 41472, z1: 128}
    index0 = 128*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf13', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg25_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('arg26_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg27_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('arg28_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf14', get_index_5, relu, None)
        return store


op15: ExternKernelSchedulerNode(ExternKernelAlloc)
op15.writes = [StarDep(name='buf15', mode=None)]
op15.unmet_dependencies = [StarDep(name='buf14', mode=None)]
op15.met_dependencies = [StarDep(name='arg29_1', mode=None)]
op15.outputs = [
    buf15: ExternKernelAlloc
    buf15.layout = FixedLayout('cuda', torch.float32, size=[8, 128, 72, 72], stride=[663552, 1, 9216, 128])
    buf15.users = [NodeUser(node=ExternKernelSchedulerNode(name='op16'), can_inplace=False, is_weak=False)]
]
op15.node.kernel = extern_kernels.convolution


op16: ExternKernelSchedulerNode(ExternKernelAlloc)
op16.writes = [StarDep(name='buf16', mode=None)]
op16.unmet_dependencies = [StarDep(name='buf15', mode=None)]
op16.met_dependencies = [StarDep(name='arg30_1', mode=None)]
op16.outputs = [
    buf16: ExternKernelAlloc
    buf16.layout = FixedLayout('cuda', torch.float32, size=[8, 128, 72, 72], stride=[663552, 1, 9216, 128])
    buf16.users = [NodeUser(node=SchedulerNode(name='op17'), can_inplace=True, is_weak=False)]
]
op16.node.kernel = extern_kernels.convolution


op17: SchedulerNode(ComputedBuffer)
op17.writes = [MemoryDep('buf17', c0, {c0: 5308416}, None)]
op17.unmet_dependencies = [MemoryDep('buf16', c0, {c0: 5308416}, None)]
op17.met_dependencies = 
    [   MemoryDep('arg31_1', c1, {c0: 41472, c1: 128}, None),
        MemoryDep('arg32_1', c1, {c0: 41472, c1: 128}, None),
        MemoryDep('arg33_1', c1, {c0: 41472, c1: 128}, None),
        MemoryDep('arg34_1', c1, {c0: 41472, c1: 128}, None)]
op17.outputs = [
    buf17: ComputedBuffer
    buf17.layout = FixedLayout('cuda', torch.float32, size=[8, 128, 72, 72], stride=[663552, 1, 9216, 128])
    buf17.users = [
        NodeUser(node=ExternKernelSchedulerNode(name='op18'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op20'), can_inplace=False, is_weak=False),
    ]
]
op17.group.device = cuda:0
op17.group.iteration = (5308416, 1)
op17.sizes = ([41472, 128], [])
buf16_layout = FixedLayout('cuda', torch.float32, size=[8, 128, 72, 72], stride=[663552, 1, 9216, 128])
arg31_1_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
arg32_1_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
arg33_1_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
arg34_1_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf17_layout = FixedLayout('cuda', torch.float32, size=[8, 128, 72, 72], stride=[663552, 1, 9216, 128])
class op17_loop_body:
    var_ranges = {z0: 41472, z1: 128}
    index0 = 128*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf16', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg31_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('arg32_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg33_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('arg34_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf17', get_index_5, relu, None)
        return store


op18: ExternKernelSchedulerNode(ExternKernelAlloc)
op18.writes = [StarDep(name='buf18', mode=None)]
op18.unmet_dependencies = [StarDep(name='buf17', mode=None)]
op18.met_dependencies = [StarDep(name='arg35_1', mode=None)]
op18.outputs = [
    buf18: ExternKernelAlloc
    buf18.layout = FixedLayout('cuda', torch.float32, size=[8, 128, 72, 72], stride=[663552, 1, 9216, 128])
    buf18.users = [NodeUser(node=ExternKernelSchedulerNode(name='op19'), can_inplace=False, is_weak=False)]
]
op18.node.kernel = extern_kernels.convolution


op19: ExternKernelSchedulerNode(ExternKernelAlloc)
op19.writes = [StarDep(name='buf19', mode=None)]
op19.unmet_dependencies = [StarDep(name='buf18', mode=None)]
op19.met_dependencies = [StarDep(name='arg36_1', mode=None)]
op19.outputs = [
    buf19: ExternKernelAlloc
    buf19.layout = FixedLayout('cuda', torch.float32, size=[8, 128, 72, 72], stride=[663552, 1, 9216, 128])
    buf19.users = [NodeUser(node=SchedulerNode(name='op20'), can_inplace=False, is_weak=False)]
]
op19.node.kernel = extern_kernels.convolution


op20: SchedulerNode(ComputedBuffer)
op20.writes = [MemoryDep('buf20', c0, {c0: 18579456}, None)]
op20.unmet_dependencies = 
    [   MemoryDep('buf14', 128*c0 + I, {c0: 41472, c1: 448}, None),
        MemoryDep('buf17', 128*c0 + I, {c0: 41472, c1: 448}, None),
        MemoryDep('buf19', 128*c0 + I, {c0: 41472, c1: 448}, None),
        MemoryDep('buf9', 64*c0 + I, {c0: 41472, c1: 448}, None)]
op20.met_dependencies = 
    [   MemoryDep('arg37_1', I, {c0: 41472, c1: 448}, None),
        MemoryDep('arg38_1', I, {c0: 41472, c1: 448}, None),
        MemoryDep('arg39_1', I, {c0: 41472, c1: 448}, None),
        MemoryDep('arg40_1', I, {c0: 41472, c1: 448}, None)]
op20.outputs = [
    buf20: ComputedBuffer
    buf20.layout = FixedLayout('cuda', torch.float32, size=[8, 448, 72, 72], stride=[2322432, 1, 32256, 448])
    buf20.users = [NodeUser(node=ExternKernelSchedulerNode(name='op21'), can_inplace=False, is_weak=False)]
]
op20.group.device = cuda:0
op20.group.iteration = (18579456, 1)
op20.sizes = ([41472, 448], [])
buf9_layout = FixedLayout('cuda', torch.float32, size=[8, 64, 72, 72], stride=[331776, 1, 4608, 64])
buf14_layout = FixedLayout('cuda', torch.float32, size=[8, 128, 72, 72], stride=[663552, 1, 9216, 128])
buf17_layout = FixedLayout('cuda', torch.float32, size=[8, 128, 72, 72], stride=[663552, 1, 9216, 128])
buf19_layout = FixedLayout('cuda', torch.float32, size=[8, 128, 72, 72], stride=[663552, 1, 9216, 128])
arg37_1_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
arg38_1_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
arg39_1_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
arg40_1_layout = FixedLayout('cuda', torch.float32, size=[128], stride=[1])
buf20_layout = FixedLayout('cuda', torch.float32, size=[8, 448, 72, 72], stride=[2322432, 1, 32256, 448])
class op20_loop_body:
    var_ranges = {z0: 41472, z1: 448}
    index0 = z1
    index1 = 64*z0 + I
    index2 = 128*z0 + I
    index3 = 128*z0 + I
    index4 = 128*z0 + I
    index5 = I
    index6 = 448*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int64)
        constant = ops.constant(0, torch.int64)
        ge = ops.ge(index_expr, constant)
        get_index_1 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_1, torch.int64)
        constant_1 = ops.constant(64, torch.int64)
        lt = ops.lt(index_expr_1, constant_1)
        masked_subblock1 = self.masked_subblock1(lt, 0.0)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        constant_2 = ops.constant(64, torch.int64)
        ge_1 = ops.ge(index_expr_2, constant_2)
        get_index_3 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        constant_3 = ops.constant(192, torch.int64)
        lt_1 = ops.lt(index_expr_3, constant_3)
        and_ = ops.and_(ge_1, lt_1)
        masked_subblock2 = self.masked_subblock2(and_, 0.0)
        get_index_4 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_4, torch.int64)
        constant_4 = ops.constant(192, torch.int64)
        ge_2 = ops.ge(index_expr_4, constant_4)
        get_index_5 = self.get_index('index0')
        index_expr_5 = ops.index_expr(get_index_5, torch.int64)
        constant_5 = ops.constant(320, torch.int64)
        lt_2 = ops.lt(index_expr_5, constant_5)
        and__1 = ops.and_(ge_2, lt_2)
        masked_subblock3 = self.masked_subblock3(and__1, 0.0)
        get_index_6 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_6, torch.int64)
        constant_6 = ops.constant(320, torch.int64)
        ge_3 = ops.ge(index_expr_6, constant_6)
        get_index_7 = self.get_index('index0')
        index_expr_7 = ops.index_expr(get_index_7, torch.int64)
        constant_7 = ops.constant(448, torch.int64)
        lt_3 = ops.lt(index_expr_7, constant_7)
        masked_subblock4 = self.masked_subblock4(ge_3, 0.0)
        where = ops.where(and__1, masked_subblock3, masked_subblock4)
        where_1 = ops.where(and_, masked_subblock2, where)
        where_2 = ops.where(lt, masked_subblock1, where_1)
        get_index_8 = self.get_index('index6')
        store = ops.store('buf20', get_index_8, where_2, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('buf9', get_index)
        return load
    def masked_subblock2(self, ops):
        get_index = self.get_index('index2')
        load = ops.load('buf14', get_index)
        return load
    def masked_subblock3(self, ops):
        get_index = self.get_index('index3')
        load = ops.load('buf17', get_index)
        return load
    def masked_subblock4(self, ops):
        get_index = self.get_index('index4')
        load = ops.load('buf19', get_index)
        get_index_1 = self.get_index('index5')
        load_1 = ops.load('arg37_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index5')
        load_2 = ops.load('arg38_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index5')
        load_3 = ops.load('arg39_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index5')
        load_4 = ops.load('arg40_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        return relu


op21: ExternKernelSchedulerNode(ExternKernelAlloc)
op21.writes = [StarDep(name='buf21', mode=None)]
op21.unmet_dependencies = [StarDep(name='buf20', mode=None)]
op21.met_dependencies = [StarDep(name='arg41_1', mode=None)]
op21.outputs = [
    buf21: ExternKernelAlloc
    buf21.layout = FixedLayout('cuda', torch.float32, size=[8, 256, 72, 72], stride=[1327104, 1, 18432, 256])
    buf21.users = [NodeUser(node=SchedulerNode(name='op22'), can_inplace=True, is_weak=False)]
]
op21.node.kernel = extern_kernels.convolution


op22: SchedulerNode(ComputedBuffer)
op22.writes = [MemoryDep('buf22', c0, {c0: 10616832}, None)]
op22.unmet_dependencies = [MemoryDep('buf21', c0, {c0: 10616832}, None)]
op22.met_dependencies = 
    [   MemoryDep('arg42_1', c1, {c0: 41472, c1: 256}, None),
        MemoryDep('arg43_1', c1, {c0: 41472, c1: 256}, None),
        MemoryDep('arg44_1', c1, {c0: 41472, c1: 256}, None),
        MemoryDep('arg45_1', c1, {c0: 41472, c1: 256}, None)]
op22.outputs = [
    buf22: ComputedBuffer
    buf22.layout = FixedLayout('cuda', torch.float32, size=[8, 256, 72, 72], stride=[1327104, 1, 18432, 256])
    buf22.users = [
        NodeUser(node=SchedulerNode(name='op23'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op27'), can_inplace=True, is_weak=False),
    ]
]
op22.group.device = cuda:0
op22.group.iteration = (10616832, 1)
op22.sizes = ([41472, 256], [])
buf21_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 72, 72], stride=[1327104, 1, 18432, 256])
arg42_1_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
arg43_1_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
arg44_1_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
arg45_1_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf22_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 72, 72], stride=[1327104, 1, 18432, 256])
class op22_loop_body:
    var_ranges = {z0: 41472, z1: 256}
    index0 = 256*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf21', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg42_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('arg43_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg44_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('arg45_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf22', get_index_5, relu, None)
        return store


op23: SchedulerNode(ComputedBuffer)
op23.writes = [MemoryDep('buf23', c0, {c0: 83968}, None)]
op23.unmet_dependencies = [   MemoryDep('buf22', 1327104*c0 + c2 + 256*ModularIndexing(127*c1 + c3, 1, 5184), {c0: 8, c1: 41, c2: 256, c3: 127}, None)]
op23.met_dependencies = []
op23.outputs = [
    buf23: ComputedBuffer
    buf23.layout = FixedLayout('cuda', torch.float32, size=[8, 256, 1, 1, 41], stride=[10496, 1, 83968, 83968, 256])
    buf23.users = [NodeUser(node=SchedulerNode(name='op24'), can_inplace=False, is_weak=False)]
]
op23.group.device = cuda:0
op23.group.iteration = (83968, 127)
op23.sizes = ([8, 41, 256], [127])
buf22_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 72, 72], stride=[1327104, 1, 18432, 256])
buf23_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 1, 1, 41], stride=[10496, 1, 83968, 83968, 256])
class op23_loop_body:
    var_ranges = {z0: 8, z1: 41, z2: 256, z3: 127}
    index0 = 127*z1 + z3
    index1 = 1327104*z0 + z2 + 256*ModularIndexing(127*z1 + z3, 1, 5184)
    index2 = 10496*z0 + 256*z1 + z2
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(5184, torch.int32)
        lt = ops.lt(index_expr, constant)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', masked_subblock1)
        get_index_1 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf23', get_index_1, reduction)
        return store_reduction
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('buf22', get_index)
        return load


op24_op25: FusedSchedulerNode(SchedulerNode,SchedulerNode)
op24_op25.writes = 
    [   MemoryDep('buf24', c0, {c0: 2048}, None),
        MemoryDep('buf25', c0, {c0: 2048}, None)]
op24_op25.unmet_dependencies = [MemoryDep('buf23', 10496*c0 + c1 + 256*c2, {c0: 8, c1: 256, c2: 41}, None)]
op24_op25.met_dependencies = []
op24_op25.outputs = [
    buf24: ComputedBuffer
    buf24.layout = FixedLayout('cuda', torch.float32, size=[8, 256, 1, 1], stride=[256, 1, 2048, 2048])
    buf24.users = [NodeUser(node=SchedulerNode(name='op25'), can_inplace=True, is_weak=False)]
    buf25: ComputedBuffer
    buf25.layout = FixedLayout('cuda', torch.float32, size=[8, 256, 1, 1], stride=[256, 1, 1, 1])
    buf25.users = [NodeUser(node=ExternKernelSchedulerNode(name='op26'), can_inplace=False, is_weak=False)]
]
op24_op25.snodes[0] =
op24: SchedulerNode(ComputedBuffer)
op24.writes = [MemoryDep('buf24', c0, {c0: 2048}, None)]
op24.unmet_dependencies = [MemoryDep('buf23', 10496*c0 + c1 + 256*c2, {c0: 8, c1: 256, c2: 41}, None)]
op24.met_dependencies = []
op24.outputs = [
    buf24: ComputedBuffer
    buf24.layout = FixedLayout('cuda', torch.float32, size=[8, 256, 1, 1], stride=[256, 1, 2048, 2048])
    buf24.users = [NodeUser(node=SchedulerNode(name='op25'), can_inplace=True, is_weak=False)]
]
op24.group.device = cuda:0
op24.group.iteration = (2048, 41)
op24.sizes = ([8, 256], [41])
buf23_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 1, 1, 41], stride=[10496, 1, 83968, 83968, 256])
buf24_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 1, 1], stride=[256, 1, 2048, 2048])
class op24_loop_body:
    var_ranges = {z0: 8, z1: 256, z2: 41}
    index0 = 10496*z0 + z1 + 256*z2
    index1 = 256*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf23', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf24', get_index_1, reduction)
        return store_reduction
op24_op25.snodes[1] =
op25: SchedulerNode(ComputedBuffer)
op25.writes = [MemoryDep('buf25', c0, {c0: 2048}, None)]
op25.unmet_dependencies = [MemoryDep('buf24', c0, {c0: 2048}, None)]
op25.met_dependencies = []
op25.outputs = [
    buf25: ComputedBuffer
    buf25.layout = FixedLayout('cuda', torch.float32, size=[8, 256, 1, 1], stride=[256, 1, 1, 1])
    buf25.users = [NodeUser(node=ExternKernelSchedulerNode(name='op26'), can_inplace=False, is_weak=False)]
]
op25.group.device = cuda:0
op25.group.iteration = (2048, 1)
op25.sizes = ([2048], [])
buf24_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 1, 1], stride=[256, 1, 2048, 2048])
buf25_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 1, 1], stride=[256, 1, 1, 1])
class op25_loop_body:
    var_ranges = {z0: 2048}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf24', get_index)
        constant = ops.constant(5184.0, torch.float32)
        truediv = ops.truediv(load, constant)
        get_index_1 = self.get_index('index0')
        store = ops.store('buf25', get_index_1, truediv, None)
        return store


op26: ExternKernelSchedulerNode(ExternKernelAlloc)
op26.writes = [StarDep(name='buf26', mode=None)]
op26.unmet_dependencies = [StarDep(name='buf25', mode=None)]
op26.met_dependencies = [StarDep(name='arg46_1', mode=None)]
op26.outputs = [
    buf26: ExternKernelAlloc
    buf26.layout = FixedLayout('cuda', torch.float32, size=[8, 256, 1, 1], stride=[256, 1, 1, 1])
    buf26.users = [NodeUser(node=SchedulerNode(name='op27'), can_inplace=False, is_weak=False)]
]
op26.node.kernel = extern_kernels.convolution


op27: SchedulerNode(ComputedBuffer)
op27.writes = [MemoryDep('buf27', c0, {c0: 10616832}, None)]
op27.unmet_dependencies = 
    [   MemoryDep('buf22', c0, {c0: 10616832}, None),
        MemoryDep('buf26', 256*c0 + c2, {c0: 8, c1: 5184, c2: 256}, None)]
op27.met_dependencies = [MemoryDep('arg47_1', c1, {c0: 41472, c1: 256}, None)]
op27.outputs = [
    buf27: ComputedBuffer
    buf27.layout = FixedLayout('cuda', torch.float32, size=[8, 256, 72, 72], stride=[1327104, 1, 18432, 256])
    buf27.users = [NodeUser(node=SchedulerNode(name='op28'), can_inplace=False, is_weak=False)]
]
op27.group.device = cuda:0
op27.group.iteration = (10616832, 1)
op27.sizes = ([8, 5184, 256], [])
buf22_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 72, 72], stride=[1327104, 1, 18432, 256])
buf26_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 1, 1], stride=[256, 1, 1, 1])
arg47_1_layout = FixedLayout('cuda', torch.float32, size=[256], stride=[1])
buf27_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 72, 72], stride=[1327104, 1, 18432, 256])
class op27_loop_body:
    var_ranges = {z0: 8, z1: 5184, z2: 256}
    index0 = 1327104*z0 + 256*z1 + z2
    index1 = 256*z0 + z2
    index2 = z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf22', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf26', get_index_1)
        get_index_2 = self.get_index('index2')
        load_2 = ops.load('arg47_1', get_index_2)
        add = ops.add(load_1, load_2)
        constant = ops.constant(3.0, torch.float32)
        add_1 = ops.add(add, constant)
        constant_1 = ops.constant(0.0, torch.float32)
        maximum = ops.maximum(add_1, constant_1)
        constant_2 = ops.constant(6.0, torch.float32)
        minimum = ops.minimum(maximum, constant_2)
        constant_3 = ops.constant(0.16666666666666666, torch.float32)
        mul = ops.mul(minimum, constant_3)
        mul_1 = ops.mul(load, mul)
        get_index_3 = self.get_index('index0')
        store = ops.store('buf27', get_index_3, mul_1, None)
        return store


op28: SchedulerNode(ComputedBuffer)
op28.writes = [MemoryDep('buf28', c0, {c0: 2654208}, None)]
op28.unmet_dependencies = 
    [   MemoryDep('buf27', 36864*c0 + 512*c1 + c2 + 18432, {c0: 288, c1: 36, c2: 256}, None),
        MemoryDep('buf27', 36864*c0 + 512*c1 + c2 + 18688, {c0: 288, c1: 36, c2: 256}, None),
        MemoryDep('buf27', 36864*c0 + 512*c1 + c2 + 18944, {c0: 288, c1: 36, c2: 256}, None),
        MemoryDep('buf27', 36864*c0 + 512*c1 + c2 + 256, {c0: 288, c1: 36, c2: 256}, None),
        MemoryDep('buf27', 36864*c0 + 512*c1 + c2 + 36864, {c0: 288, c1: 36, c2: 256}, None),
        MemoryDep('buf27', 36864*c0 + 512*c1 + c2 + 37120, {c0: 288, c1: 36, c2: 256}, None),
        MemoryDep('buf27', 36864*c0 + 512*c1 + c2 + 37376, {c0: 288, c1: 36, c2: 256}, None),
        MemoryDep('buf27', 36864*c0 + 512*c1 + c2 + 512, {c0: 288, c1: 36, c2: 256}, None),
        MemoryDep('buf27', 36864*c0 + 512*c1 + c2, {c0: 288, c1: 36, c2: 256}, None)]
op28.met_dependencies = []
op28.outputs = [
    buf28: ComputedBuffer
    buf28.layout = FixedLayout('cuda', torch.float32, size=[8, 256, 36, 36], stride=[331776, 1, 9216, 256])
    buf28.users = [
        NodeUser(node=ExternKernelSchedulerNode(name='op29'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op39'), can_inplace=False, is_weak=False),
    ]
]
op28.group.device = cuda:0
op28.group.iteration = (2654208, 1)
op28.sizes = ([8, 36, 36, 256], [])
buf27_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 72, 72], stride=[1327104, 1, 18432, 256])
buf27_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 72, 72], stride=[1327104, 1, 18432, 256])
buf27_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 72, 72], stride=[1327104, 1, 18432, 256])
buf27_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 72, 72], stride=[1327104, 1, 18432, 256])
buf27_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 72, 72], stride=[1327104, 1, 18432, 256])
buf27_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 72, 72], stride=[1327104, 1, 18432, 256])
buf27_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 72, 72], stride=[1327104, 1, 18432, 256])
buf27_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 72, 72], stride=[1327104, 1, 18432, 256])
buf27_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 72, 72], stride=[1327104, 1, 18432, 256])
buf28_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 36, 36], stride=[331776, 1, 9216, 256])
class op28_loop_body:
    var_ranges = {z0: 8, z1: 36, z2: 36, z3: 256}
    index0 = 2*z1
    index1 = 2*z2
    index2 = 1327104*z0 + 36864*z1 + 512*z2 + z3
    index3 = 2*z2 + 1
    index4 = 1327104*z0 + 36864*z1 + 512*z2 + z3 + 256
    index5 = 2*z2 + 2
    index6 = 1327104*z0 + 36864*z1 + 512*z2 + z3 + 512
    index7 = 2*z1 + 1
    index8 = 1327104*z0 + 36864*z1 + 512*z2 + z3 + 18432
    index9 = 1327104*z0 + 36864*z1 + 512*z2 + z3 + 18688
    index10 = 1327104*z0 + 36864*z1 + 512*z2 + z3 + 18944
    index11 = 2*z1 + 2
    index12 = 1327104*z0 + 36864*z1 + 512*z2 + z3 + 36864
    index13 = 1327104*z0 + 36864*z1 + 512*z2 + z3 + 37120
    index14 = 1327104*z0 + 36864*z1 + 512*z2 + z3 + 37376
    index15 = 331776*z0 + 9216*z1 + 256*z2 + z3
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int64)
        constant = ops.constant(0, torch.int64)
        ge = ops.ge(index_expr, constant)
        get_index_1 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_1, torch.int64)
        constant_1 = ops.constant(72, torch.int64)
        lt = ops.lt(index_expr_1, constant_1)
        and_ = ops.and_(ge, lt)
        get_index_2 = self.get_index('index1')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        constant_2 = ops.constant(0, torch.int64)
        ge_1 = ops.ge(index_expr_2, constant_2)
        get_index_3 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        constant_3 = ops.constant(72, torch.int64)
        lt_1 = ops.lt(index_expr_3, constant_3)
        and__1 = ops.and_(ge_1, lt_1)
        and__2 = ops.and_(and_, and__1)
        masked_subblock1 = self.masked_subblock1(and__2, -inf)
        get_index_4 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_4, torch.int64)
        constant_4 = ops.constant(0, torch.int64)
        ge_2 = ops.ge(index_expr_4, constant_4)
        get_index_5 = self.get_index('index0')
        index_expr_5 = ops.index_expr(get_index_5, torch.int64)
        constant_5 = ops.constant(72, torch.int64)
        lt_2 = ops.lt(index_expr_5, constant_5)
        and__3 = ops.and_(ge_2, lt_2)
        get_index_6 = self.get_index('index3')
        index_expr_6 = ops.index_expr(get_index_6, torch.int64)
        constant_6 = ops.constant(0, torch.int64)
        ge_3 = ops.ge(index_expr_6, constant_6)
        get_index_7 = self.get_index('index3')
        index_expr_7 = ops.index_expr(get_index_7, torch.int64)
        constant_7 = ops.constant(72, torch.int64)
        lt_3 = ops.lt(index_expr_7, constant_7)
        and__4 = ops.and_(ge_3, lt_3)
        and__5 = ops.and_(and__3, and__4)
        masked_subblock2 = self.masked_subblock2(and__5, -inf)
        maximum = ops.maximum(masked_subblock2, masked_subblock1)
        get_index_8 = self.get_index('index0')
        index_expr_8 = ops.index_expr(get_index_8, torch.int64)
        constant_8 = ops.constant(0, torch.int64)
        ge_4 = ops.ge(index_expr_8, constant_8)
        get_index_9 = self.get_index('index0')
        index_expr_9 = ops.index_expr(get_index_9, torch.int64)
        constant_9 = ops.constant(72, torch.int64)
        lt_4 = ops.lt(index_expr_9, constant_9)
        and__6 = ops.and_(ge_4, lt_4)
        get_index_10 = self.get_index('index5')
        index_expr_10 = ops.index_expr(get_index_10, torch.int64)
        constant_10 = ops.constant(0, torch.int64)
        ge_5 = ops.ge(index_expr_10, constant_10)
        get_index_11 = self.get_index('index5')
        index_expr_11 = ops.index_expr(get_index_11, torch.int64)
        constant_11 = ops.constant(72, torch.int64)
        lt_5 = ops.lt(index_expr_11, constant_11)
        and__7 = ops.and_(ge_5, lt_5)
        and__8 = ops.and_(and__6, and__7)
        masked_subblock3 = self.masked_subblock3(and__8, -inf)
        maximum_1 = ops.maximum(masked_subblock3, maximum)
        get_index_12 = self.get_index('index7')
        index_expr_12 = ops.index_expr(get_index_12, torch.int64)
        constant_12 = ops.constant(0, torch.int64)
        ge_6 = ops.ge(index_expr_12, constant_12)
        get_index_13 = self.get_index('index7')
        index_expr_13 = ops.index_expr(get_index_13, torch.int64)
        constant_13 = ops.constant(72, torch.int64)
        lt_6 = ops.lt(index_expr_13, constant_13)
        and__9 = ops.and_(ge_6, lt_6)
        get_index_14 = self.get_index('index1')
        index_expr_14 = ops.index_expr(get_index_14, torch.int64)
        constant_14 = ops.constant(0, torch.int64)
        ge_7 = ops.ge(index_expr_14, constant_14)
        get_index_15 = self.get_index('index1')
        index_expr_15 = ops.index_expr(get_index_15, torch.int64)
        constant_15 = ops.constant(72, torch.int64)
        lt_7 = ops.lt(index_expr_15, constant_15)
        and__10 = ops.and_(ge_7, lt_7)
        and__11 = ops.and_(and__9, and__10)
        masked_subblock4 = self.masked_subblock4(and__11, -inf)
        maximum_2 = ops.maximum(masked_subblock4, maximum_1)
        get_index_16 = self.get_index('index7')
        index_expr_16 = ops.index_expr(get_index_16, torch.int64)
        constant_16 = ops.constant(0, torch.int64)
        ge_8 = ops.ge(index_expr_16, constant_16)
        get_index_17 = self.get_index('index7')
        index_expr_17 = ops.index_expr(get_index_17, torch.int64)
        constant_17 = ops.constant(72, torch.int64)
        lt_8 = ops.lt(index_expr_17, constant_17)
        and__12 = ops.and_(ge_8, lt_8)
        get_index_18 = self.get_index('index3')
        index_expr_18 = ops.index_expr(get_index_18, torch.int64)
        constant_18 = ops.constant(0, torch.int64)
        ge_9 = ops.ge(index_expr_18, constant_18)
        get_index_19 = self.get_index('index3')
        index_expr_19 = ops.index_expr(get_index_19, torch.int64)
        constant_19 = ops.constant(72, torch.int64)
        lt_9 = ops.lt(index_expr_19, constant_19)
        and__13 = ops.and_(ge_9, lt_9)
        and__14 = ops.and_(and__12, and__13)
        masked_subblock5 = self.masked_subblock5(and__14, -inf)
        maximum_3 = ops.maximum(masked_subblock5, maximum_2)
        get_index_20 = self.get_index('index7')
        index_expr_20 = ops.index_expr(get_index_20, torch.int64)
        constant_20 = ops.constant(0, torch.int64)
        ge_10 = ops.ge(index_expr_20, constant_20)
        get_index_21 = self.get_index('index7')
        index_expr_21 = ops.index_expr(get_index_21, torch.int64)
        constant_21 = ops.constant(72, torch.int64)
        lt_10 = ops.lt(index_expr_21, constant_21)
        and__15 = ops.and_(ge_10, lt_10)
        get_index_22 = self.get_index('index5')
        index_expr_22 = ops.index_expr(get_index_22, torch.int64)
        constant_22 = ops.constant(0, torch.int64)
        ge_11 = ops.ge(index_expr_22, constant_22)
        get_index_23 = self.get_index('index5')
        index_expr_23 = ops.index_expr(get_index_23, torch.int64)
        constant_23 = ops.constant(72, torch.int64)
        lt_11 = ops.lt(index_expr_23, constant_23)
        and__16 = ops.and_(ge_11, lt_11)
        and__17 = ops.and_(and__15, and__16)
        masked_subblock6 = self.masked_subblock6(and__17, -inf)
        maximum_4 = ops.maximum(masked_subblock6, maximum_3)
        get_index_24 = self.get_index('index11')
        index_expr_24 = ops.index_expr(get_index_24, torch.int64)
        constant_24 = ops.constant(0, torch.int64)
        ge_12 = ops.ge(index_expr_24, constant_24)
        get_index_25 = self.get_index('index11')
        index_expr_25 = ops.index_expr(get_index_25, torch.int64)
        constant_25 = ops.constant(72, torch.int64)
        lt_12 = ops.lt(index_expr_25, constant_25)
        and__18 = ops.and_(ge_12, lt_12)
        get_index_26 = self.get_index('index1')
        index_expr_26 = ops.index_expr(get_index_26, torch.int64)
        constant_26 = ops.constant(0, torch.int64)
        ge_13 = ops.ge(index_expr_26, constant_26)
        get_index_27 = self.get_index('index1')
        index_expr_27 = ops.index_expr(get_index_27, torch.int64)
        constant_27 = ops.constant(72, torch.int64)
        lt_13 = ops.lt(index_expr_27, constant_27)
        and__19 = ops.and_(ge_13, lt_13)
        and__20 = ops.and_(and__18, and__19)
        masked_subblock7 = self.masked_subblock7(and__20, -inf)
        maximum_5 = ops.maximum(masked_subblock7, maximum_4)
        get_index_28 = self.get_index('index11')
        index_expr_28 = ops.index_expr(get_index_28, torch.int64)
        constant_28 = ops.constant(0, torch.int64)
        ge_14 = ops.ge(index_expr_28, constant_28)
        get_index_29 = self.get_index('index11')
        index_expr_29 = ops.index_expr(get_index_29, torch.int64)
        constant_29 = ops.constant(72, torch.int64)
        lt_14 = ops.lt(index_expr_29, constant_29)
        and__21 = ops.and_(ge_14, lt_14)
        get_index_30 = self.get_index('index3')
        index_expr_30 = ops.index_expr(get_index_30, torch.int64)
        constant_30 = ops.constant(0, torch.int64)
        ge_15 = ops.ge(index_expr_30, constant_30)
        get_index_31 = self.get_index('index3')
        index_expr_31 = ops.index_expr(get_index_31, torch.int64)
        constant_31 = ops.constant(72, torch.int64)
        lt_15 = ops.lt(index_expr_31, constant_31)
        and__22 = ops.and_(ge_15, lt_15)
        and__23 = ops.and_(and__21, and__22)
        masked_subblock8 = self.masked_subblock8(and__23, -inf)
        maximum_6 = ops.maximum(masked_subblock8, maximum_5)
        get_index_32 = self.get_index('index11')
        index_expr_32 = ops.index_expr(get_index_32, torch.int64)
        constant_32 = ops.constant(0, torch.int64)
        ge_16 = ops.ge(index_expr_32, constant_32)
        get_index_33 = self.get_index('index11')
        index_expr_33 = ops.index_expr(get_index_33, torch.int64)
        constant_33 = ops.constant(72, torch.int64)
        lt_16 = ops.lt(index_expr_33, constant_33)
        and__24 = ops.and_(ge_16, lt_16)
        get_index_34 = self.get_index('index5')
        index_expr_34 = ops.index_expr(get_index_34, torch.int64)
        constant_34 = ops.constant(0, torch.int64)
        ge_17 = ops.ge(index_expr_34, constant_34)
        get_index_35 = self.get_index('index5')
        index_expr_35 = ops.index_expr(get_index_35, torch.int64)
        constant_35 = ops.constant(72, torch.int64)
        lt_17 = ops.lt(index_expr_35, constant_35)
        and__25 = ops.and_(ge_17, lt_17)
        and__26 = ops.and_(and__24, and__25)
        masked_subblock9 = self.masked_subblock9(and__26, -inf)
        maximum_7 = ops.maximum(masked_subblock9, maximum_6)
        get_index_36 = self.get_index('index15')
        store = ops.store('buf28', get_index_36, maximum_7, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index2')
        load = ops.load('buf27', get_index)
        return load
    def masked_subblock2(self, ops):
        get_index = self.get_index('index4')
        load = ops.load('buf27', get_index)
        return load
    def masked_subblock3(self, ops):
        get_index = self.get_index('index6')
        load = ops.load('buf27', get_index)
        return load
    def masked_subblock4(self, ops):
        get_index = self.get_index('index8')
        load = ops.load('buf27', get_index)
        return load
    def masked_subblock5(self, ops):
        get_index = self.get_index('index9')
        load = ops.load('buf27', get_index)
        return load
    def masked_subblock6(self, ops):
        get_index = self.get_index('index10')
        load = ops.load('buf27', get_index)
        return load
    def masked_subblock7(self, ops):
        get_index = self.get_index('index12')
        load = ops.load('buf27', get_index)
        return load
    def masked_subblock8(self, ops):
        get_index = self.get_index('index13')
        load = ops.load('buf27', get_index)
        return load
    def masked_subblock9(self, ops):
        get_index = self.get_index('index14')
        load = ops.load('buf27', get_index)
        return load


op29: ExternKernelSchedulerNode(ExternKernelAlloc)
op29.writes = [StarDep(name='buf29', mode=None)]
op29.unmet_dependencies = [StarDep(name='buf28', mode=None)]
op29.met_dependencies = [StarDep(name='arg48_1', mode=None)]
op29.outputs = [
    buf29: ExternKernelAlloc
    buf29.layout = FixedLayout('cuda', torch.float32, size=[8, 160, 36, 36], stride=[207360, 1, 5760, 160])
    buf29.users = [NodeUser(node=SchedulerNode(name='op30'), can_inplace=True, is_weak=False)]
]
op29.node.kernel = extern_kernels.convolution


op30: SchedulerNode(ComputedBuffer)
op30.writes = [MemoryDep('buf30', c0, {c0: 1658880}, None)]
op30.unmet_dependencies = [MemoryDep('buf29', c0, {c0: 1658880}, None)]
op30.met_dependencies = 
    [   MemoryDep('arg49_1', c1, {c0: 10368, c1: 160}, None),
        MemoryDep('arg50_1', c1, {c0: 10368, c1: 160}, None),
        MemoryDep('arg51_1', c1, {c0: 10368, c1: 160}, None),
        MemoryDep('arg52_1', c1, {c0: 10368, c1: 160}, None)]
op30.outputs = [
    buf30: ComputedBuffer
    buf30.layout = FixedLayout('cuda', torch.float32, size=[8, 160, 36, 36], stride=[207360, 1, 5760, 160])
    buf30.users = [NodeUser(node=ExternKernelSchedulerNode(name='op31'), can_inplace=False, is_weak=False)]
]
op30.group.device = cuda:0
op30.group.iteration = (1658880, 1)
op30.sizes = ([10368, 160], [])
buf29_layout = FixedLayout('cuda', torch.float32, size=[8, 160, 36, 36], stride=[207360, 1, 5760, 160])
arg49_1_layout = FixedLayout('cuda', torch.float32, size=[160], stride=[1])
arg50_1_layout = FixedLayout('cuda', torch.float32, size=[160], stride=[1])
arg51_1_layout = FixedLayout('cuda', torch.float32, size=[160], stride=[1])
arg52_1_layout = FixedLayout('cuda', torch.float32, size=[160], stride=[1])
buf30_layout = FixedLayout('cuda', torch.float32, size=[8, 160, 36, 36], stride=[207360, 1, 5760, 160])
class op30_loop_body:
    var_ranges = {z0: 10368, z1: 160}
    index0 = 160*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf29', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg49_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('arg50_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg51_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('arg52_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf30', get_index_5, relu, None)
        return store


op31: ExternKernelSchedulerNode(ExternKernelAlloc)
op31.writes = [StarDep(name='buf31', mode=None)]
op31.unmet_dependencies = [StarDep(name='buf30', mode=None)]
op31.met_dependencies = [StarDep(name='arg53_1', mode=None)]
op31.outputs = [
    buf31: ExternKernelAlloc
    buf31.layout = FixedLayout('cuda', torch.float32, size=[8, 160, 36, 36], stride=[207360, 1, 5760, 160])
    buf31.users = [NodeUser(node=ExternKernelSchedulerNode(name='op32'), can_inplace=False, is_weak=False)]
]
op31.node.kernel = extern_kernels.convolution


op32: ExternKernelSchedulerNode(ExternKernelAlloc)
op32.writes = [StarDep(name='buf32', mode=None)]
op32.unmet_dependencies = [StarDep(name='buf31', mode=None)]
op32.met_dependencies = [StarDep(name='arg54_1', mode=None)]
op32.outputs = [
    buf32: ExternKernelAlloc
    buf32.layout = FixedLayout('cuda', torch.float32, size=[8, 160, 36, 36], stride=[207360, 1, 5760, 160])
    buf32.users = [NodeUser(node=SchedulerNode(name='op33'), can_inplace=True, is_weak=False)]
]
op32.node.kernel = extern_kernels.convolution


op33: SchedulerNode(ComputedBuffer)
op33.writes = [MemoryDep('buf33', c0, {c0: 1658880}, None)]
op33.unmet_dependencies = [MemoryDep('buf32', c0, {c0: 1658880}, None)]
op33.met_dependencies = 
    [   MemoryDep('arg55_1', c1, {c0: 10368, c1: 160}, None),
        MemoryDep('arg56_1', c1, {c0: 10368, c1: 160}, None),
        MemoryDep('arg57_1', c1, {c0: 10368, c1: 160}, None),
        MemoryDep('arg58_1', c1, {c0: 10368, c1: 160}, None)]
op33.outputs = [
    buf33: ComputedBuffer
    buf33.layout = FixedLayout('cuda', torch.float32, size=[8, 160, 36, 36], stride=[207360, 1, 5760, 160])
    buf33.users = [
        NodeUser(node=ExternKernelSchedulerNode(name='op34'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op39'), can_inplace=False, is_weak=False),
    ]
]
op33.group.device = cuda:0
op33.group.iteration = (1658880, 1)
op33.sizes = ([10368, 160], [])
buf32_layout = FixedLayout('cuda', torch.float32, size=[8, 160, 36, 36], stride=[207360, 1, 5760, 160])
arg55_1_layout = FixedLayout('cuda', torch.float32, size=[160], stride=[1])
arg56_1_layout = FixedLayout('cuda', torch.float32, size=[160], stride=[1])
arg57_1_layout = FixedLayout('cuda', torch.float32, size=[160], stride=[1])
arg58_1_layout = FixedLayout('cuda', torch.float32, size=[160], stride=[1])
buf33_layout = FixedLayout('cuda', torch.float32, size=[8, 160, 36, 36], stride=[207360, 1, 5760, 160])
class op33_loop_body:
    var_ranges = {z0: 10368, z1: 160}
    index0 = 160*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf32', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg55_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('arg56_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg57_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('arg58_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf33', get_index_5, relu, None)
        return store


op34: ExternKernelSchedulerNode(ExternKernelAlloc)
op34.writes = [StarDep(name='buf34', mode=None)]
op34.unmet_dependencies = [StarDep(name='buf33', mode=None)]
op34.met_dependencies = [StarDep(name='arg59_1', mode=None)]
op34.outputs = [
    buf34: ExternKernelAlloc
    buf34.layout = FixedLayout('cuda', torch.float32, size=[8, 160, 36, 36], stride=[207360, 1, 5760, 160])
    buf34.users = [NodeUser(node=ExternKernelSchedulerNode(name='op35'), can_inplace=False, is_weak=False)]
]
op34.node.kernel = extern_kernels.convolution


op35: ExternKernelSchedulerNode(ExternKernelAlloc)
op35.writes = [StarDep(name='buf35', mode=None)]
op35.unmet_dependencies = [StarDep(name='buf34', mode=None)]
op35.met_dependencies = [StarDep(name='arg60_1', mode=None)]
op35.outputs = [
    buf35: ExternKernelAlloc
    buf35.layout = FixedLayout('cuda', torch.float32, size=[8, 160, 36, 36], stride=[207360, 1, 5760, 160])
    buf35.users = [NodeUser(node=SchedulerNode(name='op36'), can_inplace=True, is_weak=False)]
]
op35.node.kernel = extern_kernels.convolution


op36: SchedulerNode(ComputedBuffer)
op36.writes = [MemoryDep('buf36', c0, {c0: 1658880}, None)]
op36.unmet_dependencies = [MemoryDep('buf35', c0, {c0: 1658880}, None)]
op36.met_dependencies = 
    [   MemoryDep('arg61_1', c1, {c0: 10368, c1: 160}, None),
        MemoryDep('arg62_1', c1, {c0: 10368, c1: 160}, None),
        MemoryDep('arg63_1', c1, {c0: 10368, c1: 160}, None),
        MemoryDep('arg64_1', c1, {c0: 10368, c1: 160}, None)]
op36.outputs = [
    buf36: ComputedBuffer
    buf36.layout = FixedLayout('cuda', torch.float32, size=[8, 160, 36, 36], stride=[207360, 1, 5760, 160])
    buf36.users = [
        NodeUser(node=ExternKernelSchedulerNode(name='op37'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op39'), can_inplace=False, is_weak=False),
    ]
]
op36.group.device = cuda:0
op36.group.iteration = (1658880, 1)
op36.sizes = ([10368, 160], [])
buf35_layout = FixedLayout('cuda', torch.float32, size=[8, 160, 36, 36], stride=[207360, 1, 5760, 160])
arg61_1_layout = FixedLayout('cuda', torch.float32, size=[160], stride=[1])
arg62_1_layout = FixedLayout('cuda', torch.float32, size=[160], stride=[1])
arg63_1_layout = FixedLayout('cuda', torch.float32, size=[160], stride=[1])
arg64_1_layout = FixedLayout('cuda', torch.float32, size=[160], stride=[1])
buf36_layout = FixedLayout('cuda', torch.float32, size=[8, 160, 36, 36], stride=[207360, 1, 5760, 160])
class op36_loop_body:
    var_ranges = {z0: 10368, z1: 160}
    index0 = 160*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf35', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg61_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('arg62_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg63_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('arg64_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf36', get_index_5, relu, None)
        return store


op37: ExternKernelSchedulerNode(ExternKernelAlloc)
op37.writes = [StarDep(name='buf37', mode=None)]
op37.unmet_dependencies = [StarDep(name='buf36', mode=None)]
op37.met_dependencies = [StarDep(name='arg65_1', mode=None)]
op37.outputs = [
    buf37: ExternKernelAlloc
    buf37.layout = FixedLayout('cuda', torch.float32, size=[8, 160, 36, 36], stride=[207360, 1, 5760, 160])
    buf37.users = [NodeUser(node=ExternKernelSchedulerNode(name='op38'), can_inplace=False, is_weak=False)]
]
op37.node.kernel = extern_kernels.convolution


op38: ExternKernelSchedulerNode(ExternKernelAlloc)
op38.writes = [StarDep(name='buf38', mode=None)]
op38.unmet_dependencies = [StarDep(name='buf37', mode=None)]
op38.met_dependencies = [StarDep(name='arg66_1', mode=None)]
op38.outputs = [
    buf38: ExternKernelAlloc
    buf38.layout = FixedLayout('cuda', torch.float32, size=[8, 160, 36, 36], stride=[207360, 1, 5760, 160])
    buf38.users = [NodeUser(node=SchedulerNode(name='op39'), can_inplace=False, is_weak=False)]
]
op38.node.kernel = extern_kernels.convolution


op39: SchedulerNode(ComputedBuffer)
op39.writes = [MemoryDep('buf39', c0, {c0: 7630848}, None)]
op39.unmet_dependencies = 
    [   MemoryDep('buf28', 256*c0 + I, {c0: 10368, c1: 736}, None),
        MemoryDep('buf33', 160*c0 + I, {c0: 10368, c1: 736}, None),
        MemoryDep('buf36', 160*c0 + I, {c0: 10368, c1: 736}, None),
        MemoryDep('buf38', 160*c0 + I, {c0: 10368, c1: 736}, None)]
op39.met_dependencies = 
    [   MemoryDep('arg67_1', I, {c0: 10368, c1: 736}, None),
        MemoryDep('arg68_1', I, {c0: 10368, c1: 736}, None),
        MemoryDep('arg69_1', I, {c0: 10368, c1: 736}, None),
        MemoryDep('arg70_1', I, {c0: 10368, c1: 736}, None)]
op39.outputs = [
    buf39: ComputedBuffer
    buf39.layout = FixedLayout('cuda', torch.float32, size=[8, 736, 36, 36], stride=[953856, 1, 26496, 736])
    buf39.users = [NodeUser(node=ExternKernelSchedulerNode(name='op40'), can_inplace=False, is_weak=False)]
]
op39.group.device = cuda:0
op39.group.iteration = (7630848, 1)
op39.sizes = ([10368, 736], [])
buf28_layout = FixedLayout('cuda', torch.float32, size=[8, 256, 36, 36], stride=[331776, 1, 9216, 256])
buf33_layout = FixedLayout('cuda', torch.float32, size=[8, 160, 36, 36], stride=[207360, 1, 5760, 160])
buf36_layout = FixedLayout('cuda', torch.float32, size=[8, 160, 36, 36], stride=[207360, 1, 5760, 160])
buf38_layout = FixedLayout('cuda', torch.float32, size=[8, 160, 36, 36], stride=[207360, 1, 5760, 160])
arg67_1_layout = FixedLayout('cuda', torch.float32, size=[160], stride=[1])
arg68_1_layout = FixedLayout('cuda', torch.float32, size=[160], stride=[1])
arg69_1_layout = FixedLayout('cuda', torch.float32, size=[160], stride=[1])
arg70_1_layout = FixedLayout('cuda', torch.float32, size=[160], stride=[1])
buf39_layout = FixedLayout('cuda', torch.float32, size=[8, 736, 36, 36], stride=[953856, 1, 26496, 736])
class op39_loop_body:
    var_ranges = {z0: 10368, z1: 736}
    index0 = z1
    index1 = 256*z0 + I
    index2 = 160*z0 + I
    index3 = 160*z0 + I
    index4 = 160*z0 + I
    index5 = I
    index6 = 736*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int64)
        constant = ops.constant(0, torch.int64)
        ge = ops.ge(index_expr, constant)
        get_index_1 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_1, torch.int64)
        constant_1 = ops.constant(256, torch.int64)
        lt = ops.lt(index_expr_1, constant_1)
        masked_subblock1 = self.masked_subblock1(lt, 0.0)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        constant_2 = ops.constant(256, torch.int64)
        ge_1 = ops.ge(index_expr_2, constant_2)
        get_index_3 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        constant_3 = ops.constant(416, torch.int64)
        lt_1 = ops.lt(index_expr_3, constant_3)
        and_ = ops.and_(ge_1, lt_1)
        masked_subblock2 = self.masked_subblock2(and_, 0.0)
        get_index_4 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_4, torch.int64)
        constant_4 = ops.constant(416, torch.int64)
        ge_2 = ops.ge(index_expr_4, constant_4)
        get_index_5 = self.get_index('index0')
        index_expr_5 = ops.index_expr(get_index_5, torch.int64)
        constant_5 = ops.constant(576, torch.int64)
        lt_2 = ops.lt(index_expr_5, constant_5)
        and__1 = ops.and_(ge_2, lt_2)
        masked_subblock3 = self.masked_subblock3(and__1, 0.0)
        get_index_6 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_6, torch.int64)
        constant_6 = ops.constant(576, torch.int64)
        ge_3 = ops.ge(index_expr_6, constant_6)
        get_index_7 = self.get_index('index0')
        index_expr_7 = ops.index_expr(get_index_7, torch.int64)
        constant_7 = ops.constant(736, torch.int64)
        lt_3 = ops.lt(index_expr_7, constant_7)
        masked_subblock4 = self.masked_subblock4(ge_3, 0.0)
        where = ops.where(and__1, masked_subblock3, masked_subblock4)
        where_1 = ops.where(and_, masked_subblock2, where)
        where_2 = ops.where(lt, masked_subblock1, where_1)
        get_index_8 = self.get_index('index6')
        store = ops.store('buf39', get_index_8, where_2, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('buf28', get_index)
        return load
    def masked_subblock2(self, ops):
        get_index = self.get_index('index2')
        load = ops.load('buf33', get_index)
        return load
    def masked_subblock3(self, ops):
        get_index = self.get_index('index3')
        load = ops.load('buf36', get_index)
        return load
    def masked_subblock4(self, ops):
        get_index = self.get_index('index4')
        load = ops.load('buf38', get_index)
        get_index_1 = self.get_index('index5')
        load_1 = ops.load('arg67_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index5')
        load_2 = ops.load('arg68_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index5')
        load_3 = ops.load('arg69_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index5')
        load_4 = ops.load('arg70_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        return relu


op40: ExternKernelSchedulerNode(ExternKernelAlloc)
op40.writes = [StarDep(name='buf40', mode=None)]
op40.unmet_dependencies = [StarDep(name='buf39', mode=None)]
op40.met_dependencies = [StarDep(name='arg71_1', mode=None)]
op40.outputs = [
    buf40: ExternKernelAlloc
    buf40.layout = FixedLayout('cuda', torch.float32, size=[8, 512, 36, 36], stride=[663552, 1, 18432, 512])
    buf40.users = [NodeUser(node=SchedulerNode(name='op41'), can_inplace=True, is_weak=False)]
]
op40.node.kernel = extern_kernels.convolution


op41: SchedulerNode(ComputedBuffer)
op41.writes = [MemoryDep('buf41', c0, {c0: 5308416}, None)]
op41.unmet_dependencies = [MemoryDep('buf40', c0, {c0: 5308416}, None)]
op41.met_dependencies = 
    [   MemoryDep('arg72_1', c1, {c0: 10368, c1: 512}, None),
        MemoryDep('arg73_1', c1, {c0: 10368, c1: 512}, None),
        MemoryDep('arg74_1', c1, {c0: 10368, c1: 512}, None),
        MemoryDep('arg75_1', c1, {c0: 10368, c1: 512}, None)]
op41.outputs = [
    buf41: ComputedBuffer
    buf41.layout = FixedLayout('cuda', torch.float32, size=[8, 512, 36, 36], stride=[663552, 1, 18432, 512])
    buf41.users = [
        NodeUser(node=SchedulerNode(name='op42'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op46'), can_inplace=True, is_weak=False),
    ]
]
op41.group.device = cuda:0
op41.group.iteration = (5308416, 1)
op41.sizes = ([10368, 512], [])
buf40_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 36, 36], stride=[663552, 1, 18432, 512])
arg72_1_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
arg73_1_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
arg74_1_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
arg75_1_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf41_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 36, 36], stride=[663552, 1, 18432, 512])
class op41_loop_body:
    var_ranges = {z0: 10368, z1: 512}
    index0 = 512*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf40', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg72_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('arg73_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg74_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('arg75_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf41', get_index_5, relu, None)
        return store


op42: SchedulerNode(ComputedBuffer)
op42.writes = [MemoryDep('buf42', c0, {c0: 45056}, None)]
op42.unmet_dependencies = [   MemoryDep('buf41', 663552*c0 + c2 + 512*ModularIndexing(118*c1 + c3, 1, 1296), {c0: 8, c1: 11, c2: 512, c3: 118}, None)]
op42.met_dependencies = []
op42.outputs = [
    buf42: ComputedBuffer
    buf42.layout = FixedLayout('cuda', torch.float32, size=[8, 512, 1, 1, 11], stride=[5632, 1, 45056, 45056, 512])
    buf42.users = [NodeUser(node=SchedulerNode(name='op43'), can_inplace=False, is_weak=False)]
]
op42.group.device = cuda:0
op42.group.iteration = (45056, 118)
op42.sizes = ([8, 11, 512], [118])
buf41_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 36, 36], stride=[663552, 1, 18432, 512])
buf42_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 1, 1, 11], stride=[5632, 1, 45056, 45056, 512])
class op42_loop_body:
    var_ranges = {z0: 8, z1: 11, z2: 512, z3: 118}
    index0 = 118*z1 + z3
    index1 = 663552*z0 + z2 + 512*ModularIndexing(118*z1 + z3, 1, 1296)
    index2 = 5632*z0 + 512*z1 + z2
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(1296, torch.int32)
        lt = ops.lt(index_expr, constant)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', masked_subblock1)
        get_index_1 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf42', get_index_1, reduction)
        return store_reduction
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('buf41', get_index)
        return load


op43_op44: FusedSchedulerNode(SchedulerNode,SchedulerNode)
op43_op44.writes = 
    [   MemoryDep('buf43', c0, {c0: 4096}, None),
        MemoryDep('buf44', c0, {c0: 4096}, None)]
op43_op44.unmet_dependencies = [MemoryDep('buf42', 5632*c0 + c1 + 512*c2, {c0: 8, c1: 512, c2: 11}, None)]
op43_op44.met_dependencies = []
op43_op44.outputs = [
    buf43: ComputedBuffer
    buf43.layout = FixedLayout('cuda', torch.float32, size=[8, 512, 1, 1], stride=[512, 1, 4096, 4096])
    buf43.users = [NodeUser(node=SchedulerNode(name='op44'), can_inplace=True, is_weak=False)]
    buf44: ComputedBuffer
    buf44.layout = FixedLayout('cuda', torch.float32, size=[8, 512, 1, 1], stride=[512, 1, 1, 1])
    buf44.users = [NodeUser(node=ExternKernelSchedulerNode(name='op45'), can_inplace=False, is_weak=False)]
]
op43_op44.snodes[0] =
op43: SchedulerNode(ComputedBuffer)
op43.writes = [MemoryDep('buf43', c0, {c0: 4096}, None)]
op43.unmet_dependencies = [MemoryDep('buf42', 5632*c0 + c1 + 512*c2, {c0: 8, c1: 512, c2: 11}, None)]
op43.met_dependencies = []
op43.outputs = [
    buf43: ComputedBuffer
    buf43.layout = FixedLayout('cuda', torch.float32, size=[8, 512, 1, 1], stride=[512, 1, 4096, 4096])
    buf43.users = [NodeUser(node=SchedulerNode(name='op44'), can_inplace=True, is_weak=False)]
]
op43.group.device = cuda:0
op43.group.iteration = (4096, 11)
op43.sizes = ([8, 512], [11])
buf42_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 1, 1, 11], stride=[5632, 1, 45056, 45056, 512])
buf43_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 1, 1], stride=[512, 1, 4096, 4096])
class op43_loop_body:
    var_ranges = {z0: 8, z1: 512, z2: 11}
    index0 = 5632*z0 + z1 + 512*z2
    index1 = 512*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf42', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf43', get_index_1, reduction)
        return store_reduction
op43_op44.snodes[1] =
op44: SchedulerNode(ComputedBuffer)
op44.writes = [MemoryDep('buf44', c0, {c0: 4096}, None)]
op44.unmet_dependencies = [MemoryDep('buf43', c0, {c0: 4096}, None)]
op44.met_dependencies = []
op44.outputs = [
    buf44: ComputedBuffer
    buf44.layout = FixedLayout('cuda', torch.float32, size=[8, 512, 1, 1], stride=[512, 1, 1, 1])
    buf44.users = [NodeUser(node=ExternKernelSchedulerNode(name='op45'), can_inplace=False, is_weak=False)]
]
op44.group.device = cuda:0
op44.group.iteration = (4096, 1)
op44.sizes = ([4096], [])
buf43_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 1, 1], stride=[512, 1, 4096, 4096])
buf44_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 1, 1], stride=[512, 1, 1, 1])
class op44_loop_body:
    var_ranges = {z0: 4096}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf43', get_index)
        constant = ops.constant(1296.0, torch.float32)
        truediv = ops.truediv(load, constant)
        get_index_1 = self.get_index('index0')
        store = ops.store('buf44', get_index_1, truediv, None)
        return store


op45: ExternKernelSchedulerNode(ExternKernelAlloc)
op45.writes = [StarDep(name='buf45', mode=None)]
op45.unmet_dependencies = [StarDep(name='buf44', mode=None)]
op45.met_dependencies = [StarDep(name='arg76_1', mode=None)]
op45.outputs = [
    buf45: ExternKernelAlloc
    buf45.layout = FixedLayout('cuda', torch.float32, size=[8, 512, 1, 1], stride=[512, 1, 1, 1])
    buf45.users = [NodeUser(node=SchedulerNode(name='op46'), can_inplace=False, is_weak=False)]
]
op45.node.kernel = extern_kernels.convolution


op46: SchedulerNode(ComputedBuffer)
op46.writes = [MemoryDep('buf46', c0, {c0: 5308416}, None)]
op46.unmet_dependencies = 
    [   MemoryDep('buf41', c0, {c0: 5308416}, None),
        MemoryDep('buf45', 512*c0 + c2, {c0: 8, c1: 1296, c2: 512}, None)]
op46.met_dependencies = [MemoryDep('arg77_1', c1, {c0: 10368, c1: 512}, None)]
op46.outputs = [
    buf46: ComputedBuffer
    buf46.layout = FixedLayout('cuda', torch.float32, size=[8, 512, 36, 36], stride=[663552, 1, 18432, 512])
    buf46.users = [NodeUser(node=SchedulerNode(name='op47'), can_inplace=False, is_weak=False)]
]
op46.group.device = cuda:0
op46.group.iteration = (5308416, 1)
op46.sizes = ([8, 1296, 512], [])
buf41_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 36, 36], stride=[663552, 1, 18432, 512])
buf45_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 1, 1], stride=[512, 1, 1, 1])
arg77_1_layout = FixedLayout('cuda', torch.float32, size=[512], stride=[1])
buf46_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 36, 36], stride=[663552, 1, 18432, 512])
class op46_loop_body:
    var_ranges = {z0: 8, z1: 1296, z2: 512}
    index0 = 663552*z0 + 512*z1 + z2
    index1 = 512*z0 + z2
    index2 = z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf41', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf45', get_index_1)
        get_index_2 = self.get_index('index2')
        load_2 = ops.load('arg77_1', get_index_2)
        add = ops.add(load_1, load_2)
        constant = ops.constant(3.0, torch.float32)
        add_1 = ops.add(add, constant)
        constant_1 = ops.constant(0.0, torch.float32)
        maximum = ops.maximum(add_1, constant_1)
        constant_2 = ops.constant(6.0, torch.float32)
        minimum = ops.minimum(maximum, constant_2)
        constant_3 = ops.constant(0.16666666666666666, torch.float32)
        mul = ops.mul(minimum, constant_3)
        mul_1 = ops.mul(load, mul)
        get_index_3 = self.get_index('index0')
        store = ops.store('buf46', get_index_3, mul_1, None)
        return store


op47: SchedulerNode(ComputedBuffer)
op47.writes = [MemoryDep('buf47', c0, {c0: 1327104}, None)]
op47.unmet_dependencies = 
    [   MemoryDep('buf46', 36864*c0 + 1024*c1 + c2 + 1024, {c0: 144, c1: 18, c2: 512}, None),
        MemoryDep('buf46', 36864*c0 + 1024*c1 + c2 + 18432, {c0: 144, c1: 18, c2: 512}, None),
        MemoryDep('buf46', 36864*c0 + 1024*c1 + c2 + 18944, {c0: 144, c1: 18, c2: 512}, None),
        MemoryDep('buf46', 36864*c0 + 1024*c1 + c2 + 19456, {c0: 144, c1: 18, c2: 512}, None),
        MemoryDep('buf46', 36864*c0 + 1024*c1 + c2 + 36864, {c0: 144, c1: 18, c2: 512}, None),
        MemoryDep('buf46', 36864*c0 + 1024*c1 + c2 + 37376, {c0: 144, c1: 18, c2: 512}, None),
        MemoryDep('buf46', 36864*c0 + 1024*c1 + c2 + 37888, {c0: 144, c1: 18, c2: 512}, None),
        MemoryDep('buf46', 36864*c0 + 1024*c1 + c2 + 512, {c0: 144, c1: 18, c2: 512}, None),
        MemoryDep('buf46', 36864*c0 + 1024*c1 + c2, {c0: 144, c1: 18, c2: 512}, None)]
op47.met_dependencies = []
op47.outputs = [
    buf47: ComputedBuffer
    buf47.layout = FixedLayout('cuda', torch.float32, size=[8, 512, 18, 18], stride=[165888, 1, 9216, 512])
    buf47.users = [
        NodeUser(node=ExternKernelSchedulerNode(name='op48'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op58'), can_inplace=False, is_weak=False),
    ]
]
op47.group.device = cuda:0
op47.group.iteration = (1327104, 1)
op47.sizes = ([8, 18, 18, 512], [])
buf46_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 36, 36], stride=[663552, 1, 18432, 512])
buf46_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 36, 36], stride=[663552, 1, 18432, 512])
buf46_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 36, 36], stride=[663552, 1, 18432, 512])
buf46_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 36, 36], stride=[663552, 1, 18432, 512])
buf46_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 36, 36], stride=[663552, 1, 18432, 512])
buf46_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 36, 36], stride=[663552, 1, 18432, 512])
buf46_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 36, 36], stride=[663552, 1, 18432, 512])
buf46_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 36, 36], stride=[663552, 1, 18432, 512])
buf46_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 36, 36], stride=[663552, 1, 18432, 512])
buf47_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 18, 18], stride=[165888, 1, 9216, 512])
class op47_loop_body:
    var_ranges = {z0: 8, z1: 18, z2: 18, z3: 512}
    index0 = 2*z1
    index1 = 2*z2
    index2 = 663552*z0 + 36864*z1 + 1024*z2 + z3
    index3 = 2*z2 + 1
    index4 = 663552*z0 + 36864*z1 + 1024*z2 + z3 + 512
    index5 = 2*z2 + 2
    index6 = 663552*z0 + 36864*z1 + 1024*z2 + z3 + 1024
    index7 = 2*z1 + 1
    index8 = 663552*z0 + 36864*z1 + 1024*z2 + z3 + 18432
    index9 = 663552*z0 + 36864*z1 + 1024*z2 + z3 + 18944
    index10 = 663552*z0 + 36864*z1 + 1024*z2 + z3 + 19456
    index11 = 2*z1 + 2
    index12 = 663552*z0 + 36864*z1 + 1024*z2 + z3 + 36864
    index13 = 663552*z0 + 36864*z1 + 1024*z2 + z3 + 37376
    index14 = 663552*z0 + 36864*z1 + 1024*z2 + z3 + 37888
    index15 = 165888*z0 + 9216*z1 + 512*z2 + z3
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int64)
        constant = ops.constant(0, torch.int64)
        ge = ops.ge(index_expr, constant)
        get_index_1 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_1, torch.int64)
        constant_1 = ops.constant(36, torch.int64)
        lt = ops.lt(index_expr_1, constant_1)
        and_ = ops.and_(ge, lt)
        get_index_2 = self.get_index('index1')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        constant_2 = ops.constant(0, torch.int64)
        ge_1 = ops.ge(index_expr_2, constant_2)
        get_index_3 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        constant_3 = ops.constant(36, torch.int64)
        lt_1 = ops.lt(index_expr_3, constant_3)
        and__1 = ops.and_(ge_1, lt_1)
        and__2 = ops.and_(and_, and__1)
        masked_subblock1 = self.masked_subblock1(and__2, -inf)
        get_index_4 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_4, torch.int64)
        constant_4 = ops.constant(0, torch.int64)
        ge_2 = ops.ge(index_expr_4, constant_4)
        get_index_5 = self.get_index('index0')
        index_expr_5 = ops.index_expr(get_index_5, torch.int64)
        constant_5 = ops.constant(36, torch.int64)
        lt_2 = ops.lt(index_expr_5, constant_5)
        and__3 = ops.and_(ge_2, lt_2)
        get_index_6 = self.get_index('index3')
        index_expr_6 = ops.index_expr(get_index_6, torch.int64)
        constant_6 = ops.constant(0, torch.int64)
        ge_3 = ops.ge(index_expr_6, constant_6)
        get_index_7 = self.get_index('index3')
        index_expr_7 = ops.index_expr(get_index_7, torch.int64)
        constant_7 = ops.constant(36, torch.int64)
        lt_3 = ops.lt(index_expr_7, constant_7)
        and__4 = ops.and_(ge_3, lt_3)
        and__5 = ops.and_(and__3, and__4)
        masked_subblock2 = self.masked_subblock2(and__5, -inf)
        maximum = ops.maximum(masked_subblock2, masked_subblock1)
        get_index_8 = self.get_index('index0')
        index_expr_8 = ops.index_expr(get_index_8, torch.int64)
        constant_8 = ops.constant(0, torch.int64)
        ge_4 = ops.ge(index_expr_8, constant_8)
        get_index_9 = self.get_index('index0')
        index_expr_9 = ops.index_expr(get_index_9, torch.int64)
        constant_9 = ops.constant(36, torch.int64)
        lt_4 = ops.lt(index_expr_9, constant_9)
        and__6 = ops.and_(ge_4, lt_4)
        get_index_10 = self.get_index('index5')
        index_expr_10 = ops.index_expr(get_index_10, torch.int64)
        constant_10 = ops.constant(0, torch.int64)
        ge_5 = ops.ge(index_expr_10, constant_10)
        get_index_11 = self.get_index('index5')
        index_expr_11 = ops.index_expr(get_index_11, torch.int64)
        constant_11 = ops.constant(36, torch.int64)
        lt_5 = ops.lt(index_expr_11, constant_11)
        and__7 = ops.and_(ge_5, lt_5)
        and__8 = ops.and_(and__6, and__7)
        masked_subblock3 = self.masked_subblock3(and__8, -inf)
        maximum_1 = ops.maximum(masked_subblock3, maximum)
        get_index_12 = self.get_index('index7')
        index_expr_12 = ops.index_expr(get_index_12, torch.int64)
        constant_12 = ops.constant(0, torch.int64)
        ge_6 = ops.ge(index_expr_12, constant_12)
        get_index_13 = self.get_index('index7')
        index_expr_13 = ops.index_expr(get_index_13, torch.int64)
        constant_13 = ops.constant(36, torch.int64)
        lt_6 = ops.lt(index_expr_13, constant_13)
        and__9 = ops.and_(ge_6, lt_6)
        get_index_14 = self.get_index('index1')
        index_expr_14 = ops.index_expr(get_index_14, torch.int64)
        constant_14 = ops.constant(0, torch.int64)
        ge_7 = ops.ge(index_expr_14, constant_14)
        get_index_15 = self.get_index('index1')
        index_expr_15 = ops.index_expr(get_index_15, torch.int64)
        constant_15 = ops.constant(36, torch.int64)
        lt_7 = ops.lt(index_expr_15, constant_15)
        and__10 = ops.and_(ge_7, lt_7)
        and__11 = ops.and_(and__9, and__10)
        masked_subblock4 = self.masked_subblock4(and__11, -inf)
        maximum_2 = ops.maximum(masked_subblock4, maximum_1)
        get_index_16 = self.get_index('index7')
        index_expr_16 = ops.index_expr(get_index_16, torch.int64)
        constant_16 = ops.constant(0, torch.int64)
        ge_8 = ops.ge(index_expr_16, constant_16)
        get_index_17 = self.get_index('index7')
        index_expr_17 = ops.index_expr(get_index_17, torch.int64)
        constant_17 = ops.constant(36, torch.int64)
        lt_8 = ops.lt(index_expr_17, constant_17)
        and__12 = ops.and_(ge_8, lt_8)
        get_index_18 = self.get_index('index3')
        index_expr_18 = ops.index_expr(get_index_18, torch.int64)
        constant_18 = ops.constant(0, torch.int64)
        ge_9 = ops.ge(index_expr_18, constant_18)
        get_index_19 = self.get_index('index3')
        index_expr_19 = ops.index_expr(get_index_19, torch.int64)
        constant_19 = ops.constant(36, torch.int64)
        lt_9 = ops.lt(index_expr_19, constant_19)
        and__13 = ops.and_(ge_9, lt_9)
        and__14 = ops.and_(and__12, and__13)
        masked_subblock5 = self.masked_subblock5(and__14, -inf)
        maximum_3 = ops.maximum(masked_subblock5, maximum_2)
        get_index_20 = self.get_index('index7')
        index_expr_20 = ops.index_expr(get_index_20, torch.int64)
        constant_20 = ops.constant(0, torch.int64)
        ge_10 = ops.ge(index_expr_20, constant_20)
        get_index_21 = self.get_index('index7')
        index_expr_21 = ops.index_expr(get_index_21, torch.int64)
        constant_21 = ops.constant(36, torch.int64)
        lt_10 = ops.lt(index_expr_21, constant_21)
        and__15 = ops.and_(ge_10, lt_10)
        get_index_22 = self.get_index('index5')
        index_expr_22 = ops.index_expr(get_index_22, torch.int64)
        constant_22 = ops.constant(0, torch.int64)
        ge_11 = ops.ge(index_expr_22, constant_22)
        get_index_23 = self.get_index('index5')
        index_expr_23 = ops.index_expr(get_index_23, torch.int64)
        constant_23 = ops.constant(36, torch.int64)
        lt_11 = ops.lt(index_expr_23, constant_23)
        and__16 = ops.and_(ge_11, lt_11)
        and__17 = ops.and_(and__15, and__16)
        masked_subblock6 = self.masked_subblock6(and__17, -inf)
        maximum_4 = ops.maximum(masked_subblock6, maximum_3)
        get_index_24 = self.get_index('index11')
        index_expr_24 = ops.index_expr(get_index_24, torch.int64)
        constant_24 = ops.constant(0, torch.int64)
        ge_12 = ops.ge(index_expr_24, constant_24)
        get_index_25 = self.get_index('index11')
        index_expr_25 = ops.index_expr(get_index_25, torch.int64)
        constant_25 = ops.constant(36, torch.int64)
        lt_12 = ops.lt(index_expr_25, constant_25)
        and__18 = ops.and_(ge_12, lt_12)
        get_index_26 = self.get_index('index1')
        index_expr_26 = ops.index_expr(get_index_26, torch.int64)
        constant_26 = ops.constant(0, torch.int64)
        ge_13 = ops.ge(index_expr_26, constant_26)
        get_index_27 = self.get_index('index1')
        index_expr_27 = ops.index_expr(get_index_27, torch.int64)
        constant_27 = ops.constant(36, torch.int64)
        lt_13 = ops.lt(index_expr_27, constant_27)
        and__19 = ops.and_(ge_13, lt_13)
        and__20 = ops.and_(and__18, and__19)
        masked_subblock7 = self.masked_subblock7(and__20, -inf)
        maximum_5 = ops.maximum(masked_subblock7, maximum_4)
        get_index_28 = self.get_index('index11')
        index_expr_28 = ops.index_expr(get_index_28, torch.int64)
        constant_28 = ops.constant(0, torch.int64)
        ge_14 = ops.ge(index_expr_28, constant_28)
        get_index_29 = self.get_index('index11')
        index_expr_29 = ops.index_expr(get_index_29, torch.int64)
        constant_29 = ops.constant(36, torch.int64)
        lt_14 = ops.lt(index_expr_29, constant_29)
        and__21 = ops.and_(ge_14, lt_14)
        get_index_30 = self.get_index('index3')
        index_expr_30 = ops.index_expr(get_index_30, torch.int64)
        constant_30 = ops.constant(0, torch.int64)
        ge_15 = ops.ge(index_expr_30, constant_30)
        get_index_31 = self.get_index('index3')
        index_expr_31 = ops.index_expr(get_index_31, torch.int64)
        constant_31 = ops.constant(36, torch.int64)
        lt_15 = ops.lt(index_expr_31, constant_31)
        and__22 = ops.and_(ge_15, lt_15)
        and__23 = ops.and_(and__21, and__22)
        masked_subblock8 = self.masked_subblock8(and__23, -inf)
        maximum_6 = ops.maximum(masked_subblock8, maximum_5)
        get_index_32 = self.get_index('index11')
        index_expr_32 = ops.index_expr(get_index_32, torch.int64)
        constant_32 = ops.constant(0, torch.int64)
        ge_16 = ops.ge(index_expr_32, constant_32)
        get_index_33 = self.get_index('index11')
        index_expr_33 = ops.index_expr(get_index_33, torch.int64)
        constant_33 = ops.constant(36, torch.int64)
        lt_16 = ops.lt(index_expr_33, constant_33)
        and__24 = ops.and_(ge_16, lt_16)
        get_index_34 = self.get_index('index5')
        index_expr_34 = ops.index_expr(get_index_34, torch.int64)
        constant_34 = ops.constant(0, torch.int64)
        ge_17 = ops.ge(index_expr_34, constant_34)
        get_index_35 = self.get_index('index5')
        index_expr_35 = ops.index_expr(get_index_35, torch.int64)
        constant_35 = ops.constant(36, torch.int64)
        lt_17 = ops.lt(index_expr_35, constant_35)
        and__25 = ops.and_(ge_17, lt_17)
        and__26 = ops.and_(and__24, and__25)
        masked_subblock9 = self.masked_subblock9(and__26, -inf)
        maximum_7 = ops.maximum(masked_subblock9, maximum_6)
        get_index_36 = self.get_index('index15')
        store = ops.store('buf47', get_index_36, maximum_7, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index2')
        load = ops.load('buf46', get_index)
        return load
    def masked_subblock2(self, ops):
        get_index = self.get_index('index4')
        load = ops.load('buf46', get_index)
        return load
    def masked_subblock3(self, ops):
        get_index = self.get_index('index6')
        load = ops.load('buf46', get_index)
        return load
    def masked_subblock4(self, ops):
        get_index = self.get_index('index8')
        load = ops.load('buf46', get_index)
        return load
    def masked_subblock5(self, ops):
        get_index = self.get_index('index9')
        load = ops.load('buf46', get_index)
        return load
    def masked_subblock6(self, ops):
        get_index = self.get_index('index10')
        load = ops.load('buf46', get_index)
        return load
    def masked_subblock7(self, ops):
        get_index = self.get_index('index12')
        load = ops.load('buf46', get_index)
        return load
    def masked_subblock8(self, ops):
        get_index = self.get_index('index13')
        load = ops.load('buf46', get_index)
        return load
    def masked_subblock9(self, ops):
        get_index = self.get_index('index14')
        load = ops.load('buf46', get_index)
        return load


op48: ExternKernelSchedulerNode(ExternKernelAlloc)
op48.writes = [StarDep(name='buf48', mode=None)]
op48.unmet_dependencies = [StarDep(name='buf47', mode=None)]
op48.met_dependencies = [StarDep(name='arg78_1', mode=None)]
op48.outputs = [
    buf48: ExternKernelAlloc
    buf48.layout = FixedLayout('cuda', torch.float32, size=[8, 192, 18, 18], stride=[62208, 1, 3456, 192])
    buf48.users = [NodeUser(node=SchedulerNode(name='op49'), can_inplace=True, is_weak=False)]
]
op48.node.kernel = extern_kernels.convolution


op49: SchedulerNode(ComputedBuffer)
op49.writes = [MemoryDep('buf49', c0, {c0: 497664}, None)]
op49.unmet_dependencies = [MemoryDep('buf48', c0, {c0: 497664}, None)]
op49.met_dependencies = 
    [   MemoryDep('arg79_1', c1, {c0: 2592, c1: 192}, None),
        MemoryDep('arg80_1', c1, {c0: 2592, c1: 192}, None),
        MemoryDep('arg81_1', c1, {c0: 2592, c1: 192}, None),
        MemoryDep('arg82_1', c1, {c0: 2592, c1: 192}, None)]
op49.outputs = [
    buf49: ComputedBuffer
    buf49.layout = FixedLayout('cuda', torch.float32, size=[8, 192, 18, 18], stride=[62208, 1, 3456, 192])
    buf49.users = [NodeUser(node=ExternKernelSchedulerNode(name='op50'), can_inplace=False, is_weak=False)]
]
op49.group.device = cuda:0
op49.group.iteration = (497664, 1)
op49.sizes = ([2592, 192], [])
buf48_layout = FixedLayout('cuda', torch.float32, size=[8, 192, 18, 18], stride=[62208, 1, 3456, 192])
arg79_1_layout = FixedLayout('cuda', torch.float32, size=[192], stride=[1])
arg80_1_layout = FixedLayout('cuda', torch.float32, size=[192], stride=[1])
arg81_1_layout = FixedLayout('cuda', torch.float32, size=[192], stride=[1])
arg82_1_layout = FixedLayout('cuda', torch.float32, size=[192], stride=[1])
buf49_layout = FixedLayout('cuda', torch.float32, size=[8, 192, 18, 18], stride=[62208, 1, 3456, 192])
class op49_loop_body:
    var_ranges = {z0: 2592, z1: 192}
    index0 = 192*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf48', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg79_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('arg80_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg81_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('arg82_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf49', get_index_5, relu, None)
        return store


op50: ExternKernelSchedulerNode(ExternKernelAlloc)
op50.writes = [StarDep(name='buf50', mode=None)]
op50.unmet_dependencies = [StarDep(name='buf49', mode=None)]
op50.met_dependencies = [StarDep(name='arg83_1', mode=None)]
op50.outputs = [
    buf50: ExternKernelAlloc
    buf50.layout = FixedLayout('cuda', torch.float32, size=[8, 192, 18, 18], stride=[62208, 1, 3456, 192])
    buf50.users = [NodeUser(node=ExternKernelSchedulerNode(name='op51'), can_inplace=False, is_weak=False)]
]
op50.node.kernel = extern_kernels.convolution


op51: ExternKernelSchedulerNode(ExternKernelAlloc)
op51.writes = [StarDep(name='buf51', mode=None)]
op51.unmet_dependencies = [StarDep(name='buf50', mode=None)]
op51.met_dependencies = [StarDep(name='arg84_1', mode=None)]
op51.outputs = [
    buf51: ExternKernelAlloc
    buf51.layout = FixedLayout('cuda', torch.float32, size=[8, 192, 18, 18], stride=[62208, 1, 3456, 192])
    buf51.users = [NodeUser(node=SchedulerNode(name='op52'), can_inplace=True, is_weak=False)]
]
op51.node.kernel = extern_kernels.convolution


op52: SchedulerNode(ComputedBuffer)
op52.writes = [MemoryDep('buf52', c0, {c0: 497664}, None)]
op52.unmet_dependencies = [MemoryDep('buf51', c0, {c0: 497664}, None)]
op52.met_dependencies = 
    [   MemoryDep('arg85_1', c1, {c0: 2592, c1: 192}, None),
        MemoryDep('arg86_1', c1, {c0: 2592, c1: 192}, None),
        MemoryDep('arg87_1', c1, {c0: 2592, c1: 192}, None),
        MemoryDep('arg88_1', c1, {c0: 2592, c1: 192}, None)]
op52.outputs = [
    buf52: ComputedBuffer
    buf52.layout = FixedLayout('cuda', torch.float32, size=[8, 192, 18, 18], stride=[62208, 1, 3456, 192])
    buf52.users = [
        NodeUser(node=ExternKernelSchedulerNode(name='op53'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op58'), can_inplace=False, is_weak=False),
    ]
]
op52.group.device = cuda:0
op52.group.iteration = (497664, 1)
op52.sizes = ([2592, 192], [])
buf51_layout = FixedLayout('cuda', torch.float32, size=[8, 192, 18, 18], stride=[62208, 1, 3456, 192])
arg85_1_layout = FixedLayout('cuda', torch.float32, size=[192], stride=[1])
arg86_1_layout = FixedLayout('cuda', torch.float32, size=[192], stride=[1])
arg87_1_layout = FixedLayout('cuda', torch.float32, size=[192], stride=[1])
arg88_1_layout = FixedLayout('cuda', torch.float32, size=[192], stride=[1])
buf52_layout = FixedLayout('cuda', torch.float32, size=[8, 192, 18, 18], stride=[62208, 1, 3456, 192])
class op52_loop_body:
    var_ranges = {z0: 2592, z1: 192}
    index0 = 192*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf51', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg85_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('arg86_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg87_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('arg88_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf52', get_index_5, relu, None)
        return store


op53: ExternKernelSchedulerNode(ExternKernelAlloc)
op53.writes = [StarDep(name='buf53', mode=None)]
op53.unmet_dependencies = [StarDep(name='buf52', mode=None)]
op53.met_dependencies = [StarDep(name='arg89_1', mode=None)]
op53.outputs = [
    buf53: ExternKernelAlloc
    buf53.layout = FixedLayout('cuda', torch.float32, size=[8, 192, 18, 18], stride=[62208, 1, 3456, 192])
    buf53.users = [NodeUser(node=ExternKernelSchedulerNode(name='op54'), can_inplace=False, is_weak=False)]
]
op53.node.kernel = extern_kernels.convolution


op54: ExternKernelSchedulerNode(ExternKernelAlloc)
op54.writes = [StarDep(name='buf54', mode=None)]
op54.unmet_dependencies = [StarDep(name='buf53', mode=None)]
op54.met_dependencies = [StarDep(name='arg90_1', mode=None)]
op54.outputs = [
    buf54: ExternKernelAlloc
    buf54.layout = FixedLayout('cuda', torch.float32, size=[8, 192, 18, 18], stride=[62208, 1, 3456, 192])
    buf54.users = [NodeUser(node=SchedulerNode(name='op55'), can_inplace=True, is_weak=False)]
]
op54.node.kernel = extern_kernels.convolution


op55: SchedulerNode(ComputedBuffer)
op55.writes = [MemoryDep('buf55', c0, {c0: 497664}, None)]
op55.unmet_dependencies = [MemoryDep('buf54', c0, {c0: 497664}, None)]
op55.met_dependencies = 
    [   MemoryDep('arg91_1', c1, {c0: 2592, c1: 192}, None),
        MemoryDep('arg92_1', c1, {c0: 2592, c1: 192}, None),
        MemoryDep('arg93_1', c1, {c0: 2592, c1: 192}, None),
        MemoryDep('arg94_1', c1, {c0: 2592, c1: 192}, None)]
op55.outputs = [
    buf55: ComputedBuffer
    buf55.layout = FixedLayout('cuda', torch.float32, size=[8, 192, 18, 18], stride=[62208, 1, 3456, 192])
    buf55.users = [
        NodeUser(node=ExternKernelSchedulerNode(name='op56'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op58'), can_inplace=False, is_weak=False),
    ]
]
op55.group.device = cuda:0
op55.group.iteration = (497664, 1)
op55.sizes = ([2592, 192], [])
buf54_layout = FixedLayout('cuda', torch.float32, size=[8, 192, 18, 18], stride=[62208, 1, 3456, 192])
arg91_1_layout = FixedLayout('cuda', torch.float32, size=[192], stride=[1])
arg92_1_layout = FixedLayout('cuda', torch.float32, size=[192], stride=[1])
arg93_1_layout = FixedLayout('cuda', torch.float32, size=[192], stride=[1])
arg94_1_layout = FixedLayout('cuda', torch.float32, size=[192], stride=[1])
buf55_layout = FixedLayout('cuda', torch.float32, size=[8, 192, 18, 18], stride=[62208, 1, 3456, 192])
class op55_loop_body:
    var_ranges = {z0: 2592, z1: 192}
    index0 = 192*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf54', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg91_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('arg92_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg93_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('arg94_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf55', get_index_5, relu, None)
        return store


op56: ExternKernelSchedulerNode(ExternKernelAlloc)
op56.writes = [StarDep(name='buf56', mode=None)]
op56.unmet_dependencies = [StarDep(name='buf55', mode=None)]
op56.met_dependencies = [StarDep(name='arg95_1', mode=None)]
op56.outputs = [
    buf56: ExternKernelAlloc
    buf56.layout = FixedLayout('cuda', torch.float32, size=[8, 192, 18, 18], stride=[62208, 1, 3456, 192])
    buf56.users = [NodeUser(node=ExternKernelSchedulerNode(name='op57'), can_inplace=False, is_weak=False)]
]
op56.node.kernel = extern_kernels.convolution


op57: ExternKernelSchedulerNode(ExternKernelAlloc)
op57.writes = [StarDep(name='buf57', mode=None)]
op57.unmet_dependencies = [StarDep(name='buf56', mode=None)]
op57.met_dependencies = [StarDep(name='arg96_1', mode=None)]
op57.outputs = [
    buf57: ExternKernelAlloc
    buf57.layout = FixedLayout('cuda', torch.float32, size=[8, 192, 18, 18], stride=[62208, 1, 3456, 192])
    buf57.users = [NodeUser(node=SchedulerNode(name='op58'), can_inplace=False, is_weak=False)]
]
op57.node.kernel = extern_kernels.convolution


op58: SchedulerNode(ComputedBuffer)
op58.writes = [MemoryDep('buf58', c0, {c0: 2820096}, None)]
op58.unmet_dependencies = 
    [   MemoryDep('buf47', 512*c0 + I, {c0: 2592, c1: 1088}, None),
        MemoryDep('buf52', 192*c0 + I, {c0: 2592, c1: 1088}, None),
        MemoryDep('buf55', 192*c0 + I, {c0: 2592, c1: 1088}, None),
        MemoryDep('buf57', 192*c0 + I, {c0: 2592, c1: 1088}, None)]
op58.met_dependencies = 
    [   MemoryDep('arg100_1', I, {c0: 2592, c1: 1088}, None),
        MemoryDep('arg97_1', I, {c0: 2592, c1: 1088}, None),
        MemoryDep('arg98_1', I, {c0: 2592, c1: 1088}, None),
        MemoryDep('arg99_1', I, {c0: 2592, c1: 1088}, None)]
op58.outputs = [
    buf58: ComputedBuffer
    buf58.layout = FixedLayout('cuda', torch.float32, size=[8, 1088, 18, 18], stride=[352512, 1, 19584, 1088])
    buf58.users = [NodeUser(node=ExternKernelSchedulerNode(name='op59'), can_inplace=False, is_weak=False)]
]
op58.group.device = cuda:0
op58.group.iteration = (2820096, 1)
op58.sizes = ([2592, 1088], [])
buf47_layout = FixedLayout('cuda', torch.float32, size=[8, 512, 18, 18], stride=[165888, 1, 9216, 512])
buf52_layout = FixedLayout('cuda', torch.float32, size=[8, 192, 18, 18], stride=[62208, 1, 3456, 192])
buf55_layout = FixedLayout('cuda', torch.float32, size=[8, 192, 18, 18], stride=[62208, 1, 3456, 192])
buf57_layout = FixedLayout('cuda', torch.float32, size=[8, 192, 18, 18], stride=[62208, 1, 3456, 192])
arg97_1_layout = FixedLayout('cuda', torch.float32, size=[192], stride=[1])
arg98_1_layout = FixedLayout('cuda', torch.float32, size=[192], stride=[1])
arg99_1_layout = FixedLayout('cuda', torch.float32, size=[192], stride=[1])
arg100_1_layout = FixedLayout('cuda', torch.float32, size=[192], stride=[1])
buf58_layout = FixedLayout('cuda', torch.float32, size=[8, 1088, 18, 18], stride=[352512, 1, 19584, 1088])
class op58_loop_body:
    var_ranges = {z0: 2592, z1: 1088}
    index0 = z1
    index1 = 512*z0 + I
    index2 = 192*z0 + I
    index3 = 192*z0 + I
    index4 = 192*z0 + I
    index5 = I
    index6 = 1088*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int64)
        constant = ops.constant(0, torch.int64)
        ge = ops.ge(index_expr, constant)
        get_index_1 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_1, torch.int64)
        constant_1 = ops.constant(512, torch.int64)
        lt = ops.lt(index_expr_1, constant_1)
        masked_subblock1 = self.masked_subblock1(lt, 0.0)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        constant_2 = ops.constant(512, torch.int64)
        ge_1 = ops.ge(index_expr_2, constant_2)
        get_index_3 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        constant_3 = ops.constant(704, torch.int64)
        lt_1 = ops.lt(index_expr_3, constant_3)
        and_ = ops.and_(ge_1, lt_1)
        masked_subblock2 = self.masked_subblock2(and_, 0.0)
        get_index_4 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_4, torch.int64)
        constant_4 = ops.constant(704, torch.int64)
        ge_2 = ops.ge(index_expr_4, constant_4)
        get_index_5 = self.get_index('index0')
        index_expr_5 = ops.index_expr(get_index_5, torch.int64)
        constant_5 = ops.constant(896, torch.int64)
        lt_2 = ops.lt(index_expr_5, constant_5)
        and__1 = ops.and_(ge_2, lt_2)
        masked_subblock3 = self.masked_subblock3(and__1, 0.0)
        get_index_6 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_6, torch.int64)
        constant_6 = ops.constant(896, torch.int64)
        ge_3 = ops.ge(index_expr_6, constant_6)
        get_index_7 = self.get_index('index0')
        index_expr_7 = ops.index_expr(get_index_7, torch.int64)
        constant_7 = ops.constant(1088, torch.int64)
        lt_3 = ops.lt(index_expr_7, constant_7)
        masked_subblock4 = self.masked_subblock4(ge_3, 0.0)
        where = ops.where(and__1, masked_subblock3, masked_subblock4)
        where_1 = ops.where(and_, masked_subblock2, where)
        where_2 = ops.where(lt, masked_subblock1, where_1)
        get_index_8 = self.get_index('index6')
        store = ops.store('buf58', get_index_8, where_2, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('buf47', get_index)
        return load
    def masked_subblock2(self, ops):
        get_index = self.get_index('index2')
        load = ops.load('buf52', get_index)
        return load
    def masked_subblock3(self, ops):
        get_index = self.get_index('index3')
        load = ops.load('buf55', get_index)
        return load
    def masked_subblock4(self, ops):
        get_index = self.get_index('index4')
        load = ops.load('buf57', get_index)
        get_index_1 = self.get_index('index5')
        load_1 = ops.load('arg97_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index5')
        load_2 = ops.load('arg98_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index5')
        load_3 = ops.load('arg99_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index5')
        load_4 = ops.load('arg100_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        return relu


op59: ExternKernelSchedulerNode(ExternKernelAlloc)
op59.writes = [StarDep(name='buf59', mode=None)]
op59.unmet_dependencies = [StarDep(name='buf58', mode=None)]
op59.met_dependencies = [StarDep(name='arg101_1', mode=None)]
op59.outputs = [
    buf59: ExternKernelAlloc
    buf59.layout = FixedLayout('cuda', torch.float32, size=[8, 768, 18, 18], stride=[248832, 1, 13824, 768])
    buf59.users = [NodeUser(node=SchedulerNode(name='op60'), can_inplace=True, is_weak=False)]
]
op59.node.kernel = extern_kernels.convolution


op60: SchedulerNode(ComputedBuffer)
op60.writes = [MemoryDep('buf60', c0, {c0: 1990656}, None)]
op60.unmet_dependencies = [MemoryDep('buf59', c0, {c0: 1990656}, None)]
op60.met_dependencies = 
    [   MemoryDep('arg102_1', c1, {c0: 2592, c1: 768}, None),
        MemoryDep('arg103_1', c1, {c0: 2592, c1: 768}, None),
        MemoryDep('arg104_1', c1, {c0: 2592, c1: 768}, None),
        MemoryDep('arg105_1', c1, {c0: 2592, c1: 768}, None)]
op60.outputs = [
    buf60: ComputedBuffer
    buf60.layout = FixedLayout('cuda', torch.float32, size=[8, 768, 18, 18], stride=[248832, 1, 13824, 768])
    buf60.users = [
        NodeUser(node=SchedulerNode(name='op61'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op65'), can_inplace=True, is_weak=False),
    ]
]
op60.group.device = cuda:0
op60.group.iteration = (1990656, 1)
op60.sizes = ([2592, 768], [])
buf59_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 18, 18], stride=[248832, 1, 13824, 768])
arg102_1_layout = FixedLayout('cuda', torch.float32, size=[768], stride=[1])
arg103_1_layout = FixedLayout('cuda', torch.float32, size=[768], stride=[1])
arg104_1_layout = FixedLayout('cuda', torch.float32, size=[768], stride=[1])
arg105_1_layout = FixedLayout('cuda', torch.float32, size=[768], stride=[1])
buf60_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 18, 18], stride=[248832, 1, 13824, 768])
class op60_loop_body:
    var_ranges = {z0: 2592, z1: 768}
    index0 = 768*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf59', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg102_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('arg103_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg104_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('arg105_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf60', get_index_5, relu, None)
        return store


op61: SchedulerNode(ComputedBuffer)
op61.writes = [MemoryDep('buf61', c0, {c0: 18432}, None)]
op61.unmet_dependencies = [MemoryDep('buf60', 82944*c0 + c1 + 768*c2, {c0: 24, c1: 768, c2: 108}, None)]
op61.met_dependencies = []
op61.outputs = [
    buf61: ComputedBuffer
    buf61.layout = FixedLayout('cuda', torch.float32, size=[8, 768, 1, 1, 3], stride=[2304, 1, 18432, 18432, 768])
    buf61.users = [NodeUser(node=SchedulerNode(name='op62'), can_inplace=False, is_weak=False)]
]
op61.group.device = cuda:0
op61.group.iteration = (18432, 108)
op61.sizes = ([24, 768], [108])
buf60_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 18, 18], stride=[248832, 1, 13824, 768])
buf61_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 1, 1, 3], stride=[2304, 1, 18432, 18432, 768])
class op61_loop_body:
    var_ranges = {z0: 24, z1: 768, z2: 108}
    index0 = 82944*z0 + z1 + 768*z2
    index1 = 768*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf60', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf61', get_index_1, reduction)
        return store_reduction


op62_op63: FusedSchedulerNode(SchedulerNode,SchedulerNode)
op62_op63.writes = 
    [   MemoryDep('buf62', c0, {c0: 6144}, None),
        MemoryDep('buf63', c0, {c0: 6144}, None)]
op62_op63.unmet_dependencies = [MemoryDep('buf61', 2304*c0 + c1 + 768*c2, {c0: 8, c1: 768, c2: 3}, None)]
op62_op63.met_dependencies = []
op62_op63.outputs = [
    buf62: ComputedBuffer
    buf62.layout = FixedLayout('cuda', torch.float32, size=[8, 768, 1, 1], stride=[768, 1, 6144, 6144])
    buf62.users = [NodeUser(node=SchedulerNode(name='op63'), can_inplace=True, is_weak=False)]
    buf63: ComputedBuffer
    buf63.layout = FixedLayout('cuda', torch.float32, size=[8, 768, 1, 1], stride=[768, 1, 1, 1])
    buf63.users = [NodeUser(node=ExternKernelSchedulerNode(name='op64'), can_inplace=False, is_weak=False)]
]
op62_op63.snodes[0] =
op62: SchedulerNode(ComputedBuffer)
op62.writes = [MemoryDep('buf62', c0, {c0: 6144}, None)]
op62.unmet_dependencies = [MemoryDep('buf61', 2304*c0 + c1 + 768*c2, {c0: 8, c1: 768, c2: 3}, None)]
op62.met_dependencies = []
op62.outputs = [
    buf62: ComputedBuffer
    buf62.layout = FixedLayout('cuda', torch.float32, size=[8, 768, 1, 1], stride=[768, 1, 6144, 6144])
    buf62.users = [NodeUser(node=SchedulerNode(name='op63'), can_inplace=True, is_weak=False)]
]
op62.group.device = cuda:0
op62.group.iteration = (6144, 3)
op62.sizes = ([8, 768], [3])
buf61_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 1, 1, 3], stride=[2304, 1, 18432, 18432, 768])
buf62_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 1, 1], stride=[768, 1, 6144, 6144])
class op62_loop_body:
    var_ranges = {z0: 8, z1: 768, z2: 3}
    index0 = 2304*z0 + z1 + 768*z2
    index1 = 768*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf61', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf62', get_index_1, reduction)
        return store_reduction
op62_op63.snodes[1] =
op63: SchedulerNode(ComputedBuffer)
op63.writes = [MemoryDep('buf63', c0, {c0: 6144}, None)]
op63.unmet_dependencies = [MemoryDep('buf62', c0, {c0: 6144}, None)]
op63.met_dependencies = []
op63.outputs = [
    buf63: ComputedBuffer
    buf63.layout = FixedLayout('cuda', torch.float32, size=[8, 768, 1, 1], stride=[768, 1, 1, 1])
    buf63.users = [NodeUser(node=ExternKernelSchedulerNode(name='op64'), can_inplace=False, is_weak=False)]
]
op63.group.device = cuda:0
op63.group.iteration = (6144, 1)
op63.sizes = ([6144], [])
buf62_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 1, 1], stride=[768, 1, 6144, 6144])
buf63_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 1, 1], stride=[768, 1, 1, 1])
class op63_loop_body:
    var_ranges = {z0: 6144}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf62', get_index)
        constant = ops.constant(324.0, torch.float32)
        truediv = ops.truediv(load, constant)
        get_index_1 = self.get_index('index0')
        store = ops.store('buf63', get_index_1, truediv, None)
        return store


op64: ExternKernelSchedulerNode(ExternKernelAlloc)
op64.writes = [StarDep(name='buf64', mode=None)]
op64.unmet_dependencies = [StarDep(name='buf63', mode=None)]
op64.met_dependencies = [StarDep(name='arg106_1', mode=None)]
op64.outputs = [
    buf64: ExternKernelAlloc
    buf64.layout = FixedLayout('cuda', torch.float32, size=[8, 768, 1, 1], stride=[768, 1, 1, 1])
    buf64.users = [NodeUser(node=SchedulerNode(name='op65'), can_inplace=False, is_weak=False)]
]
op64.node.kernel = extern_kernels.convolution


op65: SchedulerNode(ComputedBuffer)
op65.writes = [MemoryDep('buf65', c0, {c0: 1990656}, None)]
op65.unmet_dependencies = 
    [   MemoryDep('buf60', c0, {c0: 1990656}, None),
        MemoryDep('buf64', 768*c0 + c2, {c0: 8, c1: 324, c2: 768}, None)]
op65.met_dependencies = [MemoryDep('arg107_1', c1, {c0: 2592, c1: 768}, None)]
op65.outputs = [
    buf65: ComputedBuffer
    buf65.layout = FixedLayout('cuda', torch.float32, size=[8, 768, 18, 18], stride=[248832, 1, 13824, 768])
    buf65.users = [NodeUser(node=SchedulerNode(name='op66'), can_inplace=False, is_weak=False)]
]
op65.group.device = cuda:0
op65.group.iteration = (1990656, 1)
op65.sizes = ([8, 324, 768], [])
buf60_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 18, 18], stride=[248832, 1, 13824, 768])
buf64_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 1, 1], stride=[768, 1, 1, 1])
arg107_1_layout = FixedLayout('cuda', torch.float32, size=[768], stride=[1])
buf65_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 18, 18], stride=[248832, 1, 13824, 768])
class op65_loop_body:
    var_ranges = {z0: 8, z1: 324, z2: 768}
    index0 = 248832*z0 + 768*z1 + z2
    index1 = 768*z0 + z2
    index2 = z2
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf60', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf64', get_index_1)
        get_index_2 = self.get_index('index2')
        load_2 = ops.load('arg107_1', get_index_2)
        add = ops.add(load_1, load_2)
        constant = ops.constant(3.0, torch.float32)
        add_1 = ops.add(add, constant)
        constant_1 = ops.constant(0.0, torch.float32)
        maximum = ops.maximum(add_1, constant_1)
        constant_2 = ops.constant(6.0, torch.float32)
        minimum = ops.minimum(maximum, constant_2)
        constant_3 = ops.constant(0.16666666666666666, torch.float32)
        mul = ops.mul(minimum, constant_3)
        mul_1 = ops.mul(load, mul)
        get_index_3 = self.get_index('index0')
        store = ops.store('buf65', get_index_3, mul_1, None)
        return store


op66: SchedulerNode(ComputedBuffer)
op66.writes = [MemoryDep('buf66', c0, {c0: 497664}, None)]
op66.unmet_dependencies = 
    [   MemoryDep('buf65', 27648*c0 + 1536*c1 + c2 + 13824, {c0: 72, c1: 9, c2: 768}, None),
        MemoryDep('buf65', 27648*c0 + 1536*c1 + c2 + 14592, {c0: 72, c1: 9, c2: 768}, None),
        MemoryDep('buf65', 27648*c0 + 1536*c1 + c2 + 1536, {c0: 72, c1: 9, c2: 768}, None),
        MemoryDep('buf65', 27648*c0 + 1536*c1 + c2 + 15360, {c0: 72, c1: 9, c2: 768}, None),
        MemoryDep('buf65', 27648*c0 + 1536*c1 + c2 + 27648, {c0: 72, c1: 9, c2: 768}, None),
        MemoryDep('buf65', 27648*c0 + 1536*c1 + c2 + 28416, {c0: 72, c1: 9, c2: 768}, None),
        MemoryDep('buf65', 27648*c0 + 1536*c1 + c2 + 29184, {c0: 72, c1: 9, c2: 768}, None),
        MemoryDep('buf65', 27648*c0 + 1536*c1 + c2 + 768, {c0: 72, c1: 9, c2: 768}, None),
        MemoryDep('buf65', 27648*c0 + 1536*c1 + c2, {c0: 72, c1: 9, c2: 768}, None)]
op66.met_dependencies = []
op66.outputs = [
    buf66: ComputedBuffer
    buf66.layout = FixedLayout('cuda', torch.float32, size=[8, 768, 9, 9], stride=[62208, 1, 6912, 768])
    buf66.users = [
        NodeUser(node=ExternKernelSchedulerNode(name='op67'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op77'), can_inplace=False, is_weak=False),
    ]
]
op66.group.device = cuda:0
op66.group.iteration = (497664, 1)
op66.sizes = ([8, 9, 9, 768], [])
buf65_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 18, 18], stride=[248832, 1, 13824, 768])
buf65_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 18, 18], stride=[248832, 1, 13824, 768])
buf65_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 18, 18], stride=[248832, 1, 13824, 768])
buf65_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 18, 18], stride=[248832, 1, 13824, 768])
buf65_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 18, 18], stride=[248832, 1, 13824, 768])
buf65_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 18, 18], stride=[248832, 1, 13824, 768])
buf65_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 18, 18], stride=[248832, 1, 13824, 768])
buf65_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 18, 18], stride=[248832, 1, 13824, 768])
buf65_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 18, 18], stride=[248832, 1, 13824, 768])
buf66_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 9, 9], stride=[62208, 1, 6912, 768])
class op66_loop_body:
    var_ranges = {z0: 8, z1: 9, z2: 9, z3: 768}
    index0 = 2*z1
    index1 = 2*z2
    index2 = 248832*z0 + 27648*z1 + 1536*z2 + z3
    index3 = 2*z2 + 1
    index4 = 248832*z0 + 27648*z1 + 1536*z2 + z3 + 768
    index5 = 2*z2 + 2
    index6 = 248832*z0 + 27648*z1 + 1536*z2 + z3 + 1536
    index7 = 2*z1 + 1
    index8 = 248832*z0 + 27648*z1 + 1536*z2 + z3 + 13824
    index9 = 248832*z0 + 27648*z1 + 1536*z2 + z3 + 14592
    index10 = 248832*z0 + 27648*z1 + 1536*z2 + z3 + 15360
    index11 = 2*z1 + 2
    index12 = 248832*z0 + 27648*z1 + 1536*z2 + z3 + 27648
    index13 = 248832*z0 + 27648*z1 + 1536*z2 + z3 + 28416
    index14 = 248832*z0 + 27648*z1 + 1536*z2 + z3 + 29184
    index15 = 62208*z0 + 6912*z1 + 768*z2 + z3
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int64)
        constant = ops.constant(0, torch.int64)
        ge = ops.ge(index_expr, constant)
        get_index_1 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_1, torch.int64)
        constant_1 = ops.constant(18, torch.int64)
        lt = ops.lt(index_expr_1, constant_1)
        and_ = ops.and_(ge, lt)
        get_index_2 = self.get_index('index1')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        constant_2 = ops.constant(0, torch.int64)
        ge_1 = ops.ge(index_expr_2, constant_2)
        get_index_3 = self.get_index('index1')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        constant_3 = ops.constant(18, torch.int64)
        lt_1 = ops.lt(index_expr_3, constant_3)
        and__1 = ops.and_(ge_1, lt_1)
        and__2 = ops.and_(and_, and__1)
        masked_subblock1 = self.masked_subblock1(and__2, -inf)
        get_index_4 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_4, torch.int64)
        constant_4 = ops.constant(0, torch.int64)
        ge_2 = ops.ge(index_expr_4, constant_4)
        get_index_5 = self.get_index('index0')
        index_expr_5 = ops.index_expr(get_index_5, torch.int64)
        constant_5 = ops.constant(18, torch.int64)
        lt_2 = ops.lt(index_expr_5, constant_5)
        and__3 = ops.and_(ge_2, lt_2)
        get_index_6 = self.get_index('index3')
        index_expr_6 = ops.index_expr(get_index_6, torch.int64)
        constant_6 = ops.constant(0, torch.int64)
        ge_3 = ops.ge(index_expr_6, constant_6)
        get_index_7 = self.get_index('index3')
        index_expr_7 = ops.index_expr(get_index_7, torch.int64)
        constant_7 = ops.constant(18, torch.int64)
        lt_3 = ops.lt(index_expr_7, constant_7)
        and__4 = ops.and_(ge_3, lt_3)
        and__5 = ops.and_(and__3, and__4)
        masked_subblock2 = self.masked_subblock2(and__5, -inf)
        maximum = ops.maximum(masked_subblock2, masked_subblock1)
        get_index_8 = self.get_index('index0')
        index_expr_8 = ops.index_expr(get_index_8, torch.int64)
        constant_8 = ops.constant(0, torch.int64)
        ge_4 = ops.ge(index_expr_8, constant_8)
        get_index_9 = self.get_index('index0')
        index_expr_9 = ops.index_expr(get_index_9, torch.int64)
        constant_9 = ops.constant(18, torch.int64)
        lt_4 = ops.lt(index_expr_9, constant_9)
        and__6 = ops.and_(ge_4, lt_4)
        get_index_10 = self.get_index('index5')
        index_expr_10 = ops.index_expr(get_index_10, torch.int64)
        constant_10 = ops.constant(0, torch.int64)
        ge_5 = ops.ge(index_expr_10, constant_10)
        get_index_11 = self.get_index('index5')
        index_expr_11 = ops.index_expr(get_index_11, torch.int64)
        constant_11 = ops.constant(18, torch.int64)
        lt_5 = ops.lt(index_expr_11, constant_11)
        and__7 = ops.and_(ge_5, lt_5)
        and__8 = ops.and_(and__6, and__7)
        masked_subblock3 = self.masked_subblock3(and__8, -inf)
        maximum_1 = ops.maximum(masked_subblock3, maximum)
        get_index_12 = self.get_index('index7')
        index_expr_12 = ops.index_expr(get_index_12, torch.int64)
        constant_12 = ops.constant(0, torch.int64)
        ge_6 = ops.ge(index_expr_12, constant_12)
        get_index_13 = self.get_index('index7')
        index_expr_13 = ops.index_expr(get_index_13, torch.int64)
        constant_13 = ops.constant(18, torch.int64)
        lt_6 = ops.lt(index_expr_13, constant_13)
        and__9 = ops.and_(ge_6, lt_6)
        get_index_14 = self.get_index('index1')
        index_expr_14 = ops.index_expr(get_index_14, torch.int64)
        constant_14 = ops.constant(0, torch.int64)
        ge_7 = ops.ge(index_expr_14, constant_14)
        get_index_15 = self.get_index('index1')
        index_expr_15 = ops.index_expr(get_index_15, torch.int64)
        constant_15 = ops.constant(18, torch.int64)
        lt_7 = ops.lt(index_expr_15, constant_15)
        and__10 = ops.and_(ge_7, lt_7)
        and__11 = ops.and_(and__9, and__10)
        masked_subblock4 = self.masked_subblock4(and__11, -inf)
        maximum_2 = ops.maximum(masked_subblock4, maximum_1)
        get_index_16 = self.get_index('index7')
        index_expr_16 = ops.index_expr(get_index_16, torch.int64)
        constant_16 = ops.constant(0, torch.int64)
        ge_8 = ops.ge(index_expr_16, constant_16)
        get_index_17 = self.get_index('index7')
        index_expr_17 = ops.index_expr(get_index_17, torch.int64)
        constant_17 = ops.constant(18, torch.int64)
        lt_8 = ops.lt(index_expr_17, constant_17)
        and__12 = ops.and_(ge_8, lt_8)
        get_index_18 = self.get_index('index3')
        index_expr_18 = ops.index_expr(get_index_18, torch.int64)
        constant_18 = ops.constant(0, torch.int64)
        ge_9 = ops.ge(index_expr_18, constant_18)
        get_index_19 = self.get_index('index3')
        index_expr_19 = ops.index_expr(get_index_19, torch.int64)
        constant_19 = ops.constant(18, torch.int64)
        lt_9 = ops.lt(index_expr_19, constant_19)
        and__13 = ops.and_(ge_9, lt_9)
        and__14 = ops.and_(and__12, and__13)
        masked_subblock5 = self.masked_subblock5(and__14, -inf)
        maximum_3 = ops.maximum(masked_subblock5, maximum_2)
        get_index_20 = self.get_index('index7')
        index_expr_20 = ops.index_expr(get_index_20, torch.int64)
        constant_20 = ops.constant(0, torch.int64)
        ge_10 = ops.ge(index_expr_20, constant_20)
        get_index_21 = self.get_index('index7')
        index_expr_21 = ops.index_expr(get_index_21, torch.int64)
        constant_21 = ops.constant(18, torch.int64)
        lt_10 = ops.lt(index_expr_21, constant_21)
        and__15 = ops.and_(ge_10, lt_10)
        get_index_22 = self.get_index('index5')
        index_expr_22 = ops.index_expr(get_index_22, torch.int64)
        constant_22 = ops.constant(0, torch.int64)
        ge_11 = ops.ge(index_expr_22, constant_22)
        get_index_23 = self.get_index('index5')
        index_expr_23 = ops.index_expr(get_index_23, torch.int64)
        constant_23 = ops.constant(18, torch.int64)
        lt_11 = ops.lt(index_expr_23, constant_23)
        and__16 = ops.and_(ge_11, lt_11)
        and__17 = ops.and_(and__15, and__16)
        masked_subblock6 = self.masked_subblock6(and__17, -inf)
        maximum_4 = ops.maximum(masked_subblock6, maximum_3)
        get_index_24 = self.get_index('index11')
        index_expr_24 = ops.index_expr(get_index_24, torch.int64)
        constant_24 = ops.constant(0, torch.int64)
        ge_12 = ops.ge(index_expr_24, constant_24)
        get_index_25 = self.get_index('index11')
        index_expr_25 = ops.index_expr(get_index_25, torch.int64)
        constant_25 = ops.constant(18, torch.int64)
        lt_12 = ops.lt(index_expr_25, constant_25)
        and__18 = ops.and_(ge_12, lt_12)
        get_index_26 = self.get_index('index1')
        index_expr_26 = ops.index_expr(get_index_26, torch.int64)
        constant_26 = ops.constant(0, torch.int64)
        ge_13 = ops.ge(index_expr_26, constant_26)
        get_index_27 = self.get_index('index1')
        index_expr_27 = ops.index_expr(get_index_27, torch.int64)
        constant_27 = ops.constant(18, torch.int64)
        lt_13 = ops.lt(index_expr_27, constant_27)
        and__19 = ops.and_(ge_13, lt_13)
        and__20 = ops.and_(and__18, and__19)
        masked_subblock7 = self.masked_subblock7(and__20, -inf)
        maximum_5 = ops.maximum(masked_subblock7, maximum_4)
        get_index_28 = self.get_index('index11')
        index_expr_28 = ops.index_expr(get_index_28, torch.int64)
        constant_28 = ops.constant(0, torch.int64)
        ge_14 = ops.ge(index_expr_28, constant_28)
        get_index_29 = self.get_index('index11')
        index_expr_29 = ops.index_expr(get_index_29, torch.int64)
        constant_29 = ops.constant(18, torch.int64)
        lt_14 = ops.lt(index_expr_29, constant_29)
        and__21 = ops.and_(ge_14, lt_14)
        get_index_30 = self.get_index('index3')
        index_expr_30 = ops.index_expr(get_index_30, torch.int64)
        constant_30 = ops.constant(0, torch.int64)
        ge_15 = ops.ge(index_expr_30, constant_30)
        get_index_31 = self.get_index('index3')
        index_expr_31 = ops.index_expr(get_index_31, torch.int64)
        constant_31 = ops.constant(18, torch.int64)
        lt_15 = ops.lt(index_expr_31, constant_31)
        and__22 = ops.and_(ge_15, lt_15)
        and__23 = ops.and_(and__21, and__22)
        masked_subblock8 = self.masked_subblock8(and__23, -inf)
        maximum_6 = ops.maximum(masked_subblock8, maximum_5)
        get_index_32 = self.get_index('index11')
        index_expr_32 = ops.index_expr(get_index_32, torch.int64)
        constant_32 = ops.constant(0, torch.int64)
        ge_16 = ops.ge(index_expr_32, constant_32)
        get_index_33 = self.get_index('index11')
        index_expr_33 = ops.index_expr(get_index_33, torch.int64)
        constant_33 = ops.constant(18, torch.int64)
        lt_16 = ops.lt(index_expr_33, constant_33)
        and__24 = ops.and_(ge_16, lt_16)
        get_index_34 = self.get_index('index5')
        index_expr_34 = ops.index_expr(get_index_34, torch.int64)
        constant_34 = ops.constant(0, torch.int64)
        ge_17 = ops.ge(index_expr_34, constant_34)
        get_index_35 = self.get_index('index5')
        index_expr_35 = ops.index_expr(get_index_35, torch.int64)
        constant_35 = ops.constant(18, torch.int64)
        lt_17 = ops.lt(index_expr_35, constant_35)
        and__25 = ops.and_(ge_17, lt_17)
        and__26 = ops.and_(and__24, and__25)
        masked_subblock9 = self.masked_subblock9(and__26, -inf)
        maximum_7 = ops.maximum(masked_subblock9, maximum_6)
        get_index_36 = self.get_index('index15')
        store = ops.store('buf66', get_index_36, maximum_7, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index2')
        load = ops.load('buf65', get_index)
        return load
    def masked_subblock2(self, ops):
        get_index = self.get_index('index4')
        load = ops.load('buf65', get_index)
        return load
    def masked_subblock3(self, ops):
        get_index = self.get_index('index6')
        load = ops.load('buf65', get_index)
        return load
    def masked_subblock4(self, ops):
        get_index = self.get_index('index8')
        load = ops.load('buf65', get_index)
        return load
    def masked_subblock5(self, ops):
        get_index = self.get_index('index9')
        load = ops.load('buf65', get_index)
        return load
    def masked_subblock6(self, ops):
        get_index = self.get_index('index10')
        load = ops.load('buf65', get_index)
        return load
    def masked_subblock7(self, ops):
        get_index = self.get_index('index12')
        load = ops.load('buf65', get_index)
        return load
    def masked_subblock8(self, ops):
        get_index = self.get_index('index13')
        load = ops.load('buf65', get_index)
        return load
    def masked_subblock9(self, ops):
        get_index = self.get_index('index14')
        load = ops.load('buf65', get_index)
        return load


op67: ExternKernelSchedulerNode(ExternKernelAlloc)
op67.writes = [StarDep(name='buf67', mode=None)]
op67.unmet_dependencies = [StarDep(name='buf66', mode=None)]
op67.met_dependencies = [StarDep(name='arg108_1', mode=None)]
op67.outputs = [
    buf67: ExternKernelAlloc
    buf67.layout = FixedLayout('cuda', torch.float32, size=[8, 224, 9, 9], stride=[18144, 1, 2016, 224])
    buf67.users = [NodeUser(node=SchedulerNode(name='op68'), can_inplace=True, is_weak=False)]
]
op67.node.kernel = extern_kernels.convolution


op68: SchedulerNode(ComputedBuffer)
op68.writes = [MemoryDep('buf68', c0, {c0: 145152}, None)]
op68.unmet_dependencies = [MemoryDep('buf67', c0, {c0: 145152}, None)]
op68.met_dependencies = 
    [   MemoryDep('arg109_1', c1, {c0: 648, c1: 224}, None),
        MemoryDep('arg110_1', c1, {c0: 648, c1: 224}, None),
        MemoryDep('arg111_1', c1, {c0: 648, c1: 224}, None),
        MemoryDep('arg112_1', c1, {c0: 648, c1: 224}, None)]
op68.outputs = [
    buf68: ComputedBuffer
    buf68.layout = FixedLayout('cuda', torch.float32, size=[8, 224, 9, 9], stride=[18144, 1, 2016, 224])
    buf68.users = [NodeUser(node=ExternKernelSchedulerNode(name='op69'), can_inplace=False, is_weak=False)]
]
op68.group.device = cuda:0
op68.group.iteration = (145152, 1)
op68.sizes = ([648, 224], [])
buf67_layout = FixedLayout('cuda', torch.float32, size=[8, 224, 9, 9], stride=[18144, 1, 2016, 224])
arg109_1_layout = FixedLayout('cuda', torch.float32, size=[224], stride=[1])
arg110_1_layout = FixedLayout('cuda', torch.float32, size=[224], stride=[1])
arg111_1_layout = FixedLayout('cuda', torch.float32, size=[224], stride=[1])
arg112_1_layout = FixedLayout('cuda', torch.float32, size=[224], stride=[1])
buf68_layout = FixedLayout('cuda', torch.float32, size=[8, 224, 9, 9], stride=[18144, 1, 2016, 224])
class op68_loop_body:
    var_ranges = {z0: 648, z1: 224}
    index0 = 224*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf67', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg109_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('arg110_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg111_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('arg112_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf68', get_index_5, relu, None)
        return store


op69: ExternKernelSchedulerNode(ExternKernelAlloc)
op69.writes = [StarDep(name='buf69', mode=None)]
op69.unmet_dependencies = [StarDep(name='buf68', mode=None)]
op69.met_dependencies = [StarDep(name='arg113_1', mode=None)]
op69.outputs = [
    buf69: ExternKernelAlloc
    buf69.layout = FixedLayout('cuda', torch.float32, size=[8, 224, 9, 9], stride=[18144, 1, 2016, 224])
    buf69.users = [NodeUser(node=ExternKernelSchedulerNode(name='op70'), can_inplace=False, is_weak=False)]
]
op69.node.kernel = extern_kernels.convolution


op70: ExternKernelSchedulerNode(ExternKernelAlloc)
op70.writes = [StarDep(name='buf70', mode=None)]
op70.unmet_dependencies = [StarDep(name='buf69', mode=None)]
op70.met_dependencies = [StarDep(name='arg114_1', mode=None)]
op70.outputs = [
    buf70: ExternKernelAlloc
    buf70.layout = FixedLayout('cuda', torch.float32, size=[8, 224, 9, 9], stride=[18144, 1, 2016, 224])
    buf70.users = [NodeUser(node=SchedulerNode(name='op71'), can_inplace=True, is_weak=False)]
]
op70.node.kernel = extern_kernels.convolution


op71: SchedulerNode(ComputedBuffer)
op71.writes = [MemoryDep('buf71', c0, {c0: 145152}, None)]
op71.unmet_dependencies = [MemoryDep('buf70', c0, {c0: 145152}, None)]
op71.met_dependencies = 
    [   MemoryDep('arg115_1', c1, {c0: 648, c1: 224}, None),
        MemoryDep('arg116_1', c1, {c0: 648, c1: 224}, None),
        MemoryDep('arg117_1', c1, {c0: 648, c1: 224}, None),
        MemoryDep('arg118_1', c1, {c0: 648, c1: 224}, None)]
op71.outputs = [
    buf71: ComputedBuffer
    buf71.layout = FixedLayout('cuda', torch.float32, size=[8, 224, 9, 9], stride=[18144, 1, 2016, 224])
    buf71.users = [
        NodeUser(node=ExternKernelSchedulerNode(name='op72'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op77'), can_inplace=False, is_weak=False),
    ]
]
op71.group.device = cuda:0
op71.group.iteration = (145152, 1)
op71.sizes = ([648, 224], [])
buf70_layout = FixedLayout('cuda', torch.float32, size=[8, 224, 9, 9], stride=[18144, 1, 2016, 224])
arg115_1_layout = FixedLayout('cuda', torch.float32, size=[224], stride=[1])
arg116_1_layout = FixedLayout('cuda', torch.float32, size=[224], stride=[1])
arg117_1_layout = FixedLayout('cuda', torch.float32, size=[224], stride=[1])
arg118_1_layout = FixedLayout('cuda', torch.float32, size=[224], stride=[1])
buf71_layout = FixedLayout('cuda', torch.float32, size=[8, 224, 9, 9], stride=[18144, 1, 2016, 224])
class op71_loop_body:
    var_ranges = {z0: 648, z1: 224}
    index0 = 224*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf70', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg115_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('arg116_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg117_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('arg118_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf71', get_index_5, relu, None)
        return store


op72: ExternKernelSchedulerNode(ExternKernelAlloc)
op72.writes = [StarDep(name='buf72', mode=None)]
op72.unmet_dependencies = [StarDep(name='buf71', mode=None)]
op72.met_dependencies = [StarDep(name='arg119_1', mode=None)]
op72.outputs = [
    buf72: ExternKernelAlloc
    buf72.layout = FixedLayout('cuda', torch.float32, size=[8, 224, 9, 9], stride=[18144, 1, 2016, 224])
    buf72.users = [NodeUser(node=ExternKernelSchedulerNode(name='op73'), can_inplace=False, is_weak=False)]
]
op72.node.kernel = extern_kernels.convolution


op73: ExternKernelSchedulerNode(ExternKernelAlloc)
op73.writes = [StarDep(name='buf73', mode=None)]
op73.unmet_dependencies = [StarDep(name='buf72', mode=None)]
op73.met_dependencies = [StarDep(name='arg120_1', mode=None)]
op73.outputs = [
    buf73: ExternKernelAlloc
    buf73.layout = FixedLayout('cuda', torch.float32, size=[8, 224, 9, 9], stride=[18144, 1, 2016, 224])
    buf73.users = [NodeUser(node=SchedulerNode(name='op74'), can_inplace=True, is_weak=False)]
]
op73.node.kernel = extern_kernels.convolution


op74: SchedulerNode(ComputedBuffer)
op74.writes = [MemoryDep('buf74', c0, {c0: 145152}, None)]
op74.unmet_dependencies = [MemoryDep('buf73', c0, {c0: 145152}, None)]
op74.met_dependencies = 
    [   MemoryDep('arg121_1', c1, {c0: 648, c1: 224}, None),
        MemoryDep('arg122_1', c1, {c0: 648, c1: 224}, None),
        MemoryDep('arg123_1', c1, {c0: 648, c1: 224}, None),
        MemoryDep('arg124_1', c1, {c0: 648, c1: 224}, None)]
op74.outputs = [
    buf74: ComputedBuffer
    buf74.layout = FixedLayout('cuda', torch.float32, size=[8, 224, 9, 9], stride=[18144, 1, 2016, 224])
    buf74.users = [
        NodeUser(node=ExternKernelSchedulerNode(name='op75'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op77'), can_inplace=False, is_weak=False),
    ]
]
op74.group.device = cuda:0
op74.group.iteration = (145152, 1)
op74.sizes = ([648, 224], [])
buf73_layout = FixedLayout('cuda', torch.float32, size=[8, 224, 9, 9], stride=[18144, 1, 2016, 224])
arg121_1_layout = FixedLayout('cuda', torch.float32, size=[224], stride=[1])
arg122_1_layout = FixedLayout('cuda', torch.float32, size=[224], stride=[1])
arg123_1_layout = FixedLayout('cuda', torch.float32, size=[224], stride=[1])
arg124_1_layout = FixedLayout('cuda', torch.float32, size=[224], stride=[1])
buf74_layout = FixedLayout('cuda', torch.float32, size=[8, 224, 9, 9], stride=[18144, 1, 2016, 224])
class op74_loop_body:
    var_ranges = {z0: 648, z1: 224}
    index0 = 224*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf73', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg121_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('arg122_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg123_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('arg124_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf74', get_index_5, relu, None)
        return store


op75: ExternKernelSchedulerNode(ExternKernelAlloc)
op75.writes = [StarDep(name='buf75', mode=None)]
op75.unmet_dependencies = [StarDep(name='buf74', mode=None)]
op75.met_dependencies = [StarDep(name='arg125_1', mode=None)]
op75.outputs = [
    buf75: ExternKernelAlloc
    buf75.layout = FixedLayout('cuda', torch.float32, size=[8, 224, 9, 9], stride=[18144, 1, 2016, 224])
    buf75.users = [NodeUser(node=ExternKernelSchedulerNode(name='op76'), can_inplace=False, is_weak=False)]
]
op75.node.kernel = extern_kernels.convolution


op76: ExternKernelSchedulerNode(ExternKernelAlloc)
op76.writes = [StarDep(name='buf76', mode=None)]
op76.unmet_dependencies = [StarDep(name='buf75', mode=None)]
op76.met_dependencies = [StarDep(name='arg126_1', mode=None)]
op76.outputs = [
    buf76: ExternKernelAlloc
    buf76.layout = FixedLayout('cuda', torch.float32, size=[8, 224, 9, 9], stride=[18144, 1, 2016, 224])
    buf76.users = [NodeUser(node=SchedulerNode(name='op77'), can_inplace=False, is_weak=False)]
]
op76.node.kernel = extern_kernels.convolution


op77: SchedulerNode(ComputedBuffer)
op77.writes = [MemoryDep('buf77', c0, {c0: 933120}, None)]
op77.unmet_dependencies = 
    [   MemoryDep('buf66', 768*c0 + I, {c0: 648, c1: 1440}, None),
        MemoryDep('buf71', 224*c0 + I, {c0: 648, c1: 1440}, None),
        MemoryDep('buf74', 224*c0 + I, {c0: 648, c1: 1440}, None),
        MemoryDep('buf76', 224*c0 + I, {c0: 648, c1: 1440}, None)]
op77.met_dependencies = 
    [   MemoryDep('arg127_1', I, {c0: 648, c1: 1440}, None),
        MemoryDep('arg128_1', I, {c0: 648, c1: 1440}, None),
        MemoryDep('arg129_1', I, {c0: 648, c1: 1440}, None),
        MemoryDep('arg130_1', I, {c0: 648, c1: 1440}, None)]
op77.outputs = [
    buf77: ComputedBuffer
    buf77.layout = FixedLayout('cuda', torch.float32, size=[8, 1440, 9, 9], stride=[116640, 1, 12960, 1440])
    buf77.users = [NodeUser(node=ExternKernelSchedulerNode(name='op78'), can_inplace=False, is_weak=False)]
]
op77.group.device = cuda:0
op77.group.iteration = (933120, 1)
op77.sizes = ([648, 1440], [])
buf66_layout = FixedLayout('cuda', torch.float32, size=[8, 768, 9, 9], stride=[62208, 1, 6912, 768])
buf71_layout = FixedLayout('cuda', torch.float32, size=[8, 224, 9, 9], stride=[18144, 1, 2016, 224])
buf74_layout = FixedLayout('cuda', torch.float32, size=[8, 224, 9, 9], stride=[18144, 1, 2016, 224])
buf76_layout = FixedLayout('cuda', torch.float32, size=[8, 224, 9, 9], stride=[18144, 1, 2016, 224])
arg127_1_layout = FixedLayout('cuda', torch.float32, size=[224], stride=[1])
arg128_1_layout = FixedLayout('cuda', torch.float32, size=[224], stride=[1])
arg129_1_layout = FixedLayout('cuda', torch.float32, size=[224], stride=[1])
arg130_1_layout = FixedLayout('cuda', torch.float32, size=[224], stride=[1])
buf77_layout = FixedLayout('cuda', torch.float32, size=[8, 1440, 9, 9], stride=[116640, 1, 12960, 1440])
class op77_loop_body:
    var_ranges = {z0: 648, z1: 1440}
    index0 = z1
    index1 = 768*z0 + I
    index2 = 224*z0 + I
    index3 = 224*z0 + I
    index4 = 224*z0 + I
    index5 = I
    index6 = 1440*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int64)
        constant = ops.constant(0, torch.int64)
        ge = ops.ge(index_expr, constant)
        get_index_1 = self.get_index('index0')
        index_expr_1 = ops.index_expr(get_index_1, torch.int64)
        constant_1 = ops.constant(768, torch.int64)
        lt = ops.lt(index_expr_1, constant_1)
        masked_subblock1 = self.masked_subblock1(lt, 0.0)
        get_index_2 = self.get_index('index0')
        index_expr_2 = ops.index_expr(get_index_2, torch.int64)
        constant_2 = ops.constant(768, torch.int64)
        ge_1 = ops.ge(index_expr_2, constant_2)
        get_index_3 = self.get_index('index0')
        index_expr_3 = ops.index_expr(get_index_3, torch.int64)
        constant_3 = ops.constant(992, torch.int64)
        lt_1 = ops.lt(index_expr_3, constant_3)
        and_ = ops.and_(ge_1, lt_1)
        masked_subblock2 = self.masked_subblock2(and_, 0.0)
        get_index_4 = self.get_index('index0')
        index_expr_4 = ops.index_expr(get_index_4, torch.int64)
        constant_4 = ops.constant(992, torch.int64)
        ge_2 = ops.ge(index_expr_4, constant_4)
        get_index_5 = self.get_index('index0')
        index_expr_5 = ops.index_expr(get_index_5, torch.int64)
        constant_5 = ops.constant(1216, torch.int64)
        lt_2 = ops.lt(index_expr_5, constant_5)
        and__1 = ops.and_(ge_2, lt_2)
        masked_subblock3 = self.masked_subblock3(and__1, 0.0)
        get_index_6 = self.get_index('index0')
        index_expr_6 = ops.index_expr(get_index_6, torch.int64)
        constant_6 = ops.constant(1216, torch.int64)
        ge_3 = ops.ge(index_expr_6, constant_6)
        get_index_7 = self.get_index('index0')
        index_expr_7 = ops.index_expr(get_index_7, torch.int64)
        constant_7 = ops.constant(1440, torch.int64)
        lt_3 = ops.lt(index_expr_7, constant_7)
        masked_subblock4 = self.masked_subblock4(ge_3, 0.0)
        where = ops.where(and__1, masked_subblock3, masked_subblock4)
        where_1 = ops.where(and_, masked_subblock2, where)
        where_2 = ops.where(lt, masked_subblock1, where_1)
        get_index_8 = self.get_index('index6')
        store = ops.store('buf77', get_index_8, where_2, None)
        return store
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('buf66', get_index)
        return load
    def masked_subblock2(self, ops):
        get_index = self.get_index('index2')
        load = ops.load('buf71', get_index)
        return load
    def masked_subblock3(self, ops):
        get_index = self.get_index('index3')
        load = ops.load('buf74', get_index)
        return load
    def masked_subblock4(self, ops):
        get_index = self.get_index('index4')
        load = ops.load('buf76', get_index)
        get_index_1 = self.get_index('index5')
        load_1 = ops.load('arg127_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index5')
        load_2 = ops.load('arg128_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index5')
        load_3 = ops.load('arg129_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index5')
        load_4 = ops.load('arg130_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        return relu


op78: ExternKernelSchedulerNode(ExternKernelAlloc)
op78.writes = [StarDep(name='buf78', mode=None)]
op78.unmet_dependencies = [StarDep(name='buf77', mode=None)]
op78.met_dependencies = [StarDep(name='arg131_1', mode=None)]
op78.outputs = [
    buf78: ExternKernelAlloc
    buf78.layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 9, 9], stride=[82944, 1, 9216, 1024])
    buf78.users = [NodeUser(node=SchedulerNode(name='op79'), can_inplace=True, is_weak=False)]
]
op78.node.kernel = extern_kernels.convolution


op79: SchedulerNode(ComputedBuffer)
op79.writes = [MemoryDep('buf79', c0, {c0: 663552}, None)]
op79.unmet_dependencies = [MemoryDep('buf78', c0, {c0: 663552}, None)]
op79.met_dependencies = 
    [   MemoryDep('arg132_1', c1, {c0: 648, c1: 1024}, None),
        MemoryDep('arg133_1', c1, {c0: 648, c1: 1024}, None),
        MemoryDep('arg134_1', c1, {c0: 648, c1: 1024}, None),
        MemoryDep('arg135_1', c1, {c0: 648, c1: 1024}, None)]
op79.outputs = [
    buf79: ComputedBuffer
    buf79.layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 9, 9], stride=[82944, 1, 9216, 1024])
    buf79.users = [
        NodeUser(node=SchedulerNode(name='op80'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op83'), can_inplace=False, is_weak=False),
    ]
]
op79.group.device = cuda:0
op79.group.iteration = (663552, 1)
op79.sizes = ([648, 1024], [])
buf78_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 9, 9], stride=[82944, 1, 9216, 1024])
arg132_1_layout = FixedLayout('cuda', torch.float32, size=[1024], stride=[1])
arg133_1_layout = FixedLayout('cuda', torch.float32, size=[1024], stride=[1])
arg134_1_layout = FixedLayout('cuda', torch.float32, size=[1024], stride=[1])
arg135_1_layout = FixedLayout('cuda', torch.float32, size=[1024], stride=[1])
buf79_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 9, 9], stride=[82944, 1, 9216, 1024])
class op79_loop_body:
    var_ranges = {z0: 648, z1: 1024}
    index0 = 1024*z0 + z1
    index1 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf78', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('arg132_1', get_index_1)
        sub = ops.sub(load, load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('arg133_1', get_index_2)
        constant = ops.constant(1e-05, torch.float32)
        add = ops.add(load_2, constant)
        sqrt = ops.sqrt(add)
        reciprocal = ops.reciprocal(sqrt)
        constant_1 = ops.constant(1.0, torch.float32)
        mul = ops.mul(reciprocal, constant_1)
        mul_1 = ops.mul(sub, mul)
        get_index_3 = self.get_index('index1')
        load_3 = ops.load('arg134_1', get_index_3)
        mul_2 = ops.mul(mul_1, load_3)
        get_index_4 = self.get_index('index1')
        load_4 = ops.load('arg135_1', get_index_4)
        add_1 = ops.add(mul_2, load_4)
        relu = ops.relu(add_1)
        get_index_5 = self.get_index('index0')
        store = ops.store('buf79', get_index_5, relu, None)
        return store


op80_op81: FusedSchedulerNode(SchedulerNode,SchedulerNode)
op80_op81.writes = 
    [   MemoryDep('buf80', c0, {c0: 8192}, None),
        MemoryDep('buf81', c0, {c0: 8192}, None)]
op80_op81.unmet_dependencies = [MemoryDep('buf79', 82944*c0 + c1 + 1024*c2, {c0: 8, c1: 1024, c2: 81}, None)]
op80_op81.met_dependencies = []
op80_op81.outputs = [
    buf80: ComputedBuffer
    buf80.layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1, 1], stride=[1024, 1, 8192, 8192])
    buf80.users = [NodeUser(node=SchedulerNode(name='op81'), can_inplace=True, is_weak=False)]
    buf81: ComputedBuffer
    buf81.layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1, 1], stride=[1024, 1, 1, 1])
    buf81.users = [NodeUser(node=ExternKernelSchedulerNode(name='op82'), can_inplace=False, is_weak=False)]
]
op80_op81.snodes[0] =
op80: SchedulerNode(ComputedBuffer)
op80.writes = [MemoryDep('buf80', c0, {c0: 8192}, None)]
op80.unmet_dependencies = [MemoryDep('buf79', 82944*c0 + c1 + 1024*c2, {c0: 8, c1: 1024, c2: 81}, None)]
op80.met_dependencies = []
op80.outputs = [
    buf80: ComputedBuffer
    buf80.layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1, 1], stride=[1024, 1, 8192, 8192])
    buf80.users = [NodeUser(node=SchedulerNode(name='op81'), can_inplace=True, is_weak=False)]
]
op80.group.device = cuda:0
op80.group.iteration = (8192, 81)
op80.sizes = ([8, 1024], [81])
buf79_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 9, 9], stride=[82944, 1, 9216, 1024])
buf80_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1, 1], stride=[1024, 1, 8192, 8192])
class op80_loop_body:
    var_ranges = {z0: 8, z1: 1024, z2: 81}
    index0 = 82944*z0 + z1 + 1024*z2
    index1 = 1024*z0 + z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf79', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf80', get_index_1, reduction)
        return store_reduction
op80_op81.snodes[1] =
op81: SchedulerNode(ComputedBuffer)
op81.writes = [MemoryDep('buf81', c0, {c0: 8192}, None)]
op81.unmet_dependencies = [MemoryDep('buf80', c0, {c0: 8192}, None)]
op81.met_dependencies = []
op81.outputs = [
    buf81: ComputedBuffer
    buf81.layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1, 1], stride=[1024, 1, 1, 1])
    buf81.users = [NodeUser(node=ExternKernelSchedulerNode(name='op82'), can_inplace=False, is_weak=False)]
]
op81.group.device = cuda:0
op81.group.iteration = (8192, 1)
op81.sizes = ([8192], [])
buf80_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1, 1], stride=[1024, 1, 8192, 8192])
buf81_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1, 1], stride=[1024, 1, 1, 1])
class op81_loop_body:
    var_ranges = {z0: 8192}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf80', get_index)
        constant = ops.constant(81.0, torch.float32)
        truediv = ops.truediv(load, constant)
        get_index_1 = self.get_index('index0')
        store = ops.store('buf81', get_index_1, truediv, None)
        return store


op82: ExternKernelSchedulerNode(ExternKernelAlloc)
op82.writes = [StarDep(name='buf82', mode=None)]
op82.unmet_dependencies = [StarDep(name='buf81', mode=None)]
op82.met_dependencies = [StarDep(name='arg136_1', mode=None)]
op82.outputs = [
    buf82: ExternKernelAlloc
    buf82.layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1, 1], stride=[1024, 1, 1, 1])
    buf82.users = [NodeUser(node=SchedulerNode(name='op83'), can_inplace=True, is_weak=False)]
]
op82.node.kernel = extern_kernels.convolution


op83_op84: FusedSchedulerNode(SchedulerNode,SchedulerNode)
op83_op84.writes = 
    [   MemoryDep('buf83', c0, {c0: 8192}, None),
        MemoryDep('buf84', c0, {c0: 8192}, None)]
op83_op84.unmet_dependencies = 
    [   MemoryDep('buf79', 82944*c0 + c1 + 1024*c2, {c0: 8, c1: 1024, c2: 81}, None),
        MemoryDep('buf82', c0, {c0: 8192}, None)]
op83_op84.met_dependencies = [MemoryDep('arg137_1', c1, {c0: 8, c1: 1024}, None)]
op83_op84.outputs = [
    buf83: ComputedBuffer
    buf83.layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1, 1], stride=[1024, 1, 8192, 8192])
    buf83.users = [NodeUser(node=SchedulerNode(name='op84'), can_inplace=True, is_weak=False)]
    buf84: ComputedBuffer
    buf84.layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1, 1], stride=[1024, 1, 8192, 8192])
    buf84.users = [NodeUser(node=ExternKernelSchedulerNode(name='op85'), can_inplace=False, is_weak=False)]
]
op83_op84.snodes[0] =
op83: SchedulerNode(ComputedBuffer)
op83.writes = [MemoryDep('buf83', c0, {c0: 8192}, None)]
op83.unmet_dependencies = 
    [   MemoryDep('buf79', 82944*c0 + c1 + 1024*c2, {c0: 8, c1: 1024, c2: 81}, None),
        MemoryDep('buf82', c0, {c0: 8192}, None)]
op83.met_dependencies = [MemoryDep('arg137_1', c1, {c0: 8, c1: 1024}, None)]
op83.outputs = [
    buf83: ComputedBuffer
    buf83.layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1, 1], stride=[1024, 1, 8192, 8192])
    buf83.users = [NodeUser(node=SchedulerNode(name='op84'), can_inplace=True, is_weak=False)]
]
op83.group.device = cuda:0
op83.group.iteration = (8192, 81)
op83.sizes = ([8, 1024], [81])
buf79_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 9, 9], stride=[82944, 1, 9216, 1024])
buf82_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1, 1], stride=[1024, 1, 1, 1])
arg137_1_layout = FixedLayout('cuda', torch.float32, size=[1024], stride=[1])
buf83_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1, 1], stride=[1024, 1, 8192, 8192])
class op83_loop_body:
    var_ranges = {z0: 8, z1: 1024, z2: 81}
    index0 = 82944*z0 + z1 + 1024*z2
    index1 = 1024*z0 + z1
    index2 = z1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf79', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('buf82', get_index_1)
        get_index_2 = self.get_index('index2')
        load_2 = ops.load('arg137_1', get_index_2)
        add = ops.add(load_1, load_2)
        constant = ops.constant(3.0, torch.float32)
        add_1 = ops.add(add, constant)
        constant_1 = ops.constant(0.0, torch.float32)
        maximum = ops.maximum(add_1, constant_1)
        constant_2 = ops.constant(6.0, torch.float32)
        minimum = ops.minimum(maximum, constant_2)
        constant_3 = ops.constant(0.16666666666666666, torch.float32)
        mul = ops.mul(minimum, constant_3)
        mul_1 = ops.mul(load, mul)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', mul_1)
        get_index_3 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf83', get_index_3, reduction)
        return store_reduction
op83_op84.snodes[1] =
op84: SchedulerNode(ComputedBuffer)
op84.writes = [MemoryDep('buf84', c0, {c0: 8192}, None)]
op84.unmet_dependencies = [MemoryDep('buf83', c0, {c0: 8192}, None)]
op84.met_dependencies = []
op84.outputs = [
    buf84: ComputedBuffer
    buf84.layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1, 1], stride=[1024, 1, 8192, 8192])
    buf84.users = [NodeUser(node=ExternKernelSchedulerNode(name='op85'), can_inplace=False, is_weak=False)]
]
op84.group.device = cuda:0
op84.group.iteration = (8192, 1)
op84.sizes = ([8192], [])
buf83_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1, 1], stride=[1024, 1, 8192, 8192])
buf84_layout = FixedLayout('cuda', torch.float32, size=[8, 1024, 1, 1], stride=[1024, 1, 8192, 8192])
class op84_loop_body:
    var_ranges = {z0: 8192}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf83', get_index)
        constant = ops.constant(81.0, torch.float32)
        truediv = ops.truediv(load, constant)
        get_index_1 = self.get_index('index0')
        store = ops.store('buf84', get_index_1, truediv, None)
        return store


op85: ExternKernelSchedulerNode(ExternKernelOut)
op85.writes = [StarDep(name='buf85', mode=None)]
op85.unmet_dependencies = [StarDep(name='buf84', mode=None)]
op85.met_dependencies = [StarDep(name='arg138_1', mode=None), StarDep(name='arg139_1', mode=None)]
op85.outputs = [
    buf85: ExternKernelOut
    buf85.layout = FixedLayout('cuda', torch.float32, size=[8, 1000], stride=[1000, 1])
    buf85.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op85.node.kernel = extern_kernels.addmm


