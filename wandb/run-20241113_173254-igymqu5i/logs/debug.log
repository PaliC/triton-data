2024-11-13 17:32:54,588 INFO    MainThread:476251 [wandb_setup.py:_flush():79] Current SDK version is 0.18.7
2024-11-13 17:32:54,589 INFO    MainThread:476251 [wandb_setup.py:_flush():79] Configure stats pid to 476251
2024-11-13 17:32:54,590 INFO    MainThread:476251 [wandb_setup.py:_flush():79] Loading settings from /home/sahanp/.config/wandb/settings
2024-11-13 17:32:54,590 INFO    MainThread:476251 [wandb_setup.py:_flush():79] Loading settings from /home/sahanp/triton-data/wandb/settings
2024-11-13 17:32:54,590 INFO    MainThread:476251 [wandb_setup.py:_flush():79] Loading settings from environment variables: {}
2024-11-13 17:32:54,590 INFO    MainThread:476251 [wandb_setup.py:_flush():79] Applying setup settings: {'mode': None, '_disable_service': None}
2024-11-13 17:32:54,590 WARNING MainThread:476251 [wandb_setup.py:_flush():79] Could not save program above cwd: /home/sahanp/.conda/envs/parity-bench/lib/python3.11/site-packages/recipes/full_finetune_single_device.py
2024-11-13 17:32:54,590 INFO    MainThread:476251 [wandb_setup.py:_flush():79] Inferring run settings from compute environment: {'program_relpath': None, 'program_abspath': '/home/sahanp/.conda/envs/parity-bench/lib/python3.11/site-packages/recipes/full_finetune_single_device.py', 'program': '/home/sahanp/.conda/envs/parity-bench/lib/python3.11/site-packages/recipes/full_finetune_single_device.py'}
2024-11-13 17:32:54,590 INFO    MainThread:476251 [wandb_setup.py:_flush():79] Applying login settings: {}
2024-11-13 17:32:54,590 INFO    MainThread:476251 [wandb_init.py:_log_setup():533] Logging user logs to /home/sahanp/triton-data/wandb/run-20241113_173254-igymqu5i/logs/debug.log
2024-11-13 17:32:54,590 INFO    MainThread:476251 [wandb_init.py:_log_setup():534] Logging internal logs to /home/sahanp/triton-data/wandb/run-20241113_173254-igymqu5i/logs/debug-internal.log
2024-11-13 17:32:54,590 INFO    MainThread:476251 [wandb_init.py:init():619] calling init triggers
2024-11-13 17:32:54,590 INFO    MainThread:476251 [wandb_init.py:init():626] wandb.init called with sweep_config: {}
config: {}
2024-11-13 17:32:54,590 INFO    MainThread:476251 [wandb_init.py:init():669] starting backend
2024-11-13 17:32:54,590 INFO    MainThread:476251 [wandb_init.py:init():673] sending inform_init request
2024-11-13 17:32:54,592 INFO    MainThread:476251 [backend.py:_multiprocessing_setup():104] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-11-13 17:32:54,601 INFO    MainThread:476251 [wandb_init.py:init():686] backend started and connected
2024-11-13 17:32:54,605 INFO    MainThread:476251 [wandb_init.py:init():781] updated telemetry
2024-11-13 17:32:54,640 INFO    MainThread:476251 [wandb_init.py:init():814] communicating run to backend with 90.0 second timeout
2024-11-13 17:32:57,275 INFO    MainThread:476251 [wandb_init.py:init():867] starting run threads in backend
2024-11-13 17:32:57,351 INFO    MainThread:476251 [wandb_run.py:_console_start():2456] atexit reg
2024-11-13 17:32:57,351 INFO    MainThread:476251 [wandb_run.py:_redirect():2305] redirect: wrap_raw
2024-11-13 17:32:57,351 INFO    MainThread:476251 [wandb_run.py:_redirect():2370] Wrapping output streams.
2024-11-13 17:32:57,351 INFO    MainThread:476251 [wandb_run.py:_redirect():2395] Redirects installed.
2024-11-13 17:32:57,352 INFO    MainThread:476251 [wandb_init.py:init():911] run started, returning control to user process
2024-11-13 17:32:57,354 INFO    MainThread:476251 [wandb_run.py:_config_callback():1387] config_cb None None {'seed': None, 'shuffle': True, 'tokenizer': {'_component_': 'torchtune.models.llama3.llama3_tokenizer', 'path': '/tmp/Llama-3.2-3B/original/tokenizer.model', 'max_seq_len': None}, 'dataset': {'_component_': 'torchtune.datasets.text_completion_dataset', 'data_files': 'datasets/triton_functions.json', 'source': 'json', 'column': 'input', 'split': 'train'}, 'model': {'_component_': 'torchtune.models.llama3_2.llama3_2_3b'}, 'checkpointer': {'_component_': 'torchtune.training.FullModelHFCheckpointer', 'checkpoint_dir': '/tmp/Llama-3.2-3B/', 'checkpoint_files': ['model-00001-of-00002.safetensors', 'model-00002-of-00002.safetensors'], 'recipe_checkpoint': None, 'output_dir': '/tmp/Llama-3.2-3B/', 'model_type': 'LLAMA3_2'}, 'resume_from_checkpoint': False, 'batch_size': 4, 'epochs': 1, 'optimizer': {'_component_': 'bitsandbytes.optim.PagedAdamW8bit', 'lr': 2e-05}, 'loss': {'_component_': 'torchtune.modules.loss.CEWithChunkedOutputLoss'}, 'max_steps_per_epoch': None, 'gradient_accumulation_steps': 1, 'optimizer_in_bwd': True, 'compile': False, 'device': 'cuda', 'enable_activation_checkpointing': True, 'dtype': 'bf16', 'metric_logger': {'_component_': 'torchtune.training.metric_logging.WandBLogger', 'project': 'torchtune'}, 'output_dir': '/tmp/full-llama3.2-finetune', 'log_every_n_steps': 1, 'log_peak_memory_stats': True, 'profiler': {'_component_': 'torchtune.training.setup_torch_profiler', 'enabled': False, 'output_dir': '/tmp/full-llama3.2-finetune/profiling_outputs', 'cpu': True, 'cuda': True, 'profile_memory': True, 'with_stack': False, 'record_shapes': True, 'with_flops': False, 'wait_steps': 1, 'warmup_steps': 2, 'active_steps': 1, 'num_cycles': 1}}
2024-11-13 17:32:57,390 WARNING MsgRouterThr:476251 [router.py:message_loop():75] message_loop has been closed
