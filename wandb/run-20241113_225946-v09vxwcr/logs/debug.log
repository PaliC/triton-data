2024-11-13 22:59:46,852 INFO    MainThread:1605750 [wandb_setup.py:_flush():79] Current SDK version is 0.18.7
2024-11-13 22:59:46,852 INFO    MainThread:1605750 [wandb_setup.py:_flush():79] Configure stats pid to 1605750
2024-11-13 22:59:46,852 INFO    MainThread:1605750 [wandb_setup.py:_flush():79] Loading settings from /home/sahanp/.config/wandb/settings
2024-11-13 22:59:46,852 INFO    MainThread:1605750 [wandb_setup.py:_flush():79] Loading settings from /home/sahanp/triton-data/wandb/settings
2024-11-13 22:59:46,852 INFO    MainThread:1605750 [wandb_setup.py:_flush():79] Loading settings from environment variables: {}
2024-11-13 22:59:46,852 INFO    MainThread:1605750 [wandb_setup.py:_flush():79] Applying setup settings: {'mode': None, '_disable_service': None}
2024-11-13 22:59:46,852 WARNING MainThread:1605750 [wandb_setup.py:_flush():79] Could not save program above cwd: /home/sahanp/.conda/envs/parity-bench/lib/python3.11/site-packages/recipes/full_finetune_distributed.py
2024-11-13 22:59:46,852 INFO    MainThread:1605750 [wandb_setup.py:_flush():79] Inferring run settings from compute environment: {'program_relpath': None, 'program_abspath': '/home/sahanp/.conda/envs/parity-bench/lib/python3.11/site-packages/recipes/full_finetune_distributed.py', 'program': '/home/sahanp/.conda/envs/parity-bench/lib/python3.11/site-packages/recipes/full_finetune_distributed.py'}
2024-11-13 22:59:46,852 INFO    MainThread:1605750 [wandb_setup.py:_flush():79] Applying login settings: {}
2024-11-13 22:59:46,852 INFO    MainThread:1605750 [wandb_init.py:_log_setup():533] Logging user logs to /home/sahanp/triton-data/wandb/run-20241113_225946-v09vxwcr/logs/debug.log
2024-11-13 22:59:46,852 INFO    MainThread:1605750 [wandb_init.py:_log_setup():534] Logging internal logs to /home/sahanp/triton-data/wandb/run-20241113_225946-v09vxwcr/logs/debug-internal.log
2024-11-13 22:59:46,852 INFO    MainThread:1605750 [wandb_init.py:init():619] calling init triggers
2024-11-13 22:59:46,852 INFO    MainThread:1605750 [wandb_init.py:init():626] wandb.init called with sweep_config: {}
config: {}
2024-11-13 22:59:46,852 INFO    MainThread:1605750 [wandb_init.py:init():669] starting backend
2024-11-13 22:59:46,852 INFO    MainThread:1605750 [wandb_init.py:init():673] sending inform_init request
2024-11-13 22:59:46,853 INFO    MainThread:1605750 [backend.py:_multiprocessing_setup():104] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-11-13 22:59:46,853 INFO    MainThread:1605750 [wandb_init.py:init():686] backend started and connected
2024-11-13 22:59:46,854 INFO    MainThread:1605750 [wandb_init.py:init():781] updated telemetry
2024-11-13 22:59:46,865 INFO    MainThread:1605750 [wandb_init.py:init():814] communicating run to backend with 90.0 second timeout
2024-11-13 22:59:47,379 INFO    MainThread:1605750 [wandb_init.py:init():867] starting run threads in backend
2024-11-13 22:59:47,455 INFO    MainThread:1605750 [wandb_run.py:_console_start():2456] atexit reg
2024-11-13 22:59:47,455 INFO    MainThread:1605750 [wandb_run.py:_redirect():2305] redirect: wrap_raw
2024-11-13 22:59:47,455 INFO    MainThread:1605750 [wandb_run.py:_redirect():2370] Wrapping output streams.
2024-11-13 22:59:47,455 INFO    MainThread:1605750 [wandb_run.py:_redirect():2395] Redirects installed.
2024-11-13 22:59:47,456 INFO    MainThread:1605750 [wandb_init.py:init():911] run started, returning control to user process
2024-11-13 22:59:47,458 INFO    MainThread:1605750 [wandb_run.py:_config_callback():1387] config_cb None None {'model': {'_component_': 'torchtune.models.llama3_2_vision.llama3_2_vision_11b', 'decoder_trainable': False, 'encoder_trainable': True, 'fusion_trainable': True, 'image_size': 560}, 'tokenizer': {'_component_': 'torchtune.models.llama3_2_vision.llama3_2_vision_transform', 'path': '/tmp/Llama-3.2-11B-Vision-Instruct/original/tokenizer.model', 'image_size': 560, 'max_seq_len': 8192}, 'checkpointer': {'_component_': 'torchtune.training.FullModelHFCheckpointer', 'checkpoint_dir': '/tmp/Llama-3.2-11B-Vision-Instruct/', 'checkpoint_files': ['model-00001-of-00005.safetensors', 'model-00002-of-00005.safetensors', 'model-00003-of-00005.safetensors', 'model-00004-of-00005.safetensors', 'model-00005-of-00005.safetensors'], 'recipe_checkpoint': None, 'output_dir': '/tmp/Llama-3.2-11B-Vision-Instruct/', 'model_type': 'LLAMA3_VISION'}, 'resume_from_checkpoint': False, 'dataset': {'_component_': 'torchtune.datasets.text_completion_dataset', 'data_files': 'datasets/triton_functions.json', 'source': 'json', 'column': 'input', 'split': 'train'}, 'seed': None, 'shuffle': True, 'collate_fn': 'torchtune.data.padded_collate_tiled_images_and_mask', 'epochs': 1, 'max_steps_per_epoch': None, 'batch_size': 2, 'gradient_accumulation_steps': 8, 'optimizer': {'_component_': 'torch.optim.AdamW', 'lr': 2e-05, 'fused': True}, 'optimizer_in_bwd': False, 'loss': {'_component_': 'torchtune.modules.loss.CEWithChunkedOutputLoss'}, 'clip_grad_norm': 1.0, 'compile': False, 'device': 'cuda', 'enable_activation_checkpointing': True, 'custom_sharded_layers': ['decoder.tok_embeddings'], 'dtype': 'bf16', 'metric_logger': {'_component_': 'torchtune.training.metric_logging.WandBLogger', 'project': 'torchtune'}, 'output_dir': '/tmp/full-llama3.2-finetune-11b', 'log_every_n_steps': 1, 'log_peak_memory_stats': True, 'profiler': {'_component_': 'torchtune.training.setup_torch_profiler', 'enabled': False, 'output_dir': '/tmp/full-llama3.2-finetune-11b/profiling_outputs', 'cpu': True, 'cuda': True, 'profile_memory': False, 'with_stack': False, 'record_shapes': True, 'with_flops': False, 'wait_steps': 5, 'warmup_steps': 3, 'active_steps': 2, 'num_cycles': 1}}
2024-11-13 22:59:55,880 WARNING MsgRouterThr:1605750 [router.py:message_loop():75] message_loop has been closed
